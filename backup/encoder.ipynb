{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# baic transformer Encoder model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fun\n",
    "import numpy as np\n",
    "\n",
    "main_df = pd.read_csv('adult.csv')\n",
    "# main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>78</td>\n",
       "      <td>97</td>\n",
       "      <td>164</td>\n",
       "      <td>185</td>\n",
       "      <td>199</td>\n",
       "      <td>209</td>\n",
       "      <td>220</td>\n",
       "      <td>225</td>\n",
       "      <td>229</td>\n",
       "      <td>230</td>\n",
       "      <td>253</td>\n",
       "      <td>341</td>\n",
       "      <td>437</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>78</td>\n",
       "      <td>88</td>\n",
       "      <td>174</td>\n",
       "      <td>187</td>\n",
       "      <td>197</td>\n",
       "      <td>207</td>\n",
       "      <td>217</td>\n",
       "      <td>227</td>\n",
       "      <td>229</td>\n",
       "      <td>230</td>\n",
       "      <td>253</td>\n",
       "      <td>351</td>\n",
       "      <td>437</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>76</td>\n",
       "      <td>104</td>\n",
       "      <td>170</td>\n",
       "      <td>190</td>\n",
       "      <td>197</td>\n",
       "      <td>213</td>\n",
       "      <td>217</td>\n",
       "      <td>227</td>\n",
       "      <td>229</td>\n",
       "      <td>230</td>\n",
       "      <td>253</td>\n",
       "      <td>341</td>\n",
       "      <td>437</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>78</td>\n",
       "      <td>93</td>\n",
       "      <td>178</td>\n",
       "      <td>188</td>\n",
       "      <td>197</td>\n",
       "      <td>209</td>\n",
       "      <td>217</td>\n",
       "      <td>225</td>\n",
       "      <td>229</td>\n",
       "      <td>237</td>\n",
       "      <td>253</td>\n",
       "      <td>341</td>\n",
       "      <td>437</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>89</td>\n",
       "      <td>178</td>\n",
       "      <td>188</td>\n",
       "      <td>199</td>\n",
       "      <td>202</td>\n",
       "      <td>220</td>\n",
       "      <td>227</td>\n",
       "      <td>228</td>\n",
       "      <td>230</td>\n",
       "      <td>253</td>\n",
       "      <td>331</td>\n",
       "      <td>437</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>10</td>\n",
       "      <td>78</td>\n",
       "      <td>99</td>\n",
       "      <td>170</td>\n",
       "      <td>190</td>\n",
       "      <td>197</td>\n",
       "      <td>215</td>\n",
       "      <td>222</td>\n",
       "      <td>227</td>\n",
       "      <td>228</td>\n",
       "      <td>230</td>\n",
       "      <td>253</td>\n",
       "      <td>339</td>\n",
       "      <td>437</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>23</td>\n",
       "      <td>78</td>\n",
       "      <td>92</td>\n",
       "      <td>174</td>\n",
       "      <td>187</td>\n",
       "      <td>197</td>\n",
       "      <td>209</td>\n",
       "      <td>217</td>\n",
       "      <td>227</td>\n",
       "      <td>229</td>\n",
       "      <td>230</td>\n",
       "      <td>253</td>\n",
       "      <td>341</td>\n",
       "      <td>437</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>41</td>\n",
       "      <td>78</td>\n",
       "      <td>92</td>\n",
       "      <td>174</td>\n",
       "      <td>187</td>\n",
       "      <td>201</td>\n",
       "      <td>203</td>\n",
       "      <td>221</td>\n",
       "      <td>227</td>\n",
       "      <td>228</td>\n",
       "      <td>230</td>\n",
       "      <td>253</td>\n",
       "      <td>341</td>\n",
       "      <td>437</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>95</td>\n",
       "      <td>174</td>\n",
       "      <td>187</td>\n",
       "      <td>199</td>\n",
       "      <td>203</td>\n",
       "      <td>220</td>\n",
       "      <td>227</td>\n",
       "      <td>229</td>\n",
       "      <td>230</td>\n",
       "      <td>253</td>\n",
       "      <td>321</td>\n",
       "      <td>437</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>79</td>\n",
       "      <td>101</td>\n",
       "      <td>174</td>\n",
       "      <td>187</td>\n",
       "      <td>197</td>\n",
       "      <td>206</td>\n",
       "      <td>222</td>\n",
       "      <td>227</td>\n",
       "      <td>228</td>\n",
       "      <td>244</td>\n",
       "      <td>253</td>\n",
       "      <td>341</td>\n",
       "      <td>437</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
       "0        8         78      97        164              185             199   \n",
       "1       21         78      88        174              187             197   \n",
       "2       11         76     104        170              190             197   \n",
       "3       27         78      93        178              188             197   \n",
       "4        1         74      89        178              188             199   \n",
       "...    ...        ...     ...        ...              ...             ...   \n",
       "48837   10         78      99        170              190             197   \n",
       "48838   23         78      92        174              187             197   \n",
       "48839   41         78      92        174              187             201   \n",
       "48840    5         78      95        174              187             199   \n",
       "48841   35         79     101        174              187             197   \n",
       "\n",
       "       occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
       "0             209           220   225     229           230           253   \n",
       "1             207           217   227     229           230           253   \n",
       "2             213           217   227     229           230           253   \n",
       "3             209           217   225     229           237           253   \n",
       "4             202           220   227     228           230           253   \n",
       "...           ...           ...   ...     ...           ...           ...   \n",
       "48837         215           222   227     228           230           253   \n",
       "48838         209           217   227     229           230           253   \n",
       "48839         203           221   227     228           230           253   \n",
       "48840         203           220   227     229           230           253   \n",
       "48841         206           222   227     228           244           253   \n",
       "\n",
       "       hours-per-week  native-country  income  \n",
       "0                 341             437     440  \n",
       "1                 351             437     440  \n",
       "2                 341             437     441  \n",
       "3                 341             437     441  \n",
       "4                 331             437     440  \n",
       "...               ...             ...     ...  \n",
       "48837             339             437     440  \n",
       "48838             341             437     441  \n",
       "48839             341             437     440  \n",
       "48840             321             437     440  \n",
       "48841             341             437     441  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAT = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\n",
    "NUM = ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "# qcut on numerical columns\n",
    "for column in NUM:\n",
    "    if column in ['educational-num','capital-gain','capital-loss','hours-per-week']:\n",
    "        main_df[column] = pd.cut(main_df[column], 100)\n",
    "    else:\n",
    "        main_df[column] = pd.cut(main_df[column], 100)\n",
    "# make income column binary\n",
    "main_df['income'] = main_df['income'].apply(lambda x: 1 if x == '>50K' else 0)\n",
    "\n",
    "# lable encoding categorical columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "main_df = main_df.apply(lambda x: lb.fit_transform(x))\n",
    "\n",
    "# make all catagory in every column unique\n",
    "\n",
    "# 迴圈處理多個欄位\n",
    "offset = 0\n",
    "for column in main_df.columns:\n",
    "    main_df[column] = main_df[column].apply(lambda x: x + offset)\n",
    "    offset += main_df[column].nunique()\n",
    "\n",
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.643585</td>\n",
       "      <td>77.870439</td>\n",
       "      <td>94.497113</td>\n",
       "      <td>173.288420</td>\n",
       "      <td>188.078089</td>\n",
       "      <td>197.618750</td>\n",
       "      <td>208.577700</td>\n",
       "      <td>218.443287</td>\n",
       "      <td>226.668052</td>\n",
       "      <td>228.668482</td>\n",
       "      <td>230.626858</td>\n",
       "      <td>254.102596</td>\n",
       "      <td>341.396728</td>\n",
       "      <td>434.749355</td>\n",
       "      <td>440.239282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.710510</td>\n",
       "      <td>1.464234</td>\n",
       "      <td>7.118204</td>\n",
       "      <td>3.874492</td>\n",
       "      <td>2.570973</td>\n",
       "      <td>1.507703</td>\n",
       "      <td>4.230509</td>\n",
       "      <td>1.602151</td>\n",
       "      <td>0.845986</td>\n",
       "      <td>0.470764</td>\n",
       "      <td>2.670115</td>\n",
       "      <td>5.196314</td>\n",
       "      <td>12.295271</td>\n",
       "      <td>7.775343</td>\n",
       "      <td>0.426649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>437.000000</td>\n",
       "      <td>440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>437.000000</td>\n",
       "      <td>440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>437.000000</td>\n",
       "      <td>440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>397.000000</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>441.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age     workclass        fnlwgt     education  \\\n",
       "count  48842.000000  48842.000000  48842.000000  48842.000000   \n",
       "mean      21.643585     77.870439     94.497113    173.288420   \n",
       "std       13.710510      1.464234      7.118204      3.874492   \n",
       "min        0.000000     74.000000     83.000000    163.000000   \n",
       "25%       11.000000     78.000000     90.000000    172.000000   \n",
       "50%       20.000000     78.000000     94.000000    174.000000   \n",
       "75%       31.000000     78.000000     98.000000    175.000000   \n",
       "max       73.000000     82.000000    162.000000    178.000000   \n",
       "\n",
       "       educational-num  marital-status    occupation  relationship  \\\n",
       "count     48842.000000    48842.000000  48842.000000  48842.000000   \n",
       "mean        188.078089      197.618750    208.577700    218.443287   \n",
       "std           2.570973        1.507703      4.230509      1.602151   \n",
       "min         179.000000      195.000000    202.000000    217.000000   \n",
       "25%         187.000000      197.000000    205.000000    217.000000   \n",
       "50%         188.000000      197.000000    209.000000    218.000000   \n",
       "75%         190.000000      199.000000    212.000000    220.000000   \n",
       "max         194.000000      201.000000    216.000000    222.000000   \n",
       "\n",
       "               race        gender  capital-gain  capital-loss  hours-per-week  \\\n",
       "count  48842.000000  48842.000000  48842.000000  48842.000000    48842.000000   \n",
       "mean     226.668052    228.668482    230.626858    254.102596      341.396728   \n",
       "std        0.845986      0.470764      2.670115      5.196314       12.295271   \n",
       "min      223.000000    228.000000    230.000000    253.000000      302.000000   \n",
       "25%      227.000000    228.000000    230.000000    253.000000      341.000000   \n",
       "50%      227.000000    229.000000    230.000000    253.000000      341.000000   \n",
       "75%      227.000000    229.000000    230.000000    253.000000      346.000000   \n",
       "max      227.000000    229.000000    252.000000    301.000000      397.000000   \n",
       "\n",
       "       native-country        income  \n",
       "count    48842.000000  48842.000000  \n",
       "mean       434.749355    440.239282  \n",
       "std          7.775343      0.426649  \n",
       "min        398.000000    440.000000  \n",
       "25%        437.000000    440.000000  \n",
       "50%        437.000000    440.000000  \n",
       "75%        437.000000    440.000000  \n",
       "max        439.000000    441.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data num: 48842\n",
      "trian data num: 39074\n",
      "test data num: 9768\n"
     ]
    }
   ],
   "source": [
    "train_size = 4*48842//5\n",
    "test_size = 48842//5\n",
    "train_pool = main_df[test_size:]\n",
    "test_pool = main_df[:test_size]\n",
    "print('total data num:' , main_df.shape[0])\n",
    "print('trian data num:' , train_pool.shape[0])\n",
    "print('test data num:' , test_pool.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notations\n",
    "#   node: number of all nodes = L + S + C + F\n",
    "#   L: number of lable nodes\n",
    "#   S: number of sample nodes\n",
    "#   C: number of catagory nodes\n",
    "#   F: number of field(column) nodes\n",
    "#   hidden: number of hidden representation\n",
    "\n",
    "# data size = (node, hidden)\n",
    "# mask size = (node, node - L) without lable nodes\n",
    "#             for each node, real mask = cat[mask,(node,L)] = (node, node)\n",
    "#             cannot see it's label node\n",
    "\n",
    "# use nn.transformerEncoder(data,mask) to get the output\n",
    "# use the above output as input of MLP to predict the lable   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature pool shape: (39074, 14)\n",
      "label pool shape: (39074, 2)\n",
      "L: 2\n",
      "S: 39074\n",
      "C: 438\n",
      "F: 14\n",
      "total 39528\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439]\n",
      "438\n"
     ]
    }
   ],
   "source": [
    "TARGET_POOL = train_pool\n",
    "LABEL_COLUMN = 'income'\n",
    "# \n",
    "HIDDEN = 64\n",
    "\n",
    "# cut feature and lable\n",
    "FEATURE_POOL = TARGET_POOL.drop(LABEL_COLUMN, axis=1)\n",
    "LABEL_POOL = TARGET_POOL[LABEL_COLUMN]\n",
    "\n",
    "# trasform label into one-hot\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "LABEL_POOL = enc.fit_transform(LABEL_POOL.values.reshape(-1,1)).toarray()\n",
    "\n",
    "print('feature pool shape:', FEATURE_POOL.shape)\n",
    "print('label pool shape:', LABEL_POOL.shape)\n",
    "\n",
    "# L: number of lable nodes\n",
    "L = LABEL_POOL.shape[1]\n",
    "\n",
    "# S: number of sample nodes\n",
    "S = FEATURE_POOL.shape[0]\n",
    "\n",
    "# C: number of catagory nodes\n",
    "C = FEATURE_POOL.apply(lambda x: x.nunique()).sum() # total_unique_labels\n",
    "C_POOL = list(set(FEATURE_POOL.values.flatten()))\n",
    "\n",
    "# F: number of field(column) nodes\n",
    "F = FEATURE_POOL.shape[1]\n",
    "\n",
    "print('L:', L)\n",
    "print('S:', S)\n",
    "print('C:', C)\n",
    "print('F:', F)\n",
    "print('total', L+S+C+F)\n",
    "print(C_POOL)\n",
    "print(len(C_POOL))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL_POOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173096\n",
      "1173096\n"
     ]
    }
   ],
   "source": [
    "# caculate masking\n",
    "\n",
    "edge_x = []\n",
    "edge_y = []\n",
    "\n",
    "# label to sample \n",
    "offset = (L,0) # (x,y)\n",
    "label_ids = TARGET_POOL[LABEL_COLUMN].unique()\n",
    "for i, value_df in enumerate(TARGET_POOL[LABEL_COLUMN]):\n",
    "    for j, value_label in enumerate(label_ids):\n",
    "        if value_label == value_df:\n",
    "            edge_x.append(offset[0] + i)\n",
    "            edge_y.append(offset[1] + j)\n",
    "\n",
    "# sample to catagory\n",
    "offset = (L+S,L) # (x,y)\n",
    "tmp_df = TARGET_POOL.drop(LABEL_COLUMN, axis=1)\n",
    "for i, value_df in enumerate(tmp_df.values):\n",
    "    for j, value in enumerate(value_df):\n",
    "        edge_x.append(offset[0] + value)\n",
    "        edge_y.append(offset[1] + i)\n",
    "\n",
    "# catagory to field\n",
    "offset = (L+S+C,L+S) # (x,y)\n",
    "unique_items = [(TARGET_POOL[column].unique()) for column in (TARGET_POOL.columns)]\n",
    "for i in range(F):\n",
    "    for j in (unique_items[i]):\n",
    "        edge_x.append(offset[0] + i)\n",
    "        edge_y.append(offset[1] + j)\n",
    "\n",
    "# make edges symmetric\n",
    "tmp = edge_x.copy()\n",
    "edge_x += edge_y\n",
    "edge_y += tmp\n",
    "\n",
    "# make value on edge as 1\n",
    "value_on_edge = [1]*len(edge_x)\n",
    "\n",
    "print(len(edge_x))\n",
    "print(len(edge_y))\n",
    "\n",
    "# create mask as sparse tensor\n",
    "indices = torch.tensor([edge_x, edge_y])\n",
    "values = torch.tensor(value_on_edge)\n",
    "size = torch.Size([L+S+C+F, L+S+C+F])\n",
    "sparse_tensor_mask = torch.sparse_coo_tensor(indices, values, size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = torch.tensor([[0,0], [1,1]])\n",
    "# values = torch.tensor([1,1])\n",
    "# size = torch.Size([C+S, C+S])\n",
    "# sparse_tensor_mask = torch.sparse_coo_tensor(indices, values, size).to_dense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        440\n",
       "1        440\n",
       "2        441\n",
       "3        441\n",
       "4        440\n",
       "        ... \n",
       "48837    440\n",
       "48838    441\n",
       "48839    440\n",
       "48840    440\n",
       "48841    441\n",
       "Name: income, Length: 48842, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df[LABEL_COLUMN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_input torch.cuda.FloatTensor torch.Size([2, 2])\n",
      "S_input torch.cuda.LongTensor torch.Size([39074, 14])\n",
      "C_input torch.cuda.LongTensor torch.Size([438, 438])\n",
      "F_input torch.cuda.FloatTensor torch.Size([14, 14])\n",
      "torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# make input tensor\n",
    "# L\n",
    "L_input = torch.eye(L).to('cuda')\n",
    "print('L_input', L_input.type(), L_input.shape)\n",
    "# S\n",
    "S_input = torch.tensor(FEATURE_POOL.values).to('cuda')\n",
    "print('S_input', S_input.type(), S_input.shape)\n",
    "# C random init\n",
    "C_input = torch.tensor(np.diag(C_POOL)).to('cuda')\n",
    "print('C_input', C_input.type(), C_input.shape)\n",
    "# F random init\n",
    "F_input = torch.eye(F).to('cuda')\n",
    "print('F_input', F_input.type(), F_input.shape)\n",
    "print(L_input.type())\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dimantions (2, 14, 438, 14)\n",
      "embedded shape torch.Size([39528, 128])\n",
      "embedded shape torch.cuda.sparse.FloatTensor\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'aten::view' with arguments from the 'SparseCUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::view' is only available for these backends: [CPU, CUDA, Meta, QuantizedCPU, QuantizedCUDA, MkldnnCPU, NestedTensorCPU, NestedTensorCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nCUDA: registered at aten/src/ATen/RegisterCUDA.cpp:43635 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:26815 [kernel]\nQuantizedCPU: registered at aten/src/ATen/RegisterQuantizedCPU.cpp:929 [kernel]\nQuantizedCUDA: registered at aten/src/ATen/RegisterQuantizedCUDA.cpp:452 [kernel]\nMkldnnCPU: registered at aten/src/ATen/RegisterMkldnnCPU.cpp:492 [kernel]\nNestedTensorCPU: registered at aten/src/ATen/RegisterNestedTensorCPU.cpp:457 [kernel]\nNestedTensorCUDA: registered at aten/src/ATen/RegisterNestedTensorCUDA.cpp:565 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at aten/src/ATen/RegisterFunctionalization_3.cpp:22330 [kernel]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: fallthrough registered at ../aten/src/ATen/ConjugateFallback.cpp:22 [kernel]\nNegative: fallthrough registered at ../aten/src/ATen/native/NegateFallback.cpp:22 [kernel]\nZeroTensor: registered at aten/src/ATen/RegisterZeroTensor.cpp:161 [kernel]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:5089 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradHIP: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradVE: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradMeta: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15910 [kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:14484 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/BatchRulesViews.cpp:512 [kernel]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1068 [kernel]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minput_dimantions\u001b[39m\u001b[39m'\u001b[39m, input_dimantions)\n\u001b[1;32m     53\u001b[0m model \u001b[39m=\u001b[39m TransformerEncoderModel(input_dimantions, num_layers, embedding_dim, hidden_dim)\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m output \u001b[39m=\u001b[39m model(L_input, S_input, C_input, F_input, sparse_tensor_mask\u001b[39m.\u001b[39;49mto(\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     56\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m模型輸出的大小:\u001b[39m\u001b[39m\"\u001b[39m, output\u001b[39m.\u001b[39msize())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[25], line 42\u001b[0m, in \u001b[0;36mTransformerEncoderModel.forward\u001b[0;34m(self, L_input, S_input, C_input, F_input, mask)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39membedded shape\u001b[39m\u001b[39m'\u001b[39m, embedded\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     40\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39membedded shape\u001b[39m\u001b[39m'\u001b[39m, embedded\u001b[39m.\u001b[39mtype())\n\u001b[0;32m---> 42\u001b[0m encoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_encoder(embedded, mask\u001b[39m.\u001b[39;49mfloat())  \u001b[39m# 使用 TransformerEncoder 編碼\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mencoded shape\u001b[39m\u001b[39m'\u001b[39m, encoded\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:280\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    277\u001b[0m         src_key_padding_mask_for_layers \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 280\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask_for_layers)\n\u001b[1;32m    282\u001b[0m \u001b[39mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    283\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mto_padded_tensor(\u001b[39m0.\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:538\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    536\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x))\n\u001b[1;32m    537\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 538\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sa_block(x, src_mask, src_key_padding_mask))\n\u001b[1;32m    539\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[1;32m    541\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:546\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sa_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor,\n\u001b[1;32m    545\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 546\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(x, x, x,\n\u001b[1;32m    547\u001b[0m                        attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m    548\u001b[0m                        key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m    549\u001b[0m                        need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    550\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py:1167\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1157\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m   1158\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         q_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_proj_weight, k_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_proj_weight,\n\u001b[1;32m   1165\u001b[0m         v_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_proj_weight, average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights)\n\u001b[1;32m   1166\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m   1168\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m   1169\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[1;32m   1170\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[1;32m   1171\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m   1172\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m   1173\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask, need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[1;32m   1174\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask, average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights)\n\u001b[1;32m   1175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[1;32m   1176\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:5046\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)\u001b[0m\n\u001b[1;32m   5044\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m use_separate_proj_weight:\n\u001b[1;32m   5045\u001b[0m     \u001b[39massert\u001b[39;00m in_proj_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39muse_separate_proj_weight is False but in_proj_weight is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 5046\u001b[0m     q, k, v \u001b[39m=\u001b[39m _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)\n\u001b[1;32m   5047\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5048\u001b[0m     \u001b[39massert\u001b[39;00m q_proj_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39muse_separate_proj_weight is True but q_proj_weight is None\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:4752\u001b[0m, in \u001b[0;36m_in_projection_packed\u001b[0;34m(q, k, v, w, b)\u001b[0m\n\u001b[1;32m   4750\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4751\u001b[0m     b_q, b_k, b_v \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mchunk(\u001b[39m3\u001b[39m)\n\u001b[0;32m-> 4752\u001b[0m \u001b[39mreturn\u001b[39;00m linear(q, w_q, b_q), linear(k, w_k, b_k), linear(v, w_v, b_v)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'aten::view' with arguments from the 'SparseCUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::view' is only available for these backends: [CPU, CUDA, Meta, QuantizedCPU, QuantizedCUDA, MkldnnCPU, NestedTensorCPU, NestedTensorCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nCUDA: registered at aten/src/ATen/RegisterCUDA.cpp:43635 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:26815 [kernel]\nQuantizedCPU: registered at aten/src/ATen/RegisterQuantizedCPU.cpp:929 [kernel]\nQuantizedCUDA: registered at aten/src/ATen/RegisterQuantizedCUDA.cpp:452 [kernel]\nMkldnnCPU: registered at aten/src/ATen/RegisterMkldnnCPU.cpp:492 [kernel]\nNestedTensorCPU: registered at aten/src/ATen/RegisterNestedTensorCPU.cpp:457 [kernel]\nNestedTensorCUDA: registered at aten/src/ATen/RegisterNestedTensorCUDA.cpp:565 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at aten/src/ATen/RegisterFunctionalization_3.cpp:22330 [kernel]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: fallthrough registered at ../aten/src/ATen/ConjugateFallback.cpp:22 [kernel]\nNegative: fallthrough registered at ../aten/src/ATen/native/NegateFallback.cpp:22 [kernel]\nZeroTensor: registered at aten/src/ATen/RegisterZeroTensor.cpp:161 [kernel]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:5089 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradHIP: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradVE: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradMeta: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15931 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:15910 [kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:14484 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/BatchRulesViews.cpp:512 [kernel]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1068 [kernel]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "# baic transformer Encoder model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fun\n",
    "\n",
    "class TransformerEncoderModel(nn.Module):\n",
    "    def __init__(self, nodes_num, num_layers, embedding_dim, hidden_dim):\n",
    "        super(TransformerEncoderModel, self).__init__()\n",
    "\n",
    "        L_dim, S_dim, C_dim, F_dim = nodes_num\n",
    "        \n",
    "        # 目前b卡在embedding的怎麼用\n",
    "        # Catagory_embedding => 數值類Qcut後用linear來做embedding, 類別用nn.Embedding\n",
    "        \n",
    "        # self.Lable_embedding = nn.Embedding(L_dim, embedding_dim)\n",
    "        # self.Sample_embedding = nn.Embedding(S_dim, embedding_dim)\n",
    "        # self.Catagory_embedding = nn.Embedding(C_dim, embedding_dim)\n",
    "        # self.Field_embedding = nn.Embedding(F_dim, emedding_dim)\n",
    "        \n",
    "        self.Lable_embedding = nn.Linear(L_dim, embedding_dim, dtype=torch.float)\n",
    "        self.Sample_embedding = nn.Linear(S_dim, embedding_dim, dtype=torch.float)\n",
    "        self.Catagory_embedding = nn.Linear(C_dim, embedding_dim, dtype=torch.float)\n",
    "        self.Field_embedding = nn.Linear(F_dim, embedding_dim, dtype=torch.float)\n",
    "        \n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(embedding_dim,nhead = 4 ),\n",
    "            num_layers\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, L_input, S_input, C_input, F_input, mask):\n",
    "        L_embedded = self.Lable_embedding(L_input.float())\n",
    "        S_embedded = self.Sample_embedding(S_input.float())\n",
    "        C_embedded = self.Catagory_embedding(C_input.float())\n",
    "        F_embedded = self.Field_embedding(F_input.float())\n",
    "        \n",
    "        # concat all embedded\n",
    "        embedded = torch.cat((L_embedded, S_embedded, C_embedded, F_embedded),0).to_sparse()\n",
    "        print('embedded shape', embedded.shape)\n",
    "        print('embedded shape', embedded.type())\n",
    "\n",
    "        encoded = self.transformer_encoder(embedded, mask.float())  # 使用 TransformerEncoder 編碼\n",
    "        print('encoded shape', encoded.shape)\n",
    "        # return encoded.permute(1, 0, 2)  # 改變 tensor 的維度順序回來\n",
    "\n",
    "# 測試模型\n",
    "num_layers = 2  # TransformerEncoder 的層數\n",
    "embedding_dim = 128  # 嵌入維度\n",
    "hidden_dim = 64  # TransformerEncoderLayer 的隱藏層維度\n",
    "\n",
    "input_dimantions = (L_input.size(1), S_input.size(1), C_input.size(1), F_input.size(1))\n",
    "print('input_dimantions', input_dimantions)\n",
    "model = TransformerEncoderModel(input_dimantions, num_layers, embedding_dim, hidden_dim).to('cuda')\n",
    "output = model(L_input, S_input, C_input, F_input, sparse_tensor_mask.to('cuda'))\n",
    "\n",
    "print(\"模型輸出的大小:\", output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baic transformer Encoder model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fun\n",
    "\n",
    "class TransformerEncoderModel(nn.Module):\n",
    "    def __init__(self, nodes_num, num_layers, embedding_dim, hidden_dim):\n",
    "        super(TransformerEncoderModel, self).__init__()\n",
    "\n",
    "        L_dim, S_dim, C_dim, F_dim = nodes_num\n",
    "        \n",
    "        # 目前b卡在embedding的怎麼用\n",
    "        # Catagory_embedding => 數值類Qcut後用linear來做embedding, 類別用nn.Embedding\n",
    "        \n",
    "        # self.Lable_embedding = nn.Embedding(L_dim, embedding_dim)\n",
    "        # self.Sample_embedding = nn.Embedding(S_dim, embedding_dim)\n",
    "        # self.Catagory_embedding = nn.Embedding(C_dim, embedding_dim)\n",
    "        # self.Field_embedding = nn.Embedding(F_dim, emedding_dim)\n",
    "        \n",
    "        self.Lable_embedding = nn.Linear(L_dim, embedding_dim, dtype=torch.float)\n",
    "        self.Sample_embedding = nn.Linear(S_dim, embedding_dim, dtype=torch.float)\n",
    "        self.Catagory_embedding = nn.Linear(C_dim, embedding_dim, dtype=torch.float)\n",
    "        self.Field_embedding = nn.Linear(F_dim, embedding_dim, dtype=torch.float)\n",
    "        \n",
    "        self.transformer_decoder = nn.TransformerDecoder(\n",
    "            nn.TransformerDecoderLayer(embedding_dim,nhead = 4 ),\n",
    "            num_layers\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, L_input, S_input, C_input, F_input, mask):\n",
    "        L_embedded = self.Lable_embedding(L_input.float())\n",
    "        S_embedded = self.Sample_embedding(S_input.float())\n",
    "        C_embedded = self.Catagory_embedding(C_input.float())\n",
    "        F_embedded = self.Field_embedding(F_input.float())\n",
    "        \n",
    "        # concat all embedded\n",
    "        embedded = torch.cat((L_embedded, S_embedded, C_embedded, F_embedded),0).to_sparse()\n",
    "        print('embedded shape', embedded.shape)\n",
    "        print('embedded shape', embedded.type())\n",
    "\n",
    "        encoded = self.transformer_decoder(embedded, mask.float())  # 使用 TransformerEncoder 編碼\n",
    "        print('encoded shape', encoded.shape)\n",
    "        # return encoded.permute(1, 0, 2)  # 改變 tensor 的維度順序回來\n",
    "\n",
    "# 測試模型\n",
    "num_layers = 2  # TransformerEncoder 的層數\n",
    "embedding_dim = 128  # 嵌入維度\n",
    "hidden_dim = 64  # TransformerEncoderLayer 的隱藏層維度\n",
    "\n",
    "input_dimantions = (L_input.size(1), S_input.size(1), C_input.size(1), F_input.size(1))\n",
    "print('input_dimantions', input_dimantions)\n",
    "model = TransformerEncoderModel(input_dimantions, num_layers, embedding_dim, hidden_dim).to('cuda')\n",
    "output = model(L_input, S_input, C_input, F_input, sparse_tensor_mask.to('cuda'))\n",
    "\n",
    "print(\"模型輸出的大小:\", output.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
