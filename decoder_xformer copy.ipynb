{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# baic transformer Decoder model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fun\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import xformers.ops as xops\n",
    "import math\n",
    "\n",
    "main_df = pd.read_csv('adult.csv')\n",
    "main_df.head()\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>78</td>\n",
       "      <td>97</td>\n",
       "      <td>164</td>\n",
       "      <td>185</td>\n",
       "      <td>199</td>\n",
       "      <td>209</td>\n",
       "      <td>220</td>\n",
       "      <td>225</td>\n",
       "      <td>229</td>\n",
       "      <td>230</td>\n",
       "      <td>253</td>\n",
       "      <td>341</td>\n",
       "      <td>437</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>78</td>\n",
       "      <td>88</td>\n",
       "      <td>174</td>\n",
       "      <td>187</td>\n",
       "      <td>197</td>\n",
       "      <td>207</td>\n",
       "      <td>217</td>\n",
       "      <td>227</td>\n",
       "      <td>229</td>\n",
       "      <td>230</td>\n",
       "      <td>253</td>\n",
       "      <td>351</td>\n",
       "      <td>437</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>76</td>\n",
       "      <td>104</td>\n",
       "      <td>170</td>\n",
       "      <td>190</td>\n",
       "      <td>197</td>\n",
       "      <td>213</td>\n",
       "      <td>217</td>\n",
       "      <td>227</td>\n",
       "      <td>229</td>\n",
       "      <td>230</td>\n",
       "      <td>253</td>\n",
       "      <td>341</td>\n",
       "      <td>437</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>78</td>\n",
       "      <td>93</td>\n",
       "      <td>178</td>\n",
       "      <td>188</td>\n",
       "      <td>197</td>\n",
       "      <td>209</td>\n",
       "      <td>217</td>\n",
       "      <td>225</td>\n",
       "      <td>229</td>\n",
       "      <td>237</td>\n",
       "      <td>253</td>\n",
       "      <td>341</td>\n",
       "      <td>437</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>89</td>\n",
       "      <td>178</td>\n",
       "      <td>188</td>\n",
       "      <td>199</td>\n",
       "      <td>202</td>\n",
       "      <td>220</td>\n",
       "      <td>227</td>\n",
       "      <td>228</td>\n",
       "      <td>230</td>\n",
       "      <td>253</td>\n",
       "      <td>331</td>\n",
       "      <td>437</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
       "0    8         78      97        164              185             199   \n",
       "1   21         78      88        174              187             197   \n",
       "2   11         76     104        170              190             197   \n",
       "3   27         78      93        178              188             197   \n",
       "4    1         74      89        178              188             199   \n",
       "\n",
       "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
       "0         209           220   225     229           230           253   \n",
       "1         207           217   227     229           230           253   \n",
       "2         213           217   227     229           230           253   \n",
       "3         209           217   225     229           237           253   \n",
       "4         202           220   227     228           230           253   \n",
       "\n",
       "   hours-per-week  native-country  income  \n",
       "0             341             437     440  \n",
       "1             351             437     440  \n",
       "2             341             437     441  \n",
       "3             341             437     441  \n",
       "4             331             437     440  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def POOL_preprocess(df):\n",
    "    '''\n",
    "    input the original dataframe, output the dataframe after preprocessing,\n",
    "    change the numerical columns to categorical columns by qcut and cut\n",
    "    then apply label encoding to all columns\n",
    "    \n",
    "    '''\n",
    "    df = df.copy()\n",
    "    CAT = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\n",
    "    NUM = ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "    # qcut on numerical columns\n",
    "    for column in NUM:\n",
    "        if column in ['educational-num','capital-gain','capital-loss','hours-per-week']:\n",
    "            df[column] = pd.cut(df[column], 100)\n",
    "        else:\n",
    "            df[column] = pd.cut(df[column], 100)\n",
    "    # make income column binary\n",
    "    df['income'] = df['income'].apply(lambda x: 1 if x == '>50K' else 0)\n",
    "\n",
    "    # lable encoding categorical columns\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    lb = LabelEncoder()\n",
    "    df = df.apply(lambda x: lb.fit_transform(x))\n",
    "\n",
    "    # make all catagory in every column unique\n",
    "\n",
    "    # 迴圈處理多個欄位\n",
    "    offset = 0\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].apply(lambda x: x + offset)\n",
    "        offset += df[column].nunique()\n",
    "    \n",
    "    return df\n",
    "tmp = POOL_preprocess(main_df)\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data num: 48842\n",
      "trian data num: 39074\n",
      "test data num: 9768\n"
     ]
    }
   ],
   "source": [
    "train_size = 4*48842//5\n",
    "test_size = 48842//5\n",
    "train_pool = main_df[test_size:]\n",
    "test_pool = main_df[:test_size]\n",
    "print('total data num:' , main_df.shape[0])\n",
    "print('trian data num:' , train_pool.shape[0])\n",
    "print('test data num:' , test_pool.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notations\n",
    "#   node: number of all nodes = L + S + C + F\n",
    "#   L: number of lable nodes\n",
    "#   S: number of sample nodes\n",
    "#   C: number of catagory nodes\n",
    "#   F: number of field(column) nodes\n",
    "#   hidden: number of hidden representation\n",
    "\n",
    "# data size = (node, hidden)\n",
    "# mask size = (node, node - L) without lable nodes\n",
    "#             for each node, real mask = cat[mask,(node,L)] = (node, node)\n",
    "#             cannot see it's label node\n",
    "\n",
    "# use nn.transformerDecoder(data,mask) to get the output\n",
    "# use the above output as input of MLP to predict the lable   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_nums {'L': 2, 'S': 39074, 'C': 437, 'F': 14}\n",
      "total 39527 nodes\n",
      "L_input torch.cuda.FloatTensor torch.Size([2, 2])\n",
      "S_input torch.cuda.LongTensor torch.Size([39074, 14])\n",
      "C_input torch.cuda.LongTensor torch.Size([437, 437])\n",
      "F_input torch.cuda.FloatTensor torch.Size([14, 14])\n",
      "torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "class HGNN_DataSet():\n",
    "    def __init__(self,\n",
    "                 mode : str,  # {'train', 'test'}\n",
    "                 target_df : pd.DataFrame,\n",
    "                 label_column : str):\n",
    "        TARGET_POOL = POOL_preprocess(target_df)\n",
    "        LABEL_COLUMN = label_column\n",
    "\n",
    "        # cut feature and lable\n",
    "        FEATURE_POOL = TARGET_POOL.drop(LABEL_COLUMN, axis=1)\n",
    "        LABEL_POOL = TARGET_POOL[LABEL_COLUMN]\n",
    "\n",
    "        # trasform label into one-hot\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "        enc = OneHotEncoder()\n",
    "        LABEL_POOL = enc.fit_transform(LABEL_POOL.values.reshape(-1,1)).toarray()\n",
    "\n",
    "        # L: number of lable nodes\n",
    "        L = LABEL_POOL.shape[1]\n",
    "\n",
    "        # S: number of sample nodes\n",
    "        S = FEATURE_POOL.shape[0]\n",
    "\n",
    "        # C: number of catagory nodes\n",
    "        C = FEATURE_POOL.apply(lambda x: x.nunique()).sum() # total_unique_labels\n",
    "        C_POOL = sorted(list(set(FEATURE_POOL.values.flatten())))\n",
    "        # the last node of catagory nodes is served as knseen node\n",
    "        C += 1\n",
    "        C_POOL.append(C_POOL[-1] + 1)\n",
    "\n",
    "        # F: number of field(column) nodes\n",
    "        F = FEATURE_POOL.shape[1]\n",
    "\n",
    "        nodes_num = {'L':L, 'S':S, 'C':C, 'F':F}\n",
    "        print('node_nums', nodes_num)\n",
    "        print('total', L+S+C+F, 'nodes')\n",
    "        \n",
    "        self.TARGET_POOL = TARGET_POOL\n",
    "        self.LABEL_COLUMN = LABEL_COLUMN\n",
    "        self.FEATURE_POOL = FEATURE_POOL\n",
    "        self.LABEL_POOL = LABEL_POOL\n",
    "        self.C_POOL = C_POOL   \n",
    "        self.nodes_num = nodes_num\n",
    "        \n",
    "        \n",
    "        self.make_mask()\n",
    "        self.make_input_tensor()\n",
    "        \n",
    "        \n",
    "    def make_mask(self):\n",
    "        L, S, C, F = self.nodes_num['L'], self.nodes_num['S'], self.nodes_num['C'], self.nodes_num['F']\n",
    "        # caculate masking\n",
    "        masks = {}\n",
    "\n",
    "        # label to sample \n",
    "        tmp = torch.zeros([math.ceil(S/8) * 8, math.ceil(L/8) * 8], dtype=torch.float)\n",
    "        label_ids = self.TARGET_POOL[self.LABEL_COLUMN].unique()\n",
    "        for i, value_df in enumerate(self.TARGET_POOL[self.LABEL_COLUMN]):\n",
    "            for j, value_label in enumerate(label_ids):\n",
    "                if value_label == value_df:\n",
    "                    tmp[i][j] = 1\n",
    "                    break\n",
    "        masks['L2S'] = tmp\n",
    "\n",
    "\n",
    "        # sample to catagory\n",
    "        tmp = torch.zeros([math.ceil(C/8) * 8, math.ceil(S/8) * 8], dtype=torch.float)\n",
    "        tmp_df = self.TARGET_POOL.drop(self.LABEL_COLUMN, axis=1)\n",
    "        for i, value_df in enumerate(tmp_df.values):\n",
    "            for j, value in enumerate(value_df):\n",
    "                tmp[value][i] = 1\n",
    "        masks['S2C'] = tmp\n",
    "\n",
    "\n",
    "        # catagory to field\n",
    "        tmp = torch.zeros([math.ceil(F/8) * 8, math.ceil(C/8) * 8], dtype=torch.float)\n",
    "        unique_items = [(self.TARGET_POOL[column].unique()) for column in (self.TARGET_POOL.columns)]\n",
    "        for i in range(F):\n",
    "            for j in (unique_items[i]):\n",
    "                tmp[i][j] = 1\n",
    "        masks['C2F'] = tmp\n",
    "        \n",
    "        self.MASKS = masks\n",
    "        \n",
    "    def make_input_tensor(self):\n",
    "        # make input tensor\n",
    "        L, S, C, F = self.nodes_num['L'], self.nodes_num['S'], self.nodes_num['C'], self.nodes_num['F']\n",
    "        # L\n",
    "        L_input = torch.eye(L).to(DEVICE)\n",
    "        print('L_input', L_input.type(), L_input.shape)\n",
    "        # S\n",
    "        S_input = torch.tensor(self.FEATURE_POOL.values).to(DEVICE)\n",
    "        print('S_input', S_input.type(), S_input.shape)\n",
    "        # C random init\n",
    "        C_input = torch.tensor(np.diag(self.C_POOL)).to(DEVICE)\n",
    "        print('C_input', C_input.type(), C_input.shape)\n",
    "        # F random init\n",
    "        F_input = torch.eye(F).to(DEVICE)\n",
    "        print('F_input', F_input.type(), F_input.shape)\n",
    "        print(L_input.type())\n",
    "        # \n",
    "        self.INPUTS = (L_input, S_input, C_input, F_input)\n",
    "        self.INPUT_DIMS = (L_input.size(1), S_input.size(1), C_input.size(1), F_input.size(1))\n",
    "Train_data = HGNN_DataSet('train', train_pool, 'income')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from typing import Optional, Any, Union, Callable\n",
    "\n",
    "class CustomTransformerDecoderLayer(nn.TransformerDecoderLayer):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, activation='relu'):\n",
    "        super().__init__(d_model, nhead, dim_feedforward, dropout, activation)\n",
    "        # remove defined modules\n",
    "        delattr(self, 'self_attn')\n",
    "        delattr(self, 'norm1')\n",
    "        delattr(self, 'dropout1')\n",
    "    \n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        x = tgt\n",
    "        if self.norm_first:\n",
    "            # x = x + self._sa_block(self.norm1(x), tgt_mask, tgt_key_padding_mask)\n",
    "            x = x + self._mha_block(self.norm2(x), memory, memory_mask, memory_key_padding_mask)\n",
    "            x = x + self._ff_block(self.norm3(x))\n",
    "        else:\n",
    "            # x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))\n",
    "            x = self.norm2(x + self._mha_block(x, memory, memory_mask, memory_key_padding_mask))\n",
    "            # x =  x + self._mha_block(x, memory, memory_mask, memory_key_padding_mask)\n",
    "            # x = self.norm3(x + self._ff_block(x))\n",
    "\n",
    "        return x\n",
    "    def _mha_block(self, x: Tensor, mem: Tensor,\n",
    "                   attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) -> Tensor:\n",
    "        # random_mask = torch.cuda.FloatTensor(mem.shape[0], 1).uniform_() > 0.8\n",
    "        # print(sum(sum(attn_mask)))\n",
    "        x = xops.memory_efficient_attention(x, mem, mem, attn_mask)\n",
    "        return self.dropout2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dims (2, 14, 437, 14)\n",
      "模型輸出的大小: torch.Size([39074, 2])\n"
     ]
    }
   ],
   "source": [
    "# baic transformer decoder model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fun\n",
    "\n",
    "class TransformerDecoderModel(nn.Module):\n",
    "    def __init__(self, target_dataset, num_layers, embedding_dim, hidden_dim):\n",
    "        super(TransformerDecoderModel, self).__init__()\n",
    "\n",
    "        L_dim, S_dim, C_dim, F_dim = target_dataset.INPUT_DIMS\n",
    "        \n",
    "        # 目前b卡在embedding的怎麼用\n",
    "        # Catagory_embedding => 數值類Qcut後用linear來做embedding, 類別用nn.Embedding\n",
    "\n",
    "        self.Lable_embedding = nn.Linear(L_dim, embedding_dim, dtype=torch.float)\n",
    "        self.Sample_embedding = nn.Linear(S_dim, embedding_dim, dtype=torch.float)\n",
    "        self.Catagory_embedding = nn.Linear(C_dim, embedding_dim, dtype=torch.float)\n",
    "        self.Field_embedding = nn.Linear(F_dim, embedding_dim, dtype=torch.float)\n",
    "        \n",
    "        self.transformer_decoder = nn.TransformerDecoder(\n",
    "            CustomTransformerDecoderLayer(embedding_dim,  nhead = 1 ),\n",
    "            num_layers\n",
    "        )\n",
    "        \n",
    "        # downstream task\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim//3),\n",
    "            nn.LeakyReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(embedding_dim//3, 2),\n",
    "            #nn.LeakyReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Softmax(dim=2),\n",
    "            # nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, target_dataset):\n",
    "        L_input, S_input, C_input, F_input = target_dataset.INPUTS\n",
    "        L, S, C, F = target_dataset.nodes_num['L'], target_dataset.nodes_num['S'], target_dataset.nodes_num['C'], target_dataset.nodes_num['F']\n",
    "        masks = target_dataset.MASKS\n",
    "        \n",
    "        L_embedded = self.Lable_embedding(L_input.float()).unsqueeze(0)\n",
    "        S_embedded = self.Sample_embedding(S_input.float()).unsqueeze(0)\n",
    "        C_embedded = self.Catagory_embedding(C_input.float()).unsqueeze(0)\n",
    "        F_embedded = self.Field_embedding(F_input.float()).unsqueeze(0)\n",
    "        \n",
    "        for mask in masks.keys():\n",
    "            masks[mask] = masks[mask].to(DEVICE)\n",
    "        \n",
    "        # propagate steps: L→S→C→F\n",
    "        #                  L←S←C←\n",
    "        # more steps more menory usage\n",
    "        PROPAGATE_STEPS = 3\n",
    "        for i in range(PROPAGATE_STEPS):\n",
    "            S_embedded = self.transformer_decoder(S_embedded,L_embedded, \n",
    "                                                memory_mask = masks['L2S'][:S,:L]) \n",
    "            C_embedded = self.transformer_decoder(C_embedded,S_embedded,\n",
    "                                                memory_mask = masks['S2C'][:C,:S])\n",
    "            F_embedded = self.transformer_decoder(F_embedded,C_embedded,\n",
    "                                                memory_mask = masks['C2F'][:F,:C])\n",
    "            C_embedded = self.transformer_decoder(C_embedded,F_embedded,\n",
    "                                                memory_mask = Tensor.contiguous(masks['C2F'].transpose(0, 1))[:C,:F])\n",
    "            S_embedded = self.transformer_decoder(S_embedded,C_embedded,\n",
    "                                                memory_mask = Tensor.contiguous(masks['S2C'].transpose(0, 1))[:S,:C])\n",
    "            L_embedded = self.transformer_decoder(L_embedded,S_embedded, \n",
    "                                                memory_mask = Tensor.contiguous(masks['L2S'].transpose(0, 1))[:L,:S])\n",
    "        \n",
    "        output = self.MLP(S_embedded)[0]\n",
    "        return output\n",
    "\n",
    "# 測試模型\n",
    "num_layers = 1  # TransformerDecoder 的層數\n",
    "embedding_dim = 2*128  # 嵌入維度\n",
    "hidden_dim = 64  \n",
    "\n",
    "print('input_dims', Train_data.INPUT_DIMS)\n",
    "model = TransformerDecoderModel(Train_data, num_layers, embedding_dim, hidden_dim).to(DEVICE)\n",
    "outputs = model(Train_data)\n",
    "\n",
    "print(\"模型輸出的大小:\", outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5407, 0.4593],\n",
       "        [0.5539, 0.4461],\n",
       "        [0.5335, 0.4665],\n",
       "        ...,\n",
       "        [0.5644, 0.4356],\n",
       "        [0.5571, 0.4429],\n",
       "        [0.5360, 0.4640]], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_label = torch.argmax(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1/100 | Loss: 0.6359372644687544 | Acc: 0.7595843783590112 | AUC: 0.643252968788147\n",
      "Epoch2/100 | Loss: 0.582979273190791 | Acc: 0.7595843783590112 | AUC: 0.794161319732666\n",
      "Epoch3/100 | Loss: 0.5646408041985379 | Acc: 0.7595843783590112 | AUC: 0.8971868753433228\n",
      "Epoch4/100 | Loss: 0.5580641540911362 | Acc: 0.7595843783590112 | AUC: 0.9479806423187256\n",
      "Epoch5/100 | Loss: 0.5557018130798023 | Acc: 0.7595843783590112 | AUC: 0.972641110420227\n",
      "Epoch6/100 | Loss: 0.5547354501626469 | Acc: 0.7595843783590112 | AUC: 0.9849541187286377\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m | Loss: \u001b[39m\u001b[39m{\u001b[39;00mepoch_loss\u001b[39m}\u001b[39;00m\u001b[39m | Acc: \u001b[39m\u001b[39m{\u001b[39;00mepoch_acc\u001b[39m}\u001b[39;00m\u001b[39m | AUC: \u001b[39m\u001b[39m{\u001b[39;00mepoch_AUC\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m model \u001b[39m=\u001b[39m TransformerDecoderModel(Train_data, num_layers, embedding_dim, hidden_dim)\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[0;32m---> 40\u001b[0m train(model, Train_data)\n",
      "Cell \u001b[0;32mIn[21], line 29\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, datset)\u001b[0m\n\u001b[1;32m     24\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     27\u001b[0m output_label \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(outputs, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m TRUE \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(torch\u001b[39m.\u001b[39;49mtensor(LABEL_POOL)\u001b[39m.\u001b[39;49mto(DEVICE), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     31\u001b[0m metric \u001b[39m=\u001b[39m AUC()\n\u001b[1;32m     32\u001b[0m y_pred_first \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([x[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m outputs])\u001b[39m.\u001b[39mto(DEVICE)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "from torch import autograd\n",
    "from torcheval.metrics.aggregation.auc import AUC\n",
    "\n",
    "def train(model, datset):\n",
    "    LABEL_POOL = datset.LABEL_POOL\n",
    "    \n",
    "    \n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    epochs = 100\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        # with autograd.detect_anomaly():\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(datset)\n",
    "\n",
    "        # caculate loss\n",
    "        epoch_loss = criterion(outputs, torch.tensor(LABEL_POOL).to(DEVICE))\n",
    "\n",
    "        # backpropagation\n",
    "        epoch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        output_label = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        TRUE = torch.argmax(torch.tensor(LABEL_POOL).to(DEVICE), dim=1)\n",
    "\n",
    "        metric = AUC()\n",
    "        y_pred_first = torch.tensor([x[0] for x in outputs]).to(DEVICE)\n",
    "        metric.update(TRUE,y_pred_first)\n",
    "        epoch_AUC = float(metric.compute())\n",
    "\n",
    "        epoch_acc = torch.sum(output_label == torch.argmax(torch.tensor(LABEL_POOL).to(DEVICE), dim=1)).item() / len(output_label)\n",
    "\n",
    "        print(f\"Epoch{epoch+1}/{epochs} | Loss: {epoch_loss} | Acc: {epoch_acc} | AUC: {epoch_AUC}\")\n",
    "model = TransformerDecoderModel(Train_data, num_layers, embedding_dim, hidden_dim).to(DEVICE)\n",
    "train(model, Train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.Sample_embedding = nn.Linear(S_dim, embedding_dim, dtype=torch.half)\n",
    "# self.Catagory_embedding = nn.Linear(C_dim, embedding_dim, dtype=torch.half)\n",
    "# S_embedded = self.Sample_embedding(S_input.half()).unsqueeze(0)\n",
    "# C_embedded = self.Catagory_embedding(C_input.half()).unsqueeze(0)\n",
    "# xops.memory_efficient_attention(C_embedded, S_embedded, S_embedded,attn_mask)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
