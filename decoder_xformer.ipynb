{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# baic transformer Decoder model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fun\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import xformers.ops as xops\n",
    "import math\n",
    "from typing import Optional, Union\n",
    "from torch import Tensor\n",
    "import random\n",
    "\n",
    "main_df = pd.read_csv('adult.csv')\n",
    "main_df.head()\n",
    "DEVICE = 'cuda'\n",
    "# DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsou/.conda/envs/xformers/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:313: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>131</td>\n",
       "      <td>188</td>\n",
       "      <td>191</td>\n",
       "      <td>215</td>\n",
       "      <td>334</td>\n",
       "      <td>367</td>\n",
       "      <td>383</td>\n",
       "      <td>392</td>\n",
       "      <td>400</td>\n",
       "      <td>413</td>\n",
       "      <td>421</td>\n",
       "      <td>425</td>\n",
       "      <td>467</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>116</td>\n",
       "      <td>178</td>\n",
       "      <td>191</td>\n",
       "      <td>215</td>\n",
       "      <td>279</td>\n",
       "      <td>365</td>\n",
       "      <td>376</td>\n",
       "      <td>390</td>\n",
       "      <td>408</td>\n",
       "      <td>412</td>\n",
       "      <td>423</td>\n",
       "      <td>426</td>\n",
       "      <td>467</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>168</td>\n",
       "      <td>189</td>\n",
       "      <td>191</td>\n",
       "      <td>215</td>\n",
       "      <td>304</td>\n",
       "      <td>365</td>\n",
       "      <td>381</td>\n",
       "      <td>390</td>\n",
       "      <td>409</td>\n",
       "      <td>412</td>\n",
       "      <td>420</td>\n",
       "      <td>426</td>\n",
       "      <td>452</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>136</td>\n",
       "      <td>180</td>\n",
       "      <td>191</td>\n",
       "      <td>215</td>\n",
       "      <td>334</td>\n",
       "      <td>365</td>\n",
       "      <td>371</td>\n",
       "      <td>390</td>\n",
       "      <td>410</td>\n",
       "      <td>412</td>\n",
       "      <td>423</td>\n",
       "      <td>426</td>\n",
       "      <td>467</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>139</td>\n",
       "      <td>187</td>\n",
       "      <td>191</td>\n",
       "      <td>215</td>\n",
       "      <td>304</td>\n",
       "      <td>367</td>\n",
       "      <td>380</td>\n",
       "      <td>390</td>\n",
       "      <td>409</td>\n",
       "      <td>412</td>\n",
       "      <td>423</td>\n",
       "      <td>426</td>\n",
       "      <td>467</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  educational-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   16     131              188           191           215             334   \n",
       "1   62     116              178           191           215             279   \n",
       "2   16     168              189           191           215             304   \n",
       "3   19     136              180           191           215             334   \n",
       "4   29     139              187           191           215             304   \n",
       "\n",
       "   workclass  education  marital-status  occupation  relationship  race  \\\n",
       "0        367        383             392         400           413   421   \n",
       "1        365        376             390         408           412   423   \n",
       "2        365        381             390         409           412   420   \n",
       "3        365        371             390         410           412   423   \n",
       "4        367        380             390         409           412   423   \n",
       "\n",
       "   gender  native-country  income  \n",
       "0     425             467     472  \n",
       "1     426             467     471  \n",
       "2     426             452     471  \n",
       "3     426             467     471  \n",
       "4     426             467     472  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "def POOL_preprocess(df, N_BINS = 100):\n",
    "    \n",
    "    CAT = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\n",
    "    NUM = ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "    \n",
    "    num_CAT = len(CAT)\n",
    "    num_NUM = len(NUM)  \n",
    "    \n",
    "    ct = ColumnTransformer([\n",
    "        (\"age\", KBinsDiscretizer(n_bins = N_BINS, encode='ordinal', strategy='uniform', subsample=None), [\"age\"]),\n",
    "        (\"fnlwgt\", KBinsDiscretizer(n_bins = N_BINS, encode='ordinal', strategy='quantile', subsample=None), [\"fnlwgt\"]),\n",
    "        (\"educational-num\", KBinsDiscretizer(n_bins = N_BINS, encode='ordinal', strategy='quantile', subsample=None), [\"educational-num\"]),\n",
    "        (\"capital-gain\", KBinsDiscretizer(n_bins = N_BINS, encode='ordinal', strategy='uniform', subsample=None), [\"capital-gain\"]),\n",
    "        (\"capital-loss\", KBinsDiscretizer(n_bins = N_BINS, encode='ordinal', strategy='uniform', subsample=None), [\"capital-loss\"]),\n",
    "        (\"hours-per-week\", KBinsDiscretizer(n_bins = N_BINS, encode='ordinal', strategy='uniform', subsample=None), [\"hours-per-week\"]),\n",
    "         ],remainder = 'passthrough', verbose_feature_names_out = False) # make sure columns are unique\n",
    "    ct.set_output(transform = 'pandas')\n",
    "    X_trans = ct.fit_transform(df) \n",
    "    \n",
    "    # make catagoy in NUM columns unique\n",
    "    # each NUM column has N_BINS unique values, that is, each NUM column represents as N_BINS node\n",
    "    # 7/19: each NUM column has its own number of unique values, plus 1 for unseen values\n",
    "    offset = 0\n",
    "    # for column in NUM:\n",
    "    #     X_trans[column] = X_trans[column].apply(lambda x: x + offset)\n",
    "    #     # offset += N_BINS\n",
    "    #     offset += X_trans[column].nunique() + 1\n",
    "    \n",
    "    # apply lable encoding on CAT columns\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    lb = LabelEncoder()\n",
    "    X_trans[NUM] = X_trans[NUM].apply(lambda x: lb.fit_transform(x))\n",
    "    X_trans[CAT] = X_trans[CAT].apply(lambda x: lb.fit_transform(x))\n",
    "    \n",
    "    # make catagoy all columns unique\n",
    "    # each column has it's own number of unique values. '+1' is for unseen values\n",
    "    # offset = len(NUM) * N_BINS\n",
    "    for column in NUM + CAT:\n",
    "        X_trans[column] = X_trans[column].apply(lambda x: x + offset)\n",
    "        offset += (X_trans[column].max() - X_trans[column].min() + 1) + 1\n",
    "    \n",
    "    X_trans = X_trans.astype(int).reset_index(drop = True)\n",
    "    return X_trans, ct, (num_NUM, num_CAT - 1) # -1 is for the income column (label)\n",
    "X_trans, _, _= POOL_preprocess(main_df[48842//5:])\n",
    "X_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age 0 73\n",
      "fnlwgt 75 174\n",
      "educational-num 176 189\n",
      "capital-gain 191 213\n",
      "capital-loss 215 263\n",
      "hours-per-week 265 359\n",
      "workclass 361 369\n",
      "education 371 386\n",
      "marital-status 388 394\n",
      "occupation 396 410\n",
      "relationship 412 417\n",
      "race 419 423\n",
      "gender 425 426\n",
      "native-country 428 469\n",
      "income 471 472\n"
     ]
    }
   ],
   "source": [
    "for column in X_trans.columns:\n",
    "    print(column, X_trans[column].min(),X_trans[column].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data num: 48842\n",
      "trian data num: 39074\n",
      "test data num: 9768\n"
     ]
    }
   ],
   "source": [
    "train_size = 4*48842//5\n",
    "test_size = 48842//5\n",
    "train_pool = main_df[test_size:]\n",
    "test_pool = main_df[:test_size]\n",
    "print('total data num:' , main_df.shape[0])\n",
    "print('trian data num:' , train_pool.shape[0])\n",
    "print('test data num:' , test_pool.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notations\n",
    "#   node: number of all nodes = L + S + C + F\n",
    "#   L: number of lable nodes\n",
    "#   S: number of sample nodes\n",
    "#   C: number of catagory nodes\n",
    "#   F: number of field(column) nodes\n",
    "#   hidden: number of hidden representation\n",
    "\n",
    "# data size = (node, hidden)\n",
    "# mask size = (node, node - L) without lable nodes\n",
    "#             for each node, real mask = cat[mask,(node,L)] = (node, node)\n",
    "#             cannot see it's label node\n",
    "\n",
    "# use nn.transformerDecoder(data,mask) to get the output\n",
    "# use the above output as input of MLP to predict the lable   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data num: 48842\n",
      "trian data num: 39073\n",
      "test data num: 9769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsou/.conda/envs/xformers/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:313: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_nums {'L': 3, 'S': 39074, 'C': 469, 'F': 14}\n",
      "total 39560 nodes\n",
      "L_input torch.cuda.LongTensor torch.Size([3, 1])\n",
      "S_input torch.cuda.FloatTensor torch.Size([39074, 128])\n",
      "C_input torch.cuda.LongTensor torch.Size([469, 1])\n",
      "F_input torch.cuda.LongTensor torch.Size([14, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3558, 5987, 6988, 12988, 13657, 16096, 18399, 23675, 30662, 30991]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HGNN_DataSet():\n",
    "    def __init__(self,\n",
    "                 data_df : pd.DataFrame,\n",
    "                 split_ratio : float ,\n",
    "                 label_column : str,\n",
    "                 ):\n",
    "        # shuffle data\n",
    "        data_df = data_df.sample(frac=1).reset_index(drop=True)\n",
    "        test_size = math.ceil(data_df.shape[0] * (1-split_ratio))\n",
    "        train_pool = data_df[test_size:]\n",
    "        test_pool = data_df[:test_size]\n",
    "        print('total data num:' , data_df.shape[0])\n",
    "        print('trian data num:' , train_pool.shape[0])\n",
    "        print('test data num:' , test_pool.shape[0])\n",
    "        \n",
    "        # to-dos:\n",
    "        # train\n",
    "        #   \n",
    "        N_BINS = 100\n",
    "        TARGET_POOL, self.CT, self.NUM_vs_CAT = POOL_preprocess(train_pool, N_BINS = N_BINS)\n",
    "        # TEST_POOL = POOL_preprocess(test_pool)\n",
    "        LABEL_COLUMN = label_column\n",
    "\n",
    "        # cut feature and lable\n",
    "        FEATURE_POOL = TARGET_POOL.drop(LABEL_COLUMN, axis=1)\n",
    "        LABEL_POOL = TARGET_POOL[LABEL_COLUMN]\n",
    "        \n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "        enc = OneHotEncoder()\n",
    "        LABEL_POOL = enc.fit_transform(LABEL_POOL.values.reshape(-1,1)).toarray()\n",
    "\n",
    "        # L: number of lable nodes\n",
    "        # the last node of Lable nodes is served as unknown lable node\n",
    "        L = LABEL_POOL.shape[1] + 1\n",
    "\n",
    "        # S: number of sample nodes\n",
    "        S = FEATURE_POOL.shape[0] + 1\n",
    "        # the last node of sample nodes is served as infering node\n",
    "        \n",
    "        # F: number of field(column) nodes\n",
    "        F = FEATURE_POOL.shape[1]\n",
    "\n",
    "        # C: number of catagory nodes\n",
    "        # first, caculate nodes of each field, including unseen node\n",
    "        self.nodes_of_fields = []\n",
    "        for column in FEATURE_POOL.columns:\n",
    "            self.nodes_of_fields.append(FEATURE_POOL[column].nunique()+1)\n",
    "        C = sum(self.nodes_of_fields) # the total number of nodes equals to the sum of nodes of each field\n",
    "        C_POOL = range(int(C))\n",
    "\n",
    "        nodes_num = {'L':L, 'S':S, 'C':C, 'F':F}\n",
    "        print('node_nums', nodes_num)\n",
    "        print('total', L+S+C+F, 'nodes')\n",
    "        \n",
    "        # get samples index for each label\n",
    "        self.labe_to_index = {}\n",
    "        tmp_pool = TARGET_POOL.copy().reset_index(drop=True)\n",
    "        for label in tmp_pool['income'].unique():\n",
    "            self.labe_to_index[label] = (tmp_pool[tmp_pool['income'] == label].index).tolist()\n",
    "        \n",
    "        self.TARGET_POOL = TARGET_POOL\n",
    "        # self.TEST_POOL = TEST_POOL\n",
    "        self.LABEL_COLUMN = LABEL_COLUMN\n",
    "        self.FEATURE_POOL = FEATURE_POOL\n",
    "        self.LABEL_POOL = LABEL_POOL\n",
    "        self.C_POOL = C_POOL   \n",
    "        self.nodes_num = nodes_num\n",
    "        self.N_BINS = N_BINS\n",
    "\n",
    "        \n",
    "        self.make_input_tensor()\n",
    "        # self.get_sample(10)        \n",
    "        self.make_mask_all()\n",
    "        \n",
    "        # self.make_mask()\n",
    "        \n",
    "        \n",
    "    def make_mask(self,\n",
    "                  sample_indices: Optional[list] = None,\n",
    "                ):\n",
    "        L, S, C, F = self.nodes_num['L'], self.nodes_num['S'], self.nodes_num['C'], self.nodes_num['F']\n",
    "\n",
    "        sample_size = len(sample_indices)\n",
    "        masked_POOL = self.TARGET_POOL.iloc[sample_indices]\n",
    "        # caculate masking\n",
    "        masks = {}\n",
    "\n",
    "        # label to sample \n",
    "        tmp = torch.zeros([math.ceil(sample_size/8) * 8, math.ceil(L/8) * 8], dtype=torch.float, device=DEVICE)\n",
    "        label_ids = self.TARGET_POOL[self.LABEL_COLUMN].unique()\n",
    "        for i, value_df in enumerate(masked_POOL[self.LABEL_COLUMN]):\n",
    "            for j, value_label in enumerate(label_ids):\n",
    "                if value_label == value_df:\n",
    "                    tmp[i][j] = 1\n",
    "                    break\n",
    "        masks['L2S'] = Tensor.contiguous(tmp)\n",
    "\n",
    "        # sample to catagory\n",
    "        tmp = torch.zeros([math.ceil(C/8) * 8, math.ceil(sample_size/8) * 8], dtype=torch.float, device=DEVICE).T\n",
    "        tmp_df = masked_POOL.drop(self.LABEL_COLUMN, axis=1)\n",
    "        tmp[torch.arange(sample_size).unsqueeze(-1), torch.tensor(tmp_df.values)] = 1\n",
    "        tmp = tmp.T.contiguous()\n",
    "        \n",
    "        # tmp = (S, C)\n",
    "        # df = (S, col) \n",
    "        #\n",
    "        # [\n",
    "        #   [10, 20, 25, ...]\n",
    "        #   [10, 20, 25, ...]\n",
    "        # ]\n",
    "        \n",
    "        # indexes = [....]\n",
    "        # CC[indexes] = 1\n",
    "        \n",
    "        # tmp[torch.arange(S).unsqueeze(-1), torch.tensor(df.values)] = 1\n",
    "        \n",
    "                \n",
    "        masks['S2C'] = Tensor.contiguous(tmp)\n",
    "\n",
    "        # catagory to field\n",
    "        masks['C2F'] = self.MASKS_FULL['C2F']\n",
    "        \n",
    "        self.MASKS = masks\n",
    "        self.nodes_num['K'] = sample_size\n",
    "        \n",
    "    def make_mask_all(self,\n",
    "                  sample_indices: Optional[torch.tensor] = None,\n",
    "                ):\n",
    "        L, S, C, F = self.nodes_num['L'], self.nodes_num['S'], self.nodes_num['C'], self.nodes_num['F']\n",
    "        # caculate masking\n",
    "        masks = {}\n",
    "        \n",
    "        # label to sample \n",
    "        tmp = torch.zeros([math.ceil(S/8) * 8, math.ceil(L/8) * 8], dtype=torch.float, device=DEVICE)\n",
    "        label_ids = self.TARGET_POOL[self.LABEL_COLUMN].unique()\n",
    "        for i, value_df in enumerate(self.TARGET_POOL[self.LABEL_COLUMN]):\n",
    "            for j, value_label in enumerate(label_ids):\n",
    "                if value_label == value_df:\n",
    "                    tmp[i][j] = 1\n",
    "                    break\n",
    "        masks['L2S'] = tmp\n",
    "\n",
    "        # sample to catagory\n",
    "        tmp = torch.zeros([math.ceil(C/8) * 8, math.ceil(S/8) * 8], dtype=torch.float, device=DEVICE).T\n",
    "        tmp_df = self.TARGET_POOL.drop(self.LABEL_COLUMN, axis=1)\n",
    "        # for i, value_df in enumerate(tmp_df.values):\n",
    "        #     for j, value in enumerate(value_df):\n",
    "        #         tmp[value][i] = 1\n",
    "        tmp[torch.arange(len(self.TARGET_POOL)).unsqueeze(-1), torch.tensor(tmp_df.values)] = 1\n",
    "        tmp = tmp.T.contiguous()\n",
    "        masks['S2C'] = tmp\n",
    "\n",
    "        # catagory to field\n",
    "        tmp = torch.zeros([math.ceil(F/8) * 8, math.ceil(C/8) * 8], dtype=torch.float, device=DEVICE)\n",
    "        unique_items = [sorted(self.FEATURE_POOL[column].unique()) for column in (self.FEATURE_POOL.columns)]\n",
    "        for i in range(F):\n",
    "            for j in (unique_items[i]):\n",
    "                tmp[i][j] = 1\n",
    "        masks['C2F'] = tmp\n",
    "        \n",
    "        \n",
    "        self.MASKS = masks\n",
    "        self.MASKS_FULL = masks\n",
    "\n",
    "    \n",
    "    def make_input_tensor(self):\n",
    "        # make input tensor\n",
    "        L, S, C, F = self.nodes_num['L'], self.nodes_num['S'], self.nodes_num['C'], self.nodes_num['F']\n",
    "        # L\n",
    "        L_input = torch.tensor([range(L)], device=DEVICE).reshape(-1,1)\n",
    "        print('L_input', L_input.type(), L_input.shape)\n",
    "        \n",
    "        # S (normalized by standard scaler)\n",
    "        # features = torch.tensor(self.FEATURE_POOL.values, device=DEVICE).float()\n",
    "        # normalized_features = (features - torch.mean(features, dim = 0)) / torch.std(features, dim = 0)\n",
    "        # S_input = torch.cat([normalized_features, torch.tensor([[0]*F], device=DEVICE)],dim = 0).float() # add infering node\n",
    "        \n",
    "        # S (initialize by random)\n",
    "        S_input = torch.rand(128, device=DEVICE).repeat(S,1)\n",
    "        \n",
    "        print('S_input', S_input.type(), S_input.shape)\n",
    "        # C \n",
    "        C_input = torch.tensor([self.C_POOL], device=DEVICE).reshape(-1,1)\n",
    "        print('C_input', C_input.type(), C_input.shape)\n",
    "        # F \n",
    "        F_input = torch.tensor([range(F)], device=DEVICE).reshape(-1,1)\n",
    "        print('F_input', F_input.type(), F_input.shape)\n",
    "        # \n",
    "        self.INPUTS = (L_input, S_input, C_input, F_input)\n",
    "        self.INPUT_DIMS = (L_input.size(1), S_input.size(1), C_input.size(1), F_input.size(1))\n",
    "        \n",
    "    def sample_with_distrubution(self, sample_size):\n",
    "        # sample with distrubution\n",
    "        \"\"\"\n",
    "        currently, only support binary label\n",
    "        forced to make balenced sample\n",
    "        \"\"\"\n",
    "        \n",
    "        # decide each label's number of samples (fourced to be balenced if possible) \n",
    "        label_list = []\n",
    "        label_unique = list(self.labe_to_index.keys())\n",
    "        count = sample_size // len(label_unique)\n",
    "        remainder = sample_size % len(label_unique)\n",
    "        label_list = [item for item in label_unique for _ in range(count)]\n",
    "        label_list.extend(random.sample(label_unique, remainder))\n",
    "        # sample from indexes\n",
    "        indices = [random.choice(self.labe_to_index[label]) for label in label_list]\n",
    "        return indices     \n",
    "        \n",
    "    def get_sample(self, sample_size, inculde = []):\n",
    "        # get K samples from S\n",
    "        # return sample node indices\n",
    "        \n",
    "        # inculde specific nodes (e.g. query nodes), while remaining sample_size\n",
    "        sample_indices = self.sample_with_distrubution(sample_size - len(inculde))\n",
    "        if inculde is not []:\n",
    "            while inculde in sample_indices:\n",
    "                sample_indices = self.sample_with_distrubution(sample_size - len(inculde))\n",
    "            # add inculde nodes into sample_indices\n",
    "            for node in inculde:\n",
    "                sample_indices.append(node)\n",
    "            sample_indices = sorted(sample_indices)\n",
    "        # 作傻事\n",
    "        # sample_indices = [random.choice(Train_data.labe_to_index[472]) for i in range(sample_size-1)]\n",
    "        # sample_indices.append(inculde[0])\n",
    "        # update mask\n",
    "        sample_indices = sorted(sample_indices)\n",
    "        self.make_mask(sample_indices)\n",
    "        \n",
    "        # modify input tensor\n",
    "        L_input, S_input, C_input, F_input = self.INPUTS\n",
    "        S_input_masked = torch.index_select(S_input, 0, torch.tensor(sample_indices, device=DEVICE))\n",
    "        self.MASKED_INPUTS = (L_input, S_input_masked, C_input, F_input) \n",
    "          \n",
    "        return sample_indices\n",
    "            \n",
    "Train_data = HGNN_DataSet( main_df, 0.8, 'income')\n",
    "Train_data.get_sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_data.INPUTS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9337, 0.3869, 0.0326,  ..., 0.0852, 0.7448, 0.8449],\n",
       "        [0.9337, 0.3869, 0.0326,  ..., 0.0852, 0.7448, 0.8449],\n",
       "        [0.9337, 0.3869, 0.0326,  ..., 0.0852, 0.7448, 0.8449],\n",
       "        ...,\n",
       "        [0.9337, 0.3869, 0.0326,  ..., 0.0852, 0.7448, 0.8449],\n",
       "        [0.9337, 0.3869, 0.0326,  ..., 0.0852, 0.7448, 0.8449],\n",
       "        [0.9337, 0.3869, 0.0326,  ..., 0.0852, 0.7448, 0.8449]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_data.INPUTS[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_data.get_sample(100, inculde=[10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from typing import Optional, Any, Union, Callable\n",
    "\n",
    "class CustomTransformerDecoderLayer(nn.TransformerDecoderLayer):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, activation='relu'):\n",
    "        super().__init__(d_model, nhead, dim_feedforward, dropout, activation)\n",
    "        # remove defined modules\n",
    "        delattr(self, 'self_attn')\n",
    "        delattr(self, 'norm1')\n",
    "        delattr(self, 'dropout1')\n",
    "    \n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        x = tgt\n",
    "        # x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))\n",
    "        x = self.norm2(x + self._mha_block(x, memory, memory_mask))\n",
    "        # x =  x + self._mha_block(x, memory, memory_mask, memory_key_padding_mask)\n",
    "        # x = self.norm3(x + self._ff_block(x))\n",
    "\n",
    "        return x\n",
    "    def _mha_block(self, x: Tensor, mem: Tensor,\n",
    "                   attn_mask: Optional[Tensor],) -> Tensor:\n",
    "        x = xops.memory_efficient_attention(x, mem, mem, attn_mask)\n",
    "        # return self.dropout2(x)\n",
    "        return (x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dims (1, 128, 1, 1)\n",
      "tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]], device='cuda:0')\n",
      "tensor([[0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]], device='cuda:0')\n",
      "模型輸出的大小: torch.Size([4, 2])\n",
      "tensor([[0.1315, 0.4751],\n",
      "        [0.1654, 0.2339],\n",
      "        [0.2044, 0.5912],\n",
      "        [0.2001, 0.5755]], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baic transformer decoder model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fun\n",
    "from tqdm import trange\n",
    "\n",
    "class TransformerDecoderModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 target_dataset, \n",
    "                 num_layers, \n",
    "                 embedding_dim,  \n",
    "                 subgraph_masked: Optional[bool] = False,\n",
    "                 K : Optional[int] = 10,\n",
    "                 ):\n",
    "        super(TransformerDecoderModel, self).__init__()\n",
    "\n",
    "        L_dim, S_dim, C_dim, F_dim = target_dataset.INPUT_DIMS\n",
    "        L, S, C, F = target_dataset.nodes_num['L'], target_dataset.nodes_num['S'], target_dataset.nodes_num['C'], target_dataset.nodes_num['F']\n",
    "        num_NUM , num_CAT = target_dataset.NUM_vs_CAT\n",
    "        \n",
    "        # check input dims\n",
    "        # if num_CAT + num_NUM != S_dim:\n",
    "        #     raise ValueError('num_CAT + num_NUM != number of columns (S_dim)   {} + {} != {}'.format(num_CAT, num_NUM, S_dim))\n",
    "        \n",
    "        # 目前b卡在embedding的怎麼用\n",
    "        # Catagory_embedding => 數值類Qcut後用linear來做embedding, 類別用nn.Embedding\n",
    "\n",
    "        \n",
    "        # nn.Embedding( number of possible catagories, embedding_dim, )\n",
    "        # nn.Linear( number of input dimantion, embedding_dim, )\n",
    "\n",
    "        self.Lable_embedding = nn.Embedding(L, embedding_dim, dtype=torch.float)\n",
    "        \n",
    "        # self.Sample_embedding_num = nn.Linear(num_NUM, embedding_dim, dtype=torch.float)\n",
    "        # # use MLP projector to project sample feature from 8 dim to 128 dim\n",
    "        # # self.Sample_embedding_cat = nn.Linear(num_CAT, embedding_dim, dtype=torch.float)\n",
    "        # self.Sample_embedding_cat = nn.Sequential(\n",
    "        #                                 nn.Linear(num_CAT, 64),  \n",
    "        #                                 nn.ReLU(),        \n",
    "        #                                 nn.Linear(64, embedding_dim) \n",
    "        #                             )\n",
    "                                    \n",
    "        \n",
    "        # self.Catagory_embedding_num = nn.Linear(C_dim, embedding_dim, dtype=torch.float)\n",
    "        # for every numrical filed, construct it's own Linear embedding layer\n",
    "        self.Catagory_embedding_nums = []\n",
    "        for i in range(num_NUM):\n",
    "            self.Catagory_embedding_nums.append(\n",
    "                nn.Linear(C_dim, embedding_dim, dtype=torch.float, device=DEVICE)\n",
    "            )\n",
    "        catagories = target_dataset.nodes_of_fields[-num_CAT:] # number of all possible catagories nodes\n",
    "        self.Catagory_embedding_cat = nn.Embedding(sum(catagories), embedding_dim, dtype=torch.float)\n",
    "        \n",
    "        self.Field_embedding = nn.Embedding(F, embedding_dim, dtype=torch.float)\n",
    "        \n",
    "        self.transformer_decoder = nn.TransformerDecoder(\n",
    "            CustomTransformerDecoderLayer(embedding_dim,  nhead = 2 ),\n",
    "            num_layers\n",
    "        )\n",
    "        \n",
    "        # downstream task\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 2),\n",
    "        )\n",
    "        \n",
    "        self.subgraph_masked = subgraph_masked\n",
    "        if subgraph_masked: \n",
    "            self.K = K\n",
    "            target_dataset.get_sample(self.K)\n",
    "        else:\n",
    "            # init mask\n",
    "            target_dataset.make_mask_all()\n",
    "        \n",
    "        self.tmpmask_L2S = target_dataset.MASKS['L2S'].clone()\n",
    "\n",
    "\n",
    "    def forward(self, \n",
    "                target_dataset: HGNN_DataSet, \n",
    "                ):\n",
    "        L, S, C, F = target_dataset.nodes_num['L'], target_dataset.nodes_num['S'], target_dataset.nodes_num['C'], target_dataset.nodes_num['F']\n",
    "        num_NUM, num_CAT = target_dataset.NUM_vs_CAT\n",
    "        \n",
    "        if self.subgraph_masked: \n",
    "            # sample K nodes from S to construct subgraph\n",
    "            # target_dataset.get_sample(self.K)  ==> do not do this again!!! for every query, only one \"get_sample\" is needed\n",
    "            L_input, S_input, C_input, F_input = target_dataset.MASKED_INPUTS\n",
    "            masks = target_dataset.MASKS\n",
    "            # K = target_dataset.nodes_num['K'] \n",
    "            S_ = self.K\n",
    "        else:\n",
    "            # to-do: this could make model slow\n",
    "            target_dataset.make_input_tensor()\n",
    "            L_input, S_input, C_input, F_input = target_dataset.INPUTS\n",
    "            target_dataset.make_mask_all()\n",
    "            masks = target_dataset.MASKS\n",
    "            S_ = S\n",
    "\n",
    "        # for S and C, we use two different embedding methods, for CAT and NUM, respectively\n",
    "        # Squeeze for making batch dimantion\n",
    "        L_embedded = self.Lable_embedding(L_input.long()).squeeze(1).unsqueeze(0).float()\n",
    "        \n",
    "        S_embedded = S_input.unsqueeze(0).float()\n",
    "\n",
    "\n",
    "\n",
    "        # for every numrical filed, use it's own Linear embedding layer\n",
    "        C_embedded_nums = []\n",
    "        field = target_dataset.nodes_of_fields\n",
    "        start = 0\n",
    "        for index, nodes in enumerate(field[:num_NUM]): # pick numrical fields\n",
    "            end = start + nodes\n",
    "            C_embedded_nums.append(self.Catagory_embedding_nums[index](C_input[start:end].float()).unsqueeze(0))\n",
    "            start = end\n",
    "        C_embedded_num = torch.cat(C_embedded_nums, dim = 1)\n",
    "        \n",
    "        catagorical_filed_nodes = sum(field[-num_CAT:]) # pick catagory fields\n",
    "        C_embedded_cat = self.Catagory_embedding_cat(C_input[-catagorical_filed_nodes:].squeeze(1).long() - sum(field[:num_NUM])).unsqueeze(0).float() # - sum(field[:num_NUM] because the embedding index should start from 0\n",
    "        C_embedded = torch.cat([C_embedded_num, C_embedded_cat], dim = 1)\n",
    "        \n",
    "        F_embedded = self.Field_embedding(F_input.long()).squeeze(1).unsqueeze(0).float()\n",
    "        \n",
    "        # print(L_embedded.shape, S_embedded.shape, C_embedded.shape, F_embedded.shape)\n",
    "        \n",
    "        \n",
    "        # propagate steps: L→S→C→F\n",
    "        #                  L←S←C←\n",
    "        # more steps more menory usage\n",
    "        PROPAGATE_STEPS = 1\n",
    "        for i in range(PROPAGATE_STEPS):\n",
    "            S_embedded = self.transformer_decoder(S_embedded,L_embedded, \n",
    "                                                memory_mask = self.tmpmask_L2S[:S_,:L]) \n",
    "            C_embedded = self.transformer_decoder(C_embedded,S_embedded,\n",
    "                                                memory_mask = masks['S2C'][:C,:S_])\n",
    "            F_embedded = self.transformer_decoder(F_embedded,C_embedded,\n",
    "                                                memory_mask = masks['C2F'][:F,:C])\n",
    "            C_embedded = self.transformer_decoder(C_embedded,F_embedded,\n",
    "                                                memory_mask = Tensor.contiguous(masks['C2F'].transpose(0, 1))[:C,:F])\n",
    "            S_embedded = self.transformer_decoder(S_embedded,C_embedded,\n",
    "                                                memory_mask = Tensor.contiguous(masks['S2C'].transpose(0, 1))[:S_,:C])\n",
    "            L_embedded = self.transformer_decoder(L_embedded,S_embedded, \n",
    "                                                memory_mask = Tensor.contiguous(self.tmpmask_L2S.transpose(0, 1))[:L,:S_])\n",
    "        \n",
    "        # print('after',S_embedded[0][0])\n",
    "        output = self.MLP(S_embedded)[0]\n",
    "        return output\n",
    "\n",
    "# 測試模型\n",
    "num_layers = 1  # TransformerDecoder 的層數\n",
    "embedding_dim = 128  # 嵌入維度\n",
    "hidden_dim = 64  \n",
    "\n",
    "print('input_dims', Train_data.INPUT_DIMS)\n",
    "model = TransformerDecoderModel(Train_data, num_layers, embedding_dim, subgraph_masked = True, K = 4).to(DEVICE)\n",
    "\n",
    "model.tmpmask_L2S = Train_data.MASKS['L2S'].clone().detach()\n",
    "model.tmpmask_L2S[0] = 0\n",
    "model.tmpmask_L2S[0][3-1] = 1 # make it as unseen label\n",
    "print(Train_data.MASKS['L2S'][:4,:3])\n",
    "print(model.tmpmask_L2S[:4,:3])\n",
    "\n",
    "outputs = model(Train_data)\n",
    "print(\"模型輸出的大小:\", outputs.shape)\n",
    "print(outputs)\n",
    "output_label = torch.argmax(outputs.softmax(dim=0), dim=1)\n",
    "output_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 20,  40,  90,  80, 150])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = torch.tensor([1,2,3])\n",
    "mask = torch.tensor([[1,0,0],\n",
    "                     [1,0,0],\n",
    "                     [0,1,0],\n",
    "                     [1,0,0],\n",
    "                     [0,1,0],])\n",
    "sample = torch.tensor([10,20,30,40,50])\n",
    "\n",
    "selected_labels = torch.zeros(mask.size(0), dtype=label.dtype)\n",
    "for i in range(mask.size(0)):\n",
    "    selected_labels[i] = label[mask[i].nonzero(as_tuple=True)]\n",
    "\n",
    "selected_labels * sample + sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_data.TARGET_POOL.iloc[3].income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/39073 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:13, 153.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1/200 | Loss: 0.28683856694446436 | AUC: 0.5248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:14, 152.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch2/200 | Loss: 0.29349579961227923 | AUC: 0.4789333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:13, 153.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch3/200 | Loss: 0.2919294123704047 | AUC: 0.48213333333333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:16, 151.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch4/200 | Loss: 0.29096007746775676 | AUC: 0.47946666666666665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch5/200 | Loss: 0.2900575534691795 | AUC: 0.48533333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch6/200 | Loss: 0.28924141981643936 | AUC: 0.4826666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 155.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch7/200 | Loss: 0.28847795026465817 | AUC: 0.4848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch8/200 | Loss: 0.28776142783500164 | AUC: 0.48533333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 155.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch9/200 | Loss: 0.2870583297120006 | AUC: 0.4864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 154.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch10/200 | Loss: 0.28639797562979286 | AUC: 0.48693333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 155.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch11/200 | Loss: 0.28576090812873334 | AUC: 0.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 155.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch12/200 | Loss: 0.2851114653027429 | AUC: 0.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 154.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch13/200 | Loss: 0.28443904378295226 | AUC: 0.4885333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 154.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch14/200 | Loss: 0.28373539816145465 | AUC: 0.49066666666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch15/200 | Loss: 0.28297354228541244 | AUC: 0.4912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 155.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch16/200 | Loss: 0.2821405607230825 | AUC: 0.49173333333333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch17/200 | Loss: 0.281143322139789 | AUC: 0.4997333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch18/200 | Loss: 0.2799079241071466 | AUC: 0.5082666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 154.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch19/200 | Loss: 0.27830691034649757 | AUC: 0.5168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch20/200 | Loss: 0.27613922613356245 | AUC: 0.5306666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 154.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch21/200 | Loss: 0.2731367764505186 | AUC: 0.5493333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch22/200 | Loss: 0.26896071583231435 | AUC: 0.5754666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch23/200 | Loss: 0.2636894523695162 | AUC: 0.6048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch24/200 | Loss: 0.25742776873392154 | AUC: 0.6282666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch25/200 | Loss: 0.2507428414968493 | AUC: 0.656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch26/200 | Loss: 0.24427942997719693 | AUC: 0.6757333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch27/200 | Loss: 0.2389157927685116 | AUC: 0.696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch28/200 | Loss: 0.23518887339876668 | AUC: 0.7178666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 155.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch29/200 | Loss: 0.23263197098907726 | AUC: 0.7333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 155.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch30/200 | Loss: 0.23158255641743913 | AUC: 0.7445333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 155.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch31/200 | Loss: 0.23000230870732355 | AUC: 0.7482666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 155.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch32/200 | Loss: 0.2286991601818333 | AUC: 0.7514666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:13, 153.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch33/200 | Loss: 0.22799840142729116 | AUC: 0.7536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch34/200 | Loss: 0.22688818104576822 | AUC: 0.7552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 154.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch35/200 | Loss: 0.22608810481410513 | AUC: 0.752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:13, 153.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch36/200 | Loss: 0.2249289128541303 | AUC: 0.7578666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch37/200 | Loss: 0.22482109662950855 | AUC: 0.7552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 154.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch38/200 | Loss: 0.22355513744756805 | AUC: 0.7589333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 155.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch39/200 | Loss: 0.22291516233246134 | AUC: 0.7594666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 154.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch40/200 | Loss: 0.22245786409490959 | AUC: 0.7610666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch41/200 | Loss: 0.22154759016188097 | AUC: 0.7626666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:13, 153.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch42/200 | Loss: 0.22077012880715097 | AUC: 0.7653333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch43/200 | Loss: 0.2200330264542053 | AUC: 0.7706666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch44/200 | Loss: 0.2196869806638366 | AUC: 0.7717333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch45/200 | Loss: 0.21879655060194034 | AUC: 0.7744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:20, 149.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch46/200 | Loss: 0.21821582780953525 | AUC: 0.7754666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch47/200 | Loss: 0.21775266498083468 | AUC: 0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch48/200 | Loss: 0.2165066909221089 | AUC: 0.7802666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:15, 152.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch49/200 | Loss: 0.21580638183617404 | AUC: 0.7786666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch50/200 | Loss: 0.21524004492950952 | AUC: 0.7818666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 154.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch51/200 | Loss: 0.21414893896688716 | AUC: 0.7856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:13, 153.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch52/200 | Loss: 0.2136507592313025 | AUC: 0.7856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch53/200 | Loss: 0.21284312582290923 | AUC: 0.7893333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:14, 153.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch54/200 | Loss: 0.21184995829424863 | AUC: 0.7952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch55/200 | Loss: 0.21161295227686366 | AUC: 0.7957333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 155.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch56/200 | Loss: 0.21084616654462338 | AUC: 0.7968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 154.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch57/200 | Loss: 0.2097880340890335 | AUC: 0.7984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch58/200 | Loss: 0.20903620147965765 | AUC: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 154.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch59/200 | Loss: 0.20821430696789306 | AUC: 0.8005333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch60/200 | Loss: 0.20700468991930218 | AUC: 0.8032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 154.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch61/200 | Loss: 0.2066102815097024 | AUC: 0.8021333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch62/200 | Loss: 0.20571557536970822 | AUC: 0.8048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch63/200 | Loss: 0.20507270071722147 | AUC: 0.8069333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch64/200 | Loss: 0.20417434931850373 | AUC: 0.8085333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 155.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch65/200 | Loss: 0.20368685031693842 | AUC: 0.8090666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 154.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch66/200 | Loss: 0.2024641288796466 | AUC: 0.8122666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 155.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch67/200 | Loss: 0.20171181482283498 | AUC: 0.8133333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 155.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch68/200 | Loss: 0.20094418910403714 | AUC: 0.8128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch69/200 | Loss: 0.20034800351085721 | AUC: 0.8144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch70/200 | Loss: 0.19888190475778159 | AUC: 0.8202666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch71/200 | Loss: 0.1982125828077742 | AUC: 0.8208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 154.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch72/200 | Loss: 0.1974372229454415 | AUC: 0.8229333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:13, 153.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch73/200 | Loss: 0.19690337425028262 | AUC: 0.8245333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:13, 154.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch74/200 | Loss: 0.19584034243724296 | AUC: 0.8272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch75/200 | Loss: 0.1949257856652315 | AUC: 0.8256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 155.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch76/200 | Loss: 0.19447841560927348 | AUC: 0.8266666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch77/200 | Loss: 0.19282488977809856 | AUC: 0.8304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch78/200 | Loss: 0.1926114462219818 | AUC: 0.8325333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch79/200 | Loss: 0.1917529962394931 | AUC: 0.8314666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:14, 152.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch80/200 | Loss: 0.19062570352622887 | AUC: 0.8362666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch81/200 | Loss: 0.18978805494759868 | AUC: 0.8352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch82/200 | Loss: 0.18924601127926033 | AUC: 0.8384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 155.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch83/200 | Loss: 0.18853630515091005 | AUC: 0.8378666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:13, 153.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch84/200 | Loss: 0.1879543179730766 | AUC: 0.8416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch85/200 | Loss: 0.1870133129172911 | AUC: 0.8437333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 155.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch86/200 | Loss: 0.18605183486097077 | AUC: 0.8442666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch87/200 | Loss: 0.18540271080045606 | AUC: 0.8453333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:14, 152.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch88/200 | Loss: 0.18509084882224358 | AUC: 0.8448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch89/200 | Loss: 0.18408133281147254 | AUC: 0.8474666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch90/200 | Loss: 0.1833594299615968 | AUC: 0.8442666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 154.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch91/200 | Loss: 0.18268849343553328 | AUC: 0.8485333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 155.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch92/200 | Loss: 0.1822868148701145 | AUC: 0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch93/200 | Loss: 0.1812879629696231 | AUC: 0.8506666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:13, 153.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch94/200 | Loss: 0.18069978161022449 | AUC: 0.8512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:09, 155.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch95/200 | Loss: 0.18003381265172652 | AUC: 0.8517333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:12, 154.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch96/200 | Loss: 0.17939729569167176 | AUC: 0.8544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:13, 153.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch97/200 | Loss: 0.17883666554103328 | AUC: 0.8538666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:10, 155.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch98/200 | Loss: 0.177765989466783 | AUC: 0.8549333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 154.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch99/200 | Loss: 0.1773979331692229 | AUC: 0.8592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 154.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch100/200 | Loss: 0.1764539590841573 | AUC: 0.8602666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:11, 155.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch101/200 | Loss: 0.17610790673472054 | AUC: 0.8624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/39073 [00:00<04:13, 153.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch102/200 | Loss: 0.1747445955772899 | AUC: 0.8634666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 55/39073 [00:00<04:11, 154.84it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 99\u001b[0m\n\u001b[1;32m     96\u001b[0m             f\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m | Loss: \u001b[39m\u001b[39m{\u001b[39;00mepoch_loss\u001b[39m}\u001b[39;00m\u001b[39m | AUC: \u001b[39m\u001b[39m{\u001b[39;00mepoch_AUC\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     98\u001b[0m model \u001b[39m=\u001b[39m TransformerDecoderModel(Train_data, num_layers, embedding_dim, subgraph_masked \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, K \u001b[39m=\u001b[39m \u001b[39m200\u001b[39m)\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[0;32m---> 99\u001b[0m train(model, Train_data)\n",
      "Cell \u001b[0;32mIn[18], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, datset)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39miter\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m trange(\u001b[39mlen\u001b[39m(datset\u001b[39m.\u001b[39mFEATURE_POOL)): \u001b[39m# query through all sample nodes (not infering node)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[39m# for all query, input = sample K + 1 query smaple\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     sample_indices \u001b[39m=\u001b[39m datset\u001b[39m.\u001b[39;49mget_sample(model\u001b[39m.\u001b[39;49mK, inculde \u001b[39m=\u001b[39;49m [index])\n\u001b[1;32m     27\u001b[0m     \u001b[39m# modify the mask to mask out the queries node's edge to it's label node\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     L \u001b[39m=\u001b[39m datset\u001b[39m.\u001b[39mnodes_num[\u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[8], line 232\u001b[0m, in \u001b[0;36mHGNN_DataSet.get_sample\u001b[0;34m(self, sample_size, inculde)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39m# modify input tensor\u001b[39;00m\n\u001b[1;32m    231\u001b[0m L_input, S_input, C_input, F_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mINPUTS\n\u001b[0;32m--> 232\u001b[0m S_input_masked \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mindex_select(S_input, \u001b[39m0\u001b[39;49m, torch\u001b[39m.\u001b[39;49mtensor(sample_indices, device\u001b[39m=\u001b[39;49mDEVICE))\n\u001b[1;32m    233\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMASKED_INPUTS \u001b[39m=\u001b[39m (L_input, S_input_masked, C_input, F_input) \n\u001b[1;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m sample_indices\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "from torch import autograd\n",
    "from torcheval.metrics.aggregation.auc import AUC\n",
    "from torcheval.metrics import BinaryAUROC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "tmp_log = []\n",
    "tmp__log = []\n",
    "def train(model, datset):\n",
    "    LABEL_POOL = datset.LABEL_POOL\n",
    "    weight=torch.from_numpy(np.array([0.2, 1])).float().to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss(weight)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    epochs = 200\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # train\n",
    "        model.train()\n",
    "        # logs\n",
    "        loss_log = []\n",
    "        AUC_metric = BinaryAUROC().to(DEVICE)\n",
    "        \n",
    "        iter = 0\n",
    "        for index in trange(len(datset.FEATURE_POOL)): # query through all sample nodes (not infering node)\n",
    "            # for all query, input = sample K + 1 query smaple\n",
    "            sample_indices = datset.get_sample(model.K, inculde = [index])\n",
    "            \n",
    "            # modify the mask to mask out the queries node's edge to it's label node\n",
    "            L = datset.nodes_num['L']\n",
    "            query_index = sample_indices.index(index) # query_index: index of query node in sample_indices\n",
    "            model.tmpmask_L2S = datset.MASKS['L2S'].clone().detach()\n",
    "            model.tmpmask_L2S[query_index] = 0\n",
    "            model.tmpmask_L2S[query_index][L-1] = 1 # make it as unseen label\n",
    "\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(datset)\n",
    "            \n",
    "                \n",
    "            outputs = outputs[query_index]\n",
    "            # for trainning, only the query node's output is used\n",
    "            # caculate loss\n",
    "            if model.subgraph_masked:\n",
    "                # get the real label fo query node\n",
    "                LABEL_POOL_ = LABEL_POOL[index]\n",
    "            else:\n",
    "                LABEL_POOL_ = LABEL_POOL\n",
    "            \n",
    "            # print((LABEL_POOL_),Train_data.TARGET_POOL.iloc[index].income - 471)\n",
    "            # caculate loss\n",
    "            batch_loss = criterion(outputs, torch.tensor(LABEL_POOL_,device=DEVICE))\n",
    "            loss_log.append(batch_loss.item())\n",
    "            \n",
    "            # backpropagation\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            TRUE = (torch.argmax(torch.tensor(LABEL_POOL_,device=DEVICE)))\n",
    "            \n",
    "            outputs = outputs.softmax(dim=0)\n",
    "            pred_prob_of_is_1 = outputs[1] # the probability of the query node is 1 (from model output)\n",
    "            \n",
    "            \n",
    "            # tmp_log.append(float(pred_prob_of_is_1))\n",
    "            # tmp__log.append((TRUE))\n",
    "            \n",
    "            AUC_metric.update(torch.Tensor([pred_prob_of_is_1]),torch.Tensor([TRUE]))\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            iter += 1\n",
    "            if iter >= 100:\n",
    "                break\n",
    "        # print('1 rate pre:',sum(tmp_log)/len(tmp_log),len(tmp_log))\n",
    "        # print('1 rate tru:',float(sum(tmp__log)/len(tmp__log)),len(tmp__log))\n",
    "        # print(tmp__log)\n",
    "        # print(TRUE)\n",
    "        # print(float(AUC_metric.compute()))\n",
    "        # AUC_metric.reset()\n",
    "        # AUC_metric.update(torch.Tensor(tmp_log),torch.Tensor(tmp__log))\n",
    "        # print(float(AUC_metric.compute()))\n",
    "        \n",
    "        \n",
    "\n",
    "        epoch_loss = sum(loss_log) / len(loss_log)\n",
    "        epoch_AUC = float(AUC_metric.compute()) \n",
    "\n",
    "        AUC_metric.reset()\n",
    "        # break\n",
    "        del loss_log, AUC_metric\n",
    "        tmp_log.append(float(epoch_loss))\n",
    "        tmp__log.append(float(epoch_AUC))\n",
    "        \n",
    "        print(f\"Epoch{epoch+1}/{epochs} | Loss: {epoch_loss} | AUC: {epoch_AUC}\")\n",
    "        \n",
    "        \n",
    "        with open('logs/log.txt', 'a') as f:\n",
    "            f.write(f\"Epoch{epoch+1}/{epochs} | Loss: {epoch_loss} | AUC: {epoch_AUC}\\n\")\n",
    "\n",
    "model = TransformerDecoderModel(Train_data, num_layers, embedding_dim, subgraph_masked = True, K = 200).to(DEVICE)\n",
    "train(model, Train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(tmp_log)\n",
    "plt.plot(tmp__log)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5]) torch.Size([3, 5])\n",
      "tensor([[ 0.5443,  0.3086,  0.7909,  0.6841,  0.5280],\n",
      "        [-2.2931,  0.9872, -0.0502, -0.1197,  0.3200],\n",
      "        [ 1.1290,  1.6344, -1.9714,  0.4158,  1.1178]], requires_grad=True)\n",
      "tensor([[0.6052, 0.0118, 0.0234, 0.2101, 0.1495],\n",
      "        [0.1090, 0.4449, 0.0584, 0.1606, 0.2271],\n",
      "        [0.0216, 0.3409, 0.1344, 0.3297, 0.1734]])\n",
      "1.694624423980713\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "print(input.shape, target.shape)\n",
    "print(input)\n",
    "print(target)\n",
    "output = loss(input, target)\n",
    "print(output.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
