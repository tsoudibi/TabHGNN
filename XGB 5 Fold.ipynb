{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# baic transformer Decoder model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fun\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import xformers.ops as xops\n",
    "import math \n",
    "from typing import Optional, Union\n",
    "from torch import Tensor\n",
    "import random\n",
    "\n",
    "main_df = pd.read_csv('adult.csv')\n",
    "main_df.head()\n",
    "DEVICE = 'cuda'\n",
    "# DEVICE = 'cpu'\n",
    "torch.random.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsou/.conda/envs/xformers/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:313: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>146</td>\n",
       "      <td>181</td>\n",
       "      <td>191</td>\n",
       "      <td>215</td>\n",
       "      <td>304</td>\n",
       "      <td>366</td>\n",
       "      <td>373</td>\n",
       "      <td>393</td>\n",
       "      <td>404</td>\n",
       "      <td>416</td>\n",
       "      <td>422</td>\n",
       "      <td>427</td>\n",
       "      <td>468</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>89</td>\n",
       "      <td>183</td>\n",
       "      <td>191</td>\n",
       "      <td>215</td>\n",
       "      <td>314</td>\n",
       "      <td>366</td>\n",
       "      <td>383</td>\n",
       "      <td>391</td>\n",
       "      <td>402</td>\n",
       "      <td>413</td>\n",
       "      <td>424</td>\n",
       "      <td>427</td>\n",
       "      <td>468</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>165</td>\n",
       "      <td>186</td>\n",
       "      <td>191</td>\n",
       "      <td>215</td>\n",
       "      <td>304</td>\n",
       "      <td>364</td>\n",
       "      <td>379</td>\n",
       "      <td>391</td>\n",
       "      <td>408</td>\n",
       "      <td>413</td>\n",
       "      <td>424</td>\n",
       "      <td>427</td>\n",
       "      <td>468</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>115</td>\n",
       "      <td>184</td>\n",
       "      <td>198</td>\n",
       "      <td>215</td>\n",
       "      <td>304</td>\n",
       "      <td>366</td>\n",
       "      <td>387</td>\n",
       "      <td>391</td>\n",
       "      <td>404</td>\n",
       "      <td>413</td>\n",
       "      <td>422</td>\n",
       "      <td>427</td>\n",
       "      <td>468</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>184</td>\n",
       "      <td>191</td>\n",
       "      <td>215</td>\n",
       "      <td>294</td>\n",
       "      <td>362</td>\n",
       "      <td>387</td>\n",
       "      <td>393</td>\n",
       "      <td>397</td>\n",
       "      <td>416</td>\n",
       "      <td>424</td>\n",
       "      <td>426</td>\n",
       "      <td>468</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>10</td>\n",
       "      <td>154</td>\n",
       "      <td>186</td>\n",
       "      <td>191</td>\n",
       "      <td>215</td>\n",
       "      <td>302</td>\n",
       "      <td>366</td>\n",
       "      <td>379</td>\n",
       "      <td>391</td>\n",
       "      <td>410</td>\n",
       "      <td>418</td>\n",
       "      <td>424</td>\n",
       "      <td>426</td>\n",
       "      <td>468</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>23</td>\n",
       "      <td>113</td>\n",
       "      <td>183</td>\n",
       "      <td>191</td>\n",
       "      <td>215</td>\n",
       "      <td>304</td>\n",
       "      <td>366</td>\n",
       "      <td>383</td>\n",
       "      <td>391</td>\n",
       "      <td>404</td>\n",
       "      <td>413</td>\n",
       "      <td>424</td>\n",
       "      <td>427</td>\n",
       "      <td>468</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>41</td>\n",
       "      <td>112</td>\n",
       "      <td>183</td>\n",
       "      <td>191</td>\n",
       "      <td>215</td>\n",
       "      <td>304</td>\n",
       "      <td>366</td>\n",
       "      <td>383</td>\n",
       "      <td>395</td>\n",
       "      <td>398</td>\n",
       "      <td>417</td>\n",
       "      <td>424</td>\n",
       "      <td>426</td>\n",
       "      <td>468</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>5</td>\n",
       "      <td>137</td>\n",
       "      <td>183</td>\n",
       "      <td>191</td>\n",
       "      <td>215</td>\n",
       "      <td>284</td>\n",
       "      <td>366</td>\n",
       "      <td>383</td>\n",
       "      <td>393</td>\n",
       "      <td>398</td>\n",
       "      <td>416</td>\n",
       "      <td>424</td>\n",
       "      <td>427</td>\n",
       "      <td>468</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>159</td>\n",
       "      <td>183</td>\n",
       "      <td>205</td>\n",
       "      <td>215</td>\n",
       "      <td>304</td>\n",
       "      <td>367</td>\n",
       "      <td>383</td>\n",
       "      <td>391</td>\n",
       "      <td>401</td>\n",
       "      <td>418</td>\n",
       "      <td>424</td>\n",
       "      <td>426</td>\n",
       "      <td>468</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  fnlwgt  educational-num  capital-gain  capital-loss  \\\n",
       "0        8     146              181           191           215   \n",
       "1       21      89              183           191           215   \n",
       "2       11     165              186           191           215   \n",
       "3       27     115              184           198           215   \n",
       "4        1      93              184           191           215   \n",
       "...    ...     ...              ...           ...           ...   \n",
       "48837   10     154              186           191           215   \n",
       "48838   23     113              183           191           215   \n",
       "48839   41     112              183           191           215   \n",
       "48840    5     137              183           191           215   \n",
       "48841   35     159              183           205           215   \n",
       "\n",
       "       hours-per-week  workclass  education  marital-status  occupation  \\\n",
       "0                 304        366        373             393         404   \n",
       "1                 314        366        383             391         402   \n",
       "2                 304        364        379             391         408   \n",
       "3                 304        366        387             391         404   \n",
       "4                 294        362        387             393         397   \n",
       "...               ...        ...        ...             ...         ...   \n",
       "48837             302        366        379             391         410   \n",
       "48838             304        366        383             391         404   \n",
       "48839             304        366        383             395         398   \n",
       "48840             284        366        383             393         398   \n",
       "48841             304        367        383             391         401   \n",
       "\n",
       "       relationship  race  gender  native-country  income  \n",
       "0               416   422     427             468     472  \n",
       "1               413   424     427             468     472  \n",
       "2               413   424     427             468     473  \n",
       "3               413   422     427             468     473  \n",
       "4               416   424     426             468     472  \n",
       "...             ...   ...     ...             ...     ...  \n",
       "48837           418   424     426             468     472  \n",
       "48838           413   424     427             468     473  \n",
       "48839           417   424     426             468     472  \n",
       "48840           416   424     427             468     472  \n",
       "48841           418   424     426             468     473  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "def POOL_preprocess(df, N_BINS = 100):\n",
    "    '''\n",
    "    Preprocess the DataFrame \n",
    "    Args:\n",
    "        df: DataFrame\n",
    "        N_BINS: number of bins for each numerical column (will not be the exact number of bins, differ by distribution)\n",
    "    Return:\n",
    "        X_trans: DataFrame after preprocessing\n",
    "        ct: ColumnTransformer object, for inference and inverse transform\n",
    "        NUM_vs_CAT: tuple, (number of numerical columns, number of categorical columns - 1) \"in feature field, do not include label column\"\n",
    "        existing_values: dict, {column name: sorted list of existing values}\n",
    "    '''\n",
    "    \n",
    "    CAT = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\n",
    "    NUM = ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "    \n",
    "    num_CAT = len(CAT)\n",
    "    num_NUM = len(NUM)  \n",
    "    \n",
    "    ct = ColumnTransformer([\n",
    "        (\"age\", KBinsDiscretizer(n_bins = N_BINS, encode='ordinal', strategy='uniform', subsample=None), [\"age\"]),\n",
    "        (\"fnlwgt\", KBinsDiscretizer(n_bins = N_BINS, encode='ordinal', strategy='quantile', subsample=None), [\"fnlwgt\"]),\n",
    "        (\"educational-num\", KBinsDiscretizer(n_bins = N_BINS, encode='ordinal', strategy='quantile', subsample=None), [\"educational-num\"]),\n",
    "        (\"capital-gain\", KBinsDiscretizer(n_bins = N_BINS, encode='ordinal', strategy='uniform', subsample=None), [\"capital-gain\"]),\n",
    "        (\"capital-loss\", KBinsDiscretizer(n_bins = N_BINS, encode='ordinal', strategy='uniform', subsample=None), [\"capital-loss\"]),\n",
    "        (\"hours-per-week\", KBinsDiscretizer(n_bins = N_BINS, encode='ordinal', strategy='uniform', subsample=None), [\"hours-per-week\"]),\n",
    "         ],remainder = 'passthrough', verbose_feature_names_out = False) # make sure columns are unique\n",
    "    ct.set_output(transform = 'pandas')\n",
    "    X_trans = ct.fit_transform(df) \n",
    "    \n",
    "    # store the numrical columns' existing values for identifying unseen values\n",
    "    existing_values = {}\n",
    "    for column in NUM:\n",
    "        existing_values[column] = sorted(X_trans[column].unique().astype(int))\n",
    "    for column in CAT:\n",
    "        existing_values[column] = sorted(X_trans[column].unique().astype(str))\n",
    "    \n",
    "    # apply Ordinal encoding on columns\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "    OE_list = {}\n",
    "    for column in NUM + CAT:\n",
    "        OE = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value = -1)\n",
    "        X_trans[column] = OE.fit_transform(X_trans[[column]])\n",
    "        OE_list[column] = OE\n",
    "    \n",
    "    # make all columns' catagory unique\n",
    "    # 7/19: each NUM column has its own number of unique values, plus 1 for unseen values\n",
    "    # each column has it's own number of unique values. '+1' is for unseen values\n",
    "    offset = 0\n",
    "    for column in NUM + CAT:\n",
    "        X_trans[column] = X_trans[column].apply(lambda x: x + offset)\n",
    "        offset += (X_trans[column].max() - X_trans[column].min() + 1) + 1\n",
    "    \n",
    "    X_trans = X_trans.astype(int).reset_index(drop = True)\n",
    "    return X_trans, (ct, OE_list, NUM, CAT, existing_values), (num_NUM, num_CAT - 1)\n",
    "    # -1 is for the income column (label)\n",
    "X_trans, inference_package , _  = POOL_preprocess(main_df)\n",
    "X_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 FOLD (transformed input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "X_train: (39073, 14), X_test: (9769, 14)\n",
      "Y_train: (39073,), Y_test: (9769,)\n",
      "auc: 0.929907058541208\n",
      "Fold 1:\n",
      "X_train: (39073, 14), X_test: (9769, 14)\n",
      "Y_train: (39073,), Y_test: (9769,)\n",
      "auc: 0.9291356104330563\n",
      "Fold 2:\n",
      "X_train: (39074, 14), X_test: (9768, 14)\n",
      "Y_train: (39074,), Y_test: (9768,)\n",
      "auc: 0.92712635692001\n",
      "Fold 3:\n",
      "X_train: (39074, 14), X_test: (9768, 14)\n",
      "Y_train: (39074,), Y_test: (9768,)\n",
      "auc: 0.9242047156100273\n",
      "Fold 4:\n",
      "X_train: (39074, 14), X_test: (9768, 14)\n",
      "Y_train: (39074,), Y_test: (9768,)\n",
      "auc: 0.9263723581549314\n",
      "Average AUC: 0.9273492199318467\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# import labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "AUCS = []\n",
    "main_df = pd.read_csv('adult.csv')\n",
    "\n",
    "# 進行5-fold交叉驗證\n",
    "for index, (train_index, test_index) in enumerate(kf.split(main_df)):\n",
    "    X_train, X_test = main_df.loc[train_index], main_df.loc[test_index]\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    Y_train, Y_test = X_train['income'] , X_test['income']\n",
    "    Y_train = le.fit_transform(Y_train)\n",
    "    Y_test = le.transform(Y_test)\n",
    "    \n",
    "    X_train, X_test = X_train.drop(columns='income'), X_test.drop(columns='income')\n",
    "    \n",
    "    CAT = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
    "    le2 = LabelEncoder()\n",
    "    le2.fit(main_df[CAT].astype(str).values.flatten())\n",
    "    for column in CAT:\n",
    "        le = LabelEncoder()\n",
    "        X_train[column] = le2.transform(X_train[column].astype(str))\n",
    "        X_test[column] = le2.transform(X_test[column].astype(str))\n",
    "    \n",
    "    print(f'Fold {index}:')\n",
    "    print(f'X_train: {X_train.shape}, X_test: {X_test.shape}')\n",
    "    print(f'Y_train: {Y_train.shape}, Y_test: {Y_test.shape}')\n",
    "    \n",
    "    model = xgb.XGBClassifier(random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_prob = model.predict_proba(X_test)  # 预测概率\n",
    "    auc = roc_auc_score(Y_test, Y_prob[:, 1])\n",
    "    AUCS.append(auc)\n",
    "    print(f'auc: {auc}')\n",
    "print(f'Average AUC: {np.mean(AUCS)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-FOLD (original input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m AUCS \u001b[39m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[39m# 進行5-fold交叉驗證\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m index, (train_index, test_index) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(kf\u001b[39m.\u001b[39msplit(main)):\n\u001b[1;32m      5\u001b[0m     X_train, X_test \u001b[39m=\u001b[39m X_trans\u001b[39m.\u001b[39mloc[train_index], X_trans\u001b[39m.\u001b[39mloc[test_index]\n\u001b[1;32m      6\u001b[0m     Y_train, Y_test \u001b[39m=\u001b[39m X_train[\u001b[39m'\u001b[39m\u001b[39mincome\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m X_train[\u001b[39m'\u001b[39m\u001b[39mincome\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmin(), X_test[\u001b[39m'\u001b[39m\u001b[39mincome\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m X_test[\u001b[39m'\u001b[39m\u001b[39mincome\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmin()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'main' is not defined"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "AUCS = []\n",
    "# 進行5-fold交叉驗證\n",
    "for index, (train_index, test_index) in enumerate(kf.split(main)):\n",
    "    X_train, X_test = X_trans.loc[train_index], X_trans.loc[test_index]\n",
    "    Y_train, Y_test = X_train['income'] - X_train['income'].min(), X_test['income'] - X_test['income'].min()\n",
    "    X_train, X_test = X_train.drop(columns='income'), X_test.drop(columns='income')\n",
    "    print(f'Fold {index}:')\n",
    "    print(f'X_train: {X_train.shape}, X_test: {X_test.shape}')\n",
    "    print(f'Y_train: {Y_train.shape}, Y_test: {Y_test.shape}')\n",
    "    \n",
    "    model = xgb.XGBClassifier()\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_prob = model.predict_proba(X_test)  # 预测概率\n",
    "    auc = roc_auc_score(Y_test, Y_prob[:, 1])\n",
    "    AUCS.append(auc)\n",
    "    print(f'auc: {auc}')\n",
    "print(f'Average AUC: {np.mean(AUCS)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main_df: Average AUC: 0.9204860054219773 <br>\n",
    "processed:  Average AUC: 0.9200331315953896"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
