{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# baic transformer Decoder model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fun\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import xformers.ops as xops\n",
    "import math \n",
    "from typing import Optional, Union\n",
    "from torch import Tensor\n",
    "import random\n",
    "\n",
    "main_df = pd.read_csv('adult.csv')\n",
    "main_df.head()\n",
    "DEVICE = 'cuda'\n",
    "# DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_DataFrame_distribution(X_trans):\n",
    "    columns_range = {}\n",
    "    print('%15s' % '', '%6s' % 'min','%6s' % 'max', '%6s' % 'nunique')\n",
    "    \n",
    "    for column in X_trans.columns:\n",
    "        print('%15s' % column, '%6s' % X_trans[column].min(),'%6s' % X_trans[column].max(), '%6s' % X_trans[column].nunique())\n",
    "        columns_range[column] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsou/.conda/envs/xformers/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:313: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>180</td>\n",
       "      <td>190</td>\n",
       "      <td>214</td>\n",
       "      <td>275</td>\n",
       "      <td>362</td>\n",
       "      <td>369</td>\n",
       "      <td>389</td>\n",
       "      <td>399</td>\n",
       "      <td>412</td>\n",
       "      <td>420</td>\n",
       "      <td>423</td>\n",
       "      <td>464</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>133</td>\n",
       "      <td>187</td>\n",
       "      <td>190</td>\n",
       "      <td>214</td>\n",
       "      <td>288</td>\n",
       "      <td>360</td>\n",
       "      <td>380</td>\n",
       "      <td>389</td>\n",
       "      <td>403</td>\n",
       "      <td>413</td>\n",
       "      <td>420</td>\n",
       "      <td>422</td>\n",
       "      <td>464</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "      <td>182</td>\n",
       "      <td>190</td>\n",
       "      <td>214</td>\n",
       "      <td>303</td>\n",
       "      <td>362</td>\n",
       "      <td>379</td>\n",
       "      <td>387</td>\n",
       "      <td>396</td>\n",
       "      <td>409</td>\n",
       "      <td>420</td>\n",
       "      <td>423</td>\n",
       "      <td>464</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>78</td>\n",
       "      <td>186</td>\n",
       "      <td>190</td>\n",
       "      <td>214</td>\n",
       "      <td>308</td>\n",
       "      <td>362</td>\n",
       "      <td>377</td>\n",
       "      <td>389</td>\n",
       "      <td>405</td>\n",
       "      <td>410</td>\n",
       "      <td>420</td>\n",
       "      <td>423</td>\n",
       "      <td>464</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>96</td>\n",
       "      <td>179</td>\n",
       "      <td>190</td>\n",
       "      <td>214</td>\n",
       "      <td>313</td>\n",
       "      <td>364</td>\n",
       "      <td>368</td>\n",
       "      <td>389</td>\n",
       "      <td>396</td>\n",
       "      <td>412</td>\n",
       "      <td>420</td>\n",
       "      <td>423</td>\n",
       "      <td>464</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  educational-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0    1     125              180           190           214             275   \n",
       "1   44     133              187           190           214             288   \n",
       "2   37     113              182           190           214             303   \n",
       "3    7      78              186           190           214             308   \n",
       "4   27      96              179           190           214             313   \n",
       "\n",
       "   workclass  education  marital-status  occupation  relationship  race  \\\n",
       "0        362        369             389         399           412   420   \n",
       "1        360        380             389         403           413   420   \n",
       "2        362        379             387         396           409   420   \n",
       "3        362        377             389         405           410   420   \n",
       "4        364        368             389         396           412   420   \n",
       "\n",
       "   gender  native-country  income  \n",
       "0     423             464     468  \n",
       "1     422             464     468  \n",
       "2     423             464     468  \n",
       "3     423             464     468  \n",
       "4     423             464     468  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "def POOL_preprocess(df, N_BINS = 100):\n",
    "    '''\n",
    "    Preprocess the DataFrame \n",
    "    Args:\n",
    "        df: DataFrame\n",
    "        N_BINS: number of bins for each numerical column (will not be the exact number of bins, differ by distribution)\n",
    "    Return:\n",
    "        X_trans: DataFrame after preprocessing\n",
    "        ct: ColumnTransformer object, for inference and inverse transform\n",
    "        NUM_vs_CAT: tuple, (number of numerical columns, number of categorical columns - 1) \"in feature field, do not include label column\"\n",
    "        existing_values: dict, {column name: sorted list of existing values}\n",
    "    '''\n",
    "    \n",
    "    CAT = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\n",
    "    NUM = ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "    \n",
    "    num_CAT = len(CAT)\n",
    "    num_NUM = len(NUM)  \n",
    "    \n",
    "    ct = ColumnTransformer([\n",
    "        (\"age\", KBinsDiscretizer(n_bins = N_BINS, encode='ordinal', strategy='uniform', subsample=None), [\"age\"]),\n",
    "        (\"fnlwgt\", KBinsDiscretizer(n_bins = N_BINS, encode='ordinal', strategy='quantile', subsample=None), [\"fnlwgt\"]),\n",
    "        (\"educational-num\", KBinsDiscretizer(n_bins = N_BINS, encode='ordinal', strategy='quantile', subsample=None), [\"educational-num\"]),\n",
    "        (\"capital-gain\", KBinsDiscretizer(n_bins = N_BINS, encode='ordinal', strategy='uniform', subsample=None), [\"capital-gain\"]),\n",
    "        (\"capital-loss\", KBinsDiscretizer(n_bins = N_BINS, encode='ordinal', strategy='uniform', subsample=None), [\"capital-loss\"]),\n",
    "        (\"hours-per-week\", KBinsDiscretizer(n_bins = N_BINS, encode='ordinal', strategy='uniform', subsample=None), [\"hours-per-week\"]),\n",
    "         ],remainder = 'passthrough', verbose_feature_names_out = False) # make sure columns are unique\n",
    "    ct.set_output(transform = 'pandas')\n",
    "    X_trans = ct.fit_transform(df) \n",
    "    \n",
    "    # store the numrical columns' existing values for identifying unseen values\n",
    "    existing_values = {}\n",
    "    for column in NUM:\n",
    "        existing_values[column] = sorted(X_trans[column].unique().astype(int))\n",
    "    for column in CAT:\n",
    "        existing_values[column] = sorted(X_trans[column].unique().astype(str))\n",
    "    \n",
    "    # apply Ordinal encoding on columns\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "    OE_list = {}\n",
    "    for column in NUM + CAT:\n",
    "        OE = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value = -1)\n",
    "        X_trans[column] = OE.fit_transform(X_trans[[column]])\n",
    "        OE_list[column] = OE\n",
    "    \n",
    "    # make all columns' catagory unique\n",
    "    # 7/19: each NUM column has its own number of unique values, plus 1 for unseen values\n",
    "    # each column has it's own number of unique values. '+1' is for unseen values\n",
    "    offset = 0\n",
    "    for column in NUM + CAT:\n",
    "        X_trans[column] = X_trans[column].apply(lambda x: x + offset)\n",
    "        offset += (X_trans[column].max() - X_trans[column].min() + 1) + 1\n",
    "    \n",
    "    X_trans = X_trans.astype(int).reset_index(drop = True)\n",
    "    return X_trans, (ct, OE_list, NUM, CAT, existing_values), (num_NUM, num_CAT - 1)\n",
    "    # -1 is for the income column (label)\n",
    "main_df_SHUFFLE = main_df.sample(frac=1).reset_index(drop=True)\n",
    "X_trans, inference_package , _  = POOL_preprocess(main_df_SHUFFLE[48842//5:])\n",
    "X_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[preprocess]: detected unseen values in column age\n",
      "[preprocess]: detected unseen values in column hours-per-week\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>140</td>\n",
       "      <td>183</td>\n",
       "      <td>190</td>\n",
       "      <td>214</td>\n",
       "      <td>291</td>\n",
       "      <td>362</td>\n",
       "      <td>383</td>\n",
       "      <td>389</td>\n",
       "      <td>401</td>\n",
       "      <td>410</td>\n",
       "      <td>420</td>\n",
       "      <td>422</td>\n",
       "      <td>464</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>114</td>\n",
       "      <td>186</td>\n",
       "      <td>190</td>\n",
       "      <td>214</td>\n",
       "      <td>303</td>\n",
       "      <td>362</td>\n",
       "      <td>377</td>\n",
       "      <td>387</td>\n",
       "      <td>403</td>\n",
       "      <td>409</td>\n",
       "      <td>420</td>\n",
       "      <td>423</td>\n",
       "      <td>464</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>88</td>\n",
       "      <td>187</td>\n",
       "      <td>190</td>\n",
       "      <td>214</td>\n",
       "      <td>308</td>\n",
       "      <td>360</td>\n",
       "      <td>380</td>\n",
       "      <td>387</td>\n",
       "      <td>397</td>\n",
       "      <td>409</td>\n",
       "      <td>420</td>\n",
       "      <td>423</td>\n",
       "      <td>464</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>113</td>\n",
       "      <td>175</td>\n",
       "      <td>190</td>\n",
       "      <td>214</td>\n",
       "      <td>303</td>\n",
       "      <td>360</td>\n",
       "      <td>371</td>\n",
       "      <td>391</td>\n",
       "      <td>399</td>\n",
       "      <td>413</td>\n",
       "      <td>418</td>\n",
       "      <td>423</td>\n",
       "      <td>464</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>167</td>\n",
       "      <td>186</td>\n",
       "      <td>200</td>\n",
       "      <td>214</td>\n",
       "      <td>308</td>\n",
       "      <td>362</td>\n",
       "      <td>377</td>\n",
       "      <td>389</td>\n",
       "      <td>403</td>\n",
       "      <td>410</td>\n",
       "      <td>420</td>\n",
       "      <td>422</td>\n",
       "      <td>464</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  educational-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0    6     140              183           190           214             291   \n",
       "1   16     114              186           190           214             303   \n",
       "2   22      88              187           190           214             308   \n",
       "3   41     113              175           190           214             303   \n",
       "4   16     167              186           200           214             308   \n",
       "\n",
       "   workclass  education  marital-status  occupation  relationship  race  \\\n",
       "0        362        383             389         401           410   420   \n",
       "1        362        377             387         403           409   420   \n",
       "2        360        380             387         397           409   420   \n",
       "3        360        371             391         399           413   418   \n",
       "4        362        377             389         403           410   420   \n",
       "\n",
       "   gender  native-country  income  \n",
       "0     422             464     468  \n",
       "1     423             464     469  \n",
       "2     423             464     468  \n",
       "3     423             464     468  \n",
       "4     422             464     469  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def POOL_preprocess_inference(df: pd.DataFrame,\n",
    "                              inference_package: tuple,\n",
    "                                # ct: ColumnTransformer,\n",
    "                                # OE_list: dict,\n",
    "                                # NUM: list,\n",
    "                                # CAT: list,\n",
    "                                # existing_values: dict,\n",
    "                              ):\n",
    "    '''Preprocess the DataFrame when inference\n",
    "    \n",
    "    Args:\n",
    "        `df`: DataFrame to be processed.\\n\n",
    "        `inference_package`: tuple, containing the following objects.\n",
    "            `ct`: ColumnTransformer object required for inference, which makes sure values are in the same range as training data\n",
    "            `OE_list`: dict, {column name: OrdinalEncoder object}\\n\n",
    "            `NUM`: list of numerical columns \\n\n",
    "            `CAT`: list of categorical columns\\n\n",
    "            `existing_values`: dict, {column name: sorted list of existing values}\n",
    "    '''\n",
    "    (ct, OE_list, NUM, CAT, existing_values) = inference_package\n",
    "    X_trans_ori = ct.transform(df)\n",
    "    \n",
    "    # caculate the loaction of unseen values\n",
    "    unseen_node_indexs = {}\n",
    "    offset = 0\n",
    "    for col in NUM + CAT:\n",
    "        unseen_node_indexs[col] = (int(len(existing_values[col])) + offset )\n",
    "        offset += int(len(existing_values[col])) + 1\n",
    "    \n",
    "    X_trans = X_trans_ori\n",
    "    \n",
    "    # apply Ordinal encoding on columns, and make all columns' catagory unique\n",
    "    offset = 0\n",
    "    for column in NUM + CAT:\n",
    "        OE = OE_list[column]\n",
    "        X_trans[column] = OE.transform(X_trans[[column]]) # use fitted OE to transform, the unseen values will be encoded as -1\n",
    "        if -1 in X_trans[column].tolist():\n",
    "            print('[preprocess]: detected unseen values in column', column)\n",
    "        X_trans[column] = X_trans[column].apply(lambda x: x + offset if x != -1 else unseen_node_indexs[column])\n",
    "        offset = unseen_node_indexs[column] + 1  \n",
    "\n",
    "    \n",
    "    X_trans = X_trans.astype(int).reset_index(drop = True) \n",
    "    return X_trans, unseen_node_indexs \n",
    "X_trans_ , unseen_node_indexs= POOL_preprocess_inference(main_df_SHUFFLE[:48842//5], inference_package)\n",
    "X_trans_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   min    max nunique\n",
      "            age      0     73     72\n",
      "         fnlwgt     74    173    100\n",
      "educational-num    175    188     14\n",
      "   capital-gain    190    212     20\n",
      "   capital-loss    214    262     36\n",
      " hours-per-week    264    357     87\n",
      "      workclass    358    366      9\n",
      "      education    368    383     16\n",
      " marital-status    385    391      7\n",
      "     occupation    393    407     15\n",
      "   relationship    409    414      6\n",
      "           race    416    420      5\n",
      "         gender    422    423      2\n",
      " native-country    425    466     41\n",
      "         income    468    469      2\n"
     ]
    }
   ],
   "source": [
    "check_DataFrame_distribution(X_trans_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   min    max nunique\n",
      "            age      0     72     73\n",
      "         fnlwgt     74    173    100\n",
      "educational-num    175    188     14\n",
      "   capital-gain    190    212     23\n",
      "   capital-loss    214    262     49\n",
      " hours-per-week    264    356     93\n",
      "      workclass    358    366      9\n",
      "      education    368    383     16\n",
      " marital-status    385    391      7\n",
      "     occupation    393    407     15\n",
      "   relationship    409    414      6\n",
      "           race    416    420      5\n",
      "         gender    422    423      2\n",
      " native-country    425    466     42\n",
      "         income    468    469      2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[74, 175, 190, 214, 264, 360, 370, 387, 395, 411, 418, 424, 427, 470, 473]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_DataFrame_distribution(X_trans)\n",
    "'[74, 175, 190, 214, 264, 360, 370, 387, 395, 411, 418, 424, 427, 470, 473]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = 4*48842//5\n",
    "# test_size = 48842//5\n",
    "# train_pool = main_df[test_size:]\n",
    "# test_pool = main_df[:test_size]\n",
    "# print('total data num:' , main_df.shape[0])\n",
    "# print('trian data num:' , train_pool.shape[0])\n",
    "# print('test data num:' , test_pool.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Notations\\n  node: number of all nodes = L + S + C + F\\n  L: number of lable nodes + 1 (for unseen lable)\\n  S: number of sample nodes + 1 (for inference)\\n  C: number of catagory nodes + F (for each field(column)\\n  F: number of field(column) nodes (no unseen field is allowed)\\n  hidden: number of hidden representation\\n\\ndata size = \\nmask size =\\nuse nn.transformerDecoder(data,mask) to get the output\\nuse the above output as input of MLP to predict the lable   \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Notations\n",
    "  node: number of all nodes = L + S + C + F\n",
    "  L: number of lable nodes + 1 (for unseen lable)\n",
    "  S: number of sample nodes + 1 (for inference)\n",
    "  C: number of catagory nodes + F (for each field(column)\n",
    "  F: number of field(column) nodes (no unseen field is allowed)\n",
    "  hidden: number of hidden representation\n",
    "\n",
    "data size = \n",
    "mask size =\n",
    "use nn.transformerDecoder(data,mask) to get the output\n",
    "use the above output as input of MLP to predict the lable   \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data num: 48842\n",
      "trian data num: 39073\n",
      "test data num: 9769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[preprocess]: detected unseen values in column hours-per-week\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsou/.conda/envs/xformers/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:313: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_nums {'L': 3, 'S': 39074, 'C': 469, 'F': 14}\n",
      "total 39560 nodes\n",
      "L_input torch.cuda.LongTensor torch.Size([3, 1])\n",
      "S_input torch.cuda.FloatTensor torch.Size([39074, 128])\n",
      "C_input torch.cuda.LongTensor torch.Size([469, 1])\n",
      "F_input torch.cuda.LongTensor torch.Size([14, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9731, 14565, 17376, 17387, 20075, 21223, 23671, 29431, 32360, 34676]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HGNN_():\n",
    "    def __init__(self,\n",
    "                 data_df : pd.DataFrame,\n",
    "                 split_ratio : float ,\n",
    "                 label_column : str,\n",
    "                 ):\n",
    "        # shuffle and cut data\n",
    "        data_df = data_df.sample(frac=1).reset_index(drop=True)\n",
    "        test_size = math.ceil(data_df.shape[0] * (1-split_ratio))\n",
    "        train_pool = data_df[test_size:]\n",
    "        test_pool = data_df[:test_size]\n",
    "        print('total data num:' , data_df.shape[0])\n",
    "        print('trian data num:' , train_pool.shape[0])\n",
    "        print('test data num:' , test_pool.shape[0])\n",
    "        \n",
    "        # to-dos:\n",
    "        # train\n",
    "        #   \n",
    "        N_BINS = 100\n",
    "        TARGET_POOL, self.inference_package, self.NUM_vs_CAT = POOL_preprocess(train_pool, N_BINS = N_BINS)\n",
    "        TEST_POOL, self.unseen_node_indexs_C = POOL_preprocess_inference(test_pool, self.inference_package)\n",
    "        LABEL_COLUMN = label_column\n",
    "\n",
    "        # cut feature and lable\n",
    "        FEATURE_POOL = TARGET_POOL.drop(LABEL_COLUMN, axis=1)\n",
    "        LABEL_POOL = TARGET_POOL[LABEL_COLUMN]\n",
    "        TEST_LABEL_POOL = TEST_POOL[LABEL_COLUMN]\n",
    "        \n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "        enc = OneHotEncoder()\n",
    "        LABEL_POOL = enc.fit_transform(LABEL_POOL.values.reshape(-1,1)).toarray()\n",
    "        TEST_LABEL_POOL = enc.fit_transform(TEST_LABEL_POOL.values.reshape(-1,1)).toarray()\n",
    "\n",
    "        # L: number of lable nodes, the last node of Lable nodes is served as unknown lable node\n",
    "        L = LABEL_POOL.shape[1] + 1\n",
    "\n",
    "        # S: number of sample nodes, the last node of sample nodes is served as infering node\n",
    "        S = FEATURE_POOL.shape[0] + 1\n",
    "        \n",
    "        # F: number of field (column) nodes\n",
    "        F = FEATURE_POOL.shape[1]\n",
    "\n",
    "        # C: number of catagory nodes, each field(column) has its own \"unseen\" catagory nodes\n",
    "        self.nodes_of_fields = []\n",
    "        for column in FEATURE_POOL.columns:\n",
    "            self.nodes_of_fields.append(FEATURE_POOL[column].nunique()+1)\n",
    "        C = sum(self.nodes_of_fields) # the total number of nodes equals to the sum of nodes of each field\n",
    "        C_POOL = range(int(C))\n",
    "\n",
    "        nodes_num = {'L':L, 'S':S, 'C':C, 'F':F}\n",
    "        print('node_nums', nodes_num)\n",
    "        print('total', L+S+C+F, 'nodes')\n",
    "        \n",
    "        # get samples indexs for each label\n",
    "        self.labe_to_index = {}\n",
    "        tmp_pool = TARGET_POOL.copy().reset_index(drop=True)\n",
    "        for label in tmp_pool['income'].unique():\n",
    "            self.labe_to_index[label] = (tmp_pool[tmp_pool['income'] == label].index).tolist()\n",
    "        \n",
    "        self.TARGET_POOL = TARGET_POOL\n",
    "        self.TEST_POOL = TEST_POOL\n",
    "        self.TEST_LABEL_POOL = TEST_LABEL_POOL\n",
    "        self.LABEL_COLUMN = LABEL_COLUMN\n",
    "        self.FEATURE_POOL = FEATURE_POOL\n",
    "        self.LABEL_POOL = LABEL_POOL\n",
    "        self.C_POOL = C_POOL   \n",
    "        self.nodes_num = nodes_num\n",
    "        self.N_BINS = N_BINS\n",
    "\n",
    "        \n",
    "        self.make_input_tensor()\n",
    "        # self.get_sample(10)        \n",
    "        self.make_mask_all()\n",
    "        \n",
    "        # self.make_mask()\n",
    "        \n",
    "        \n",
    "    def make_mask_subgraph(self,\n",
    "                  sample_indices: Optional[list] = None,\n",
    "                ):\n",
    "        '''Makeing masks for subgraph. Mask values are 1 if two nodes are connected, otherwise 0.\n",
    "        \n",
    "        Args:\n",
    "            sample_indices: list of sample node indices\n",
    "        \n",
    "        for example, with:\n",
    "            {'L': 3, 'S': 39074, 'C': 470, 'F': 14, 'K': 10}\n",
    "            \n",
    "        the masks will be:\n",
    "            masks['L2S'] = torch.Size([16, 8]), values in torch.Size([10, 3])\\\\\n",
    "            masks['S2C'] = torch.Size([472, 16]), values in torch.Size([470, 10])\\\\\n",
    "            masls['C2F'] = torch.Size([16, 472]), values in torch.Size([14, 470])\\\\\n",
    "        Notice: xformer require the mask's tensor must align on memory, and should be slice of a tensor if shape cannot be divided by 8\n",
    "        '''\n",
    "        L, S, C, F = self.nodes_num['L'], self.nodes_num['S'], self.nodes_num['C'], self.nodes_num['F']\n",
    "\n",
    "        sample_size = len(sample_indices)\n",
    "        masked_POOL = self.TARGET_POOL.iloc[sample_indices] # sample dataframe into shape (10,14)\n",
    "        # caculate masking\n",
    "        masks = {}\n",
    "\n",
    "        # label to sample\n",
    "        tmp = torch.zeros([math.ceil(sample_size/8) * 8, math.ceil(L/8) * 8], dtype=torch.float, device=DEVICE) \n",
    "        label_value = masked_POOL[self.LABEL_COLUMN].values\n",
    "        tmp[torch.arange(sample_size), torch.tensor(label_value - min(label_value))] = 1\n",
    "        masks['L2S'] = tmp\n",
    "\n",
    "        # sample to catagory\n",
    "        tmp = torch.zeros([math.ceil(C/8) * 8, math.ceil(sample_size/8) * 8], dtype=torch.float, device=DEVICE).T\n",
    "        tmp_df = masked_POOL.drop(self.LABEL_COLUMN, axis=1)\n",
    "        tmp[torch.arange(sample_size).unsqueeze(-1), torch.tensor(tmp_df.values)] = 1\n",
    "        tmp = tmp.T.contiguous()\n",
    "        \n",
    "        masks['S2C'] = Tensor.contiguous(tmp)\n",
    "\n",
    "        # catagory to field\n",
    "        masks['C2F'] = self.MASKS_FULL['C2F']\n",
    "        \n",
    "        self.MASKS = masks\n",
    "        self.nodes_num['K'] = sample_size\n",
    "        \n",
    "    def make_mask_all(self):\n",
    "        '''Makeing masks for the entire graph. Mask values are 1 if two nodes are connected, otherwise 0.\n",
    "\n",
    "        for example, with:\n",
    "            {'L': 3, 'S': 39074, 'C': 470, 'F': 14, 'K': 10}.\n",
    "            \n",
    "        the masks will be:\n",
    "            masks['L2S']: torch.Size([39080, 8]), values in torch.Size([39074, 3]).\\\\\n",
    "            masks['S2C']: torch.Size([472, 39080]), values in torch.Size([470, 39074]).\\\\\n",
    "            masls['C2F']: torch.Size([16, 472]), values in torch.Size([14, 470]).\\\\\n",
    "            \n",
    "        Notice: xformer require the mask's tensor must align on memory, and should be slice of a tensor if shape cannot be divided by 8\n",
    "        '''\n",
    "        L, S, C, F = self.nodes_num['L'], self.nodes_num['S'], self.nodes_num['C'], self.nodes_num['F']\n",
    "        # caculate masking\n",
    "        masks = {}\n",
    "        \n",
    "        # label to sample \n",
    "        tmp = torch.zeros([math.ceil(S/8) * 8, math.ceil(L/8) * 8], dtype=torch.float, device=DEVICE)\n",
    "        label_ids = self.TARGET_POOL[self.LABEL_COLUMN].unique()\n",
    "        for i, value_df in enumerate(self.TARGET_POOL[self.LABEL_COLUMN]):\n",
    "            for j, value_label in enumerate(label_ids):\n",
    "                if value_label == value_df:\n",
    "                    tmp[i][j] = 1\n",
    "                    break\n",
    "        masks['L2S'] = tmp\n",
    "\n",
    "        # sample to catagory\n",
    "        tmp = torch.zeros([math.ceil(C/8) * 8, math.ceil(S/8) * 8], dtype=torch.float, device=DEVICE).T\n",
    "        tmp_df = self.TARGET_POOL.drop(self.LABEL_COLUMN, axis=1)\n",
    "        tmp[torch.arange(len(self.TARGET_POOL)).unsqueeze(-1), torch.tensor(tmp_df.values)] = 1\n",
    "        tmp = tmp.T.contiguous()\n",
    "        masks['S2C'] = tmp\n",
    "\n",
    "        # catagory to field\n",
    "        # to do : this is wrong , should connect all catagory nodes (even unseen nodes))\n",
    "        tmp = torch.zeros([math.ceil(F/8) * 8, math.ceil(C/8) * 8], dtype=torch.float, device=DEVICE)\n",
    "        unique_items = [sorted(self.FEATURE_POOL[column].unique()) for column in (self.FEATURE_POOL.columns)]\n",
    "        for i in range(F):\n",
    "            for j in (unique_items[i]):\n",
    "                tmp[i][j] = 1\n",
    "        masks['C2F'] = tmp\n",
    "        \n",
    "        self.MASKS = masks\n",
    "        self.MASKS_FULL = masks\n",
    "        \n",
    "    def make_mask_test(self, index_in_test_pool ):\n",
    "        '''Make mask tensor for the testing scenario. \\n\n",
    "        In testing scenario, L, S, C, F remain the same, while all INPUTs are the same (sience they are initialized fixed vlaues\\n\n",
    "        All we need to do is to update masks(L2S, S2C) for the new inference node\n",
    "        '''\n",
    "        L, S, C, F = self.nodes_num['L'], self.nodes_num['S'], self.nodes_num['C'], self.nodes_num['F']\n",
    "        \n",
    "        masks = {}\n",
    "        # L2S shape: torch.Size([39080, 8]), values in torch.Size([39074, 3]).\n",
    "        # number of sample nodes : 39073 + 1 (inference node)\n",
    "        # S = 39074, -1 to convert to index of last node\n",
    "        tmp = self.MASKS_FULL['L2S'].clone().detach()\n",
    "        tmp[S-1, L-1] = 1 # connect inference node to unseen lable nodes\n",
    "        masks['L2S'] = tmp\n",
    "        \n",
    "        # S2C shape: torch.Size([472, 39080]), values in torch.Size([470, 39074]).\n",
    "        # self.MASKS_FULL['S2C'].T :[39080, 472], values in [39074, 470]\n",
    "        # self.TEST_POOL.drop(self.LABEL_COLUMN, axis=1).values[index_in_test_pool]\n",
    "        tmp = self.MASKS_FULL['S2C'].T.clone().detach()\n",
    "        tmp[S-1, self.TEST_POOL.drop(self.LABEL_COLUMN, axis=1).values[index_in_test_pool]] = 1 \n",
    "        masks['S2C'] = tmp.T.contiguous()\n",
    "        \n",
    "        # C2F remains the same\n",
    "        masks['C2F'] = self.MASKS_FULL['C2F']\n",
    "        \n",
    "        self.MASKS = masks\n",
    "        # print('masks[\\'L2S\\']',masks['L2S'].shape)\n",
    "        # print('masks[\\'S2C\\']',masks['S2C'].shape)\n",
    "        # print('masks[\\'C2F\\']',masks['C2F'].shape)\n",
    "        \n",
    "        \n",
    "    def make_input_tensor(self):\n",
    "        '''Makeing input tensor for the entire graph.\n",
    "            \n",
    "        for example, with:\n",
    "            {'L': 3, 'S': 39074, 'C': 470, 'F': 14, 'K': 10}.\n",
    "                \n",
    "        the input tensor will be:\n",
    "            L_input: torch.Size([3, 1]).\n",
    "            S_input: torch.Size([39074, 128]).\n",
    "            C_input: torch.Size([470, 1]).\n",
    "            F_input: torch.Size([14, 1]).\n",
    "        '''\n",
    "        # make input tensor\n",
    "        L, S, C, F = self.nodes_num['L'], self.nodes_num['S'], self.nodes_num['C'], self.nodes_num['F']\n",
    "        # L\n",
    "        L_input = torch.tensor([range(L)], device=DEVICE).reshape(-1,1)\n",
    "        print('L_input', L_input.type(), L_input.shape)\n",
    "        \n",
    "        # S (normalized by standard scaler)\n",
    "        # features = torch.tensor(self.FEATURE_POOL.values, device=DEVICE).float()\n",
    "        # normalized_features = (features - torch.mean(features, dim = 0)) / torch.std(features, dim = 0)\n",
    "        # S_input = torch.cat([normalized_features, torch.tensor([[0]*F], device=DEVICE)],dim = 0).float() # add infering node\n",
    "        \n",
    "        # S (initialize by random)\n",
    "        S_input = torch.rand(128, device=DEVICE).repeat(S,1)\n",
    "        \n",
    "        print('S_input', S_input.type(), S_input.shape)\n",
    "        # C \n",
    "        C_input = torch.tensor([self.C_POOL], device=DEVICE).reshape(-1,1)\n",
    "        print('C_input', C_input.type(), C_input.shape)\n",
    "        # F \n",
    "        F_input = torch.tensor([range(F)], device=DEVICE).reshape(-1,1)\n",
    "        print('F_input', F_input.type(), F_input.shape)\n",
    "        # \n",
    "        self.INPUTS = (L_input, S_input, C_input, F_input)\n",
    "        self.INPUT_DIMS = (L_input.size(1), S_input.size(1), C_input.size(1), F_input.size(1))\n",
    "\n",
    "    def sample_with_distrubution(self, sample_size):\n",
    "        '''\n",
    "        Sample equally from each label with required sample size\\\\\n",
    "        forced to make balenced sample\n",
    "        '''\n",
    "        # decide each label's number of samples (fourced to be balenced if possible) \n",
    "        label_list = []\n",
    "        label_unique = list(self.labe_to_index.keys())\n",
    "        count = sample_size // len(label_unique)\n",
    "        remainder = sample_size % len(label_unique)\n",
    "        label_list = [item for item in label_unique for _ in range(count)]\n",
    "        label_list.extend(random.sample(label_unique, remainder))\n",
    "        # sample from indexes\n",
    "        indices = [random.choice(self.labe_to_index[label]) for label in label_list]\n",
    "        return indices     \n",
    "        \n",
    "    def get_sample(self, sample_size, inculde = []):\n",
    "        '''get sample nodes indices, and update mask and input tensor\n",
    "        \n",
    "        Args:\n",
    "            sample_size: number of sample nodes required.\n",
    "            inculde (optional): list of nodes indices that must be included in the nodes indices.\n",
    "        \n",
    "        The inculded nodes shold not and will not be repeated, in case of the lable leakage.\n",
    "        '''\n",
    "        # inculde specific nodes (e.g. query nodes), while remaining sample_size\n",
    "        sample_indices = self.sample_with_distrubution(sample_size - len(inculde))\n",
    "        if inculde is not []:\n",
    "            while inculde in sample_indices:\n",
    "                sample_indices = self.sample_with_distrubution(sample_size - len(inculde))\n",
    "            # add inculde nodes into sample_indices\n",
    "            for node in inculde:\n",
    "                sample_indices.append(node)\n",
    "            sample_indices = sorted(sample_indices)\n",
    "        # update mask\n",
    "        sample_indices = sorted(sample_indices)\n",
    "        \n",
    "        # modify input tensor\n",
    "        L_input, S_input, C_input, F_input = self.INPUTS\n",
    "        S_input_masked = torch.index_select(S_input, 0, torch.tensor(sample_indices, device=DEVICE))\n",
    "        self.MASKED_INPUTS = (L_input, S_input_masked, C_input, F_input) \n",
    "          \n",
    "        return sample_indices\n",
    "            \n",
    "Train_data = HGNN_( main_df, 0.8, 'income')\n",
    "Train_data.get_sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_data.INPUTS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7863, 0.7523, 0.2203,  ..., 0.3749, 0.4264, 0.9780],\n",
       "        [0.7863, 0.7523, 0.2203,  ..., 0.3749, 0.4264, 0.9780],\n",
       "        [0.7863, 0.7523, 0.2203,  ..., 0.3749, 0.4264, 0.9780],\n",
       "        ...,\n",
       "        [0.7863, 0.7523, 0.2203,  ..., 0.3749, 0.4264, 0.9780],\n",
       "        [0.7863, 0.7523, 0.2203,  ..., 0.3749, 0.4264, 0.9780],\n",
       "        [0.7863, 0.7523, 0.2203,  ..., 0.3749, 0.4264, 0.9780]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_data.INPUTS[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_data.get_sample(100, inculde=[10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from typing import Optional, Any, Union, Callable\n",
    "\n",
    "class TabHyperformer_Layer(nn.TransformerDecoderLayer):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, activation='relu'):\n",
    "        super().__init__(d_model, nhead, dim_feedforward, dropout, activation)\n",
    "        # remove defined modules\n",
    "        delattr(self, 'self_attn')\n",
    "        delattr(self, 'norm1')\n",
    "        delattr(self, 'dropout1')\n",
    "    \n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        x = tgt\n",
    "        # x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))\n",
    "        x = self.norm2(x + self._mha_block(x, memory, memory_mask))\n",
    "        # x =  x + self._mha_block(x, memory, memory_mask, memory_key_padding_mask)\n",
    "        # x = self.norm3(x + self._ff_block(x))\n",
    "\n",
    "        return x\n",
    "    def _mha_block(self, x: Tensor, mem: Tensor,\n",
    "                   attn_mask: Optional[Tensor],) -> Tensor:\n",
    "        x = xops.memory_efficient_attention(x, mem, mem, attn_mask)\n",
    "        # return self.dropout2(x)\n",
    "        return (x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dims (1, 128, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_input torch.cuda.LongTensor torch.Size([3, 1])\n",
      "S_input torch.cuda.FloatTensor torch.Size([39074, 128])\n",
      "C_input torch.cuda.LongTensor torch.Size([469, 1])\n",
      "F_input torch.cuda.LongTensor torch.Size([14, 1])\n",
      "模型輸出的大小[q,2]: torch.Size([2, 2])\n",
      "tensor([[-0.2031,  0.2205],\n",
      "        [-0.1641,  0.0278]], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([[0.3956, 0.6044],\n",
      "        [0.4522, 0.5478]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baic transformer decoder model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fun\n",
    "from tqdm import trange\n",
    "\n",
    "class TransformerDecoderModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 target_ : HGNN_, \n",
    "                 num_layers, \n",
    "                 embedding_dim, \n",
    "                 ):\n",
    "        super(TransformerDecoderModel, self).__init__()\n",
    "\n",
    "        L_dim, S_dim, C_dim, F_dim = target_.INPUT_DIMS\n",
    "        L, S, C, F = target_.nodes_num['L'], target_.nodes_num['S'], target_.nodes_num['C'], target_.nodes_num['F']\n",
    "        num_NUM , num_CAT = target_.NUM_vs_CAT\n",
    "        \n",
    "        # check input dims\n",
    "        # if num_CAT + num_NUM != S_dim:\n",
    "        #     raise ValueError('num_CAT + num_NUM != number of columns (S_dim)   {} + {} != {}'.format(num_CAT, num_NUM, S_dim))\n",
    "        \n",
    "        # nn.Embedding( number of possible catagories, embedding_dim, )\n",
    "        # nn.Linear( number of input dimantion, embedding_dim, )\n",
    "\n",
    "        self.Lable_embedding = nn.Embedding(L, embedding_dim, dtype=torch.float)\n",
    "    \n",
    "        # self.Catagory_embedding_num = nn.Linear(C_dim, embedding_dim, dtype=torch.float)\n",
    "        # for every numrical filed, construct it's own Linear embedding layer\n",
    "        self.Catagory_embedding_nums = []\n",
    "        for i in range(num_NUM):\n",
    "            self.Catagory_embedding_nums.append(\n",
    "                nn.Linear(C_dim, embedding_dim, dtype=torch.float, device=DEVICE)\n",
    "            )\n",
    "        catagories = target_.nodes_of_fields[-num_CAT:] # number of all possible catagories nodes\n",
    "        self.Catagory_embedding_cat = nn.Embedding(sum(catagories), embedding_dim, dtype=torch.float)\n",
    "        \n",
    "        self.Field_embedding = nn.Embedding(F, embedding_dim, dtype=torch.float)\n",
    "        \n",
    "        self.transformer_decoder = nn.TransformerDecoder(\n",
    "            TabHyperformer_Layer(embedding_dim,  nhead = 2 ),\n",
    "            num_layers\n",
    "        )\n",
    "        \n",
    "        # downstream task\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 2),\n",
    "        )\n",
    "        \n",
    "        # initialize MASK_FULL\n",
    "        target_.make_mask_all()\n",
    "        target_.make_input_tensor()\n",
    "        \n",
    "        self.tmpmask_L2S = target_.MASKS['L2S'].clone()\n",
    "\n",
    "    def maskout_lable(self,\n",
    "                      target_: HGNN_,\n",
    "                      query_indices: list, # must be sorted\n",
    "                      sample_indices: Optional[list] = None, \n",
    "                      ):\n",
    "        if sample_indices is not None:\n",
    "            for query in query_indices:\n",
    "                # modify the mask to mask out the queries node's edge to it's label node\n",
    "                L = target_.nodes_num['L']\n",
    "                query_index = sample_indices.index(query) # query_index: index of query node in sample_indices\n",
    "                self.tmpmask_L2S = target_.MASKS['L2S'].clone().detach()\n",
    "                self.tmpmask_L2S[query_index] = 0\n",
    "                self.tmpmask_L2S[query_index][L-1] = 1 # make it as unseen label\n",
    "        else:\n",
    "            for query in query_indices:\n",
    "                L = target_.nodes_num['L']\n",
    "                self.tmpmask_L2S = target_.MASKS['L2S'].clone().detach()\n",
    "                self.tmpmask_L2S[query] = 0\n",
    "                self.tmpmask_L2S[query][L-1] = 1 # make it as unseen label\n",
    "    def forward(self, \n",
    "                target_: HGNN_, \n",
    "                mode : str = 'train',\n",
    "                query_indices: list = None,  # must be sorted\n",
    "                K : Optional[int] = 10,\n",
    "                ):\n",
    "        L, S, C, F = target_.nodes_num['L'], target_.nodes_num['S'], target_.nodes_num['C'], target_.nodes_num['F']\n",
    "        num_NUM, num_CAT = target_.NUM_vs_CAT\n",
    "        \n",
    "        # decide scenario\n",
    "        if mode == 'train':\n",
    "            # generate subgraph with K nodes, including query_indices\n",
    "            # update mask and input tensor\n",
    "            self.sample_indices = Train_data.get_sample(K, inculde = query_indices) # update mask\n",
    "            Train_data.make_mask_subgraph(self.sample_indices)\n",
    "            # get updated masked input tensor and mask \n",
    "            L_input, S_input, C_input, F_input = target_.MASKED_INPUTS\n",
    "            masks = target_.MASKS\n",
    "            # mask out the queries node's edge to it's label node, prevent label leakage\n",
    "            self.maskout_lable(target_, query_indices, self.sample_indices)\n",
    "            \n",
    "            # the query node's indexs in sample_indices\n",
    "            query_indexs = [self.sample_indices.index(query) for query in query_indices]\n",
    "            S_ = K # the S used in transformer decoder\n",
    "            \n",
    "        elif mode == 'inferring':\n",
    "            # use all nodes in the graph \n",
    "            # get input tensor (no need to update)\n",
    "            L_input, S_input, C_input, F_input = target_.INPUTS\n",
    "            # updata mask for inference node\n",
    "            target_.make_mask_test(query_indices[0]) # query node equal to inference node\n",
    "            self.maskout_lable(target_, query_indices)\n",
    "            \n",
    "            masks = target_.MASKS\n",
    "            \n",
    "            # the query node's indexs in sample_indices\n",
    "            query_indexs = [S-1]\n",
    "            S_ = S # the S used in transformer decoder\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # for S and C, we use two different embedding methods, for CAT and NUM, respectively\n",
    "        # Squeeze for making batch dimantion\n",
    "        L_embedded = self.Lable_embedding(L_input.long()).squeeze(1).unsqueeze(0).float()\n",
    "        \n",
    "        S_embedded = S_input.unsqueeze(0).float()\n",
    "\n",
    "        # for every numrical filed, use it's own Linear embedding layer\n",
    "        C_embedded_nums = []\n",
    "        field = target_.nodes_of_fields\n",
    "        start = 0\n",
    "        for index, nodes in enumerate(field[:num_NUM]): # pick numrical fields\n",
    "            end = start + nodes\n",
    "            C_embedded_nums.append(self.Catagory_embedding_nums[index](C_input[start:end].float()).unsqueeze(0))\n",
    "            start = end\n",
    "        C_embedded_num = torch.cat(C_embedded_nums, dim = 1)\n",
    "        \n",
    "        catagorical_filed_nodes = sum(field[-num_CAT:]) # pick catagory fields\n",
    "        C_embedded_cat = self.Catagory_embedding_cat(C_input[-catagorical_filed_nodes:].squeeze(1).long() - sum(field[:num_NUM])).unsqueeze(0).float() # - sum(field[:num_NUM] because the embedding index should start from 0\n",
    "        C_embedded = torch.cat([C_embedded_num, C_embedded_cat], dim = 1)\n",
    "        \n",
    "        F_embedded = self.Field_embedding(F_input.long()).squeeze(1).unsqueeze(0).float()\n",
    "        \n",
    "        # print(L_embedded.shape, S_embedded.shape, C_embedded.shape, F_embedded.shape)\n",
    "        \n",
    "        \n",
    "        # propagate steps: L→S→C→F\n",
    "        #                  L←S←C←\n",
    "        # more steps more menory usage\n",
    "        PROPAGATE_STEPS = 1\n",
    "        for i in range(PROPAGATE_STEPS):\n",
    "            S_embedded = self.transformer_decoder(S_embedded,L_embedded, \n",
    "                                                memory_mask = self.tmpmask_L2S[:S_,:L]) \n",
    "            C_embedded = self.transformer_decoder(C_embedded,S_embedded,\n",
    "                                                memory_mask = masks['S2C'][:C,:S_])\n",
    "            F_embedded = self.transformer_decoder(F_embedded,C_embedded,\n",
    "                                                memory_mask = masks['C2F'][:F,:C])\n",
    "            C_embedded = self.transformer_decoder(C_embedded,F_embedded,\n",
    "                                                memory_mask = Tensor.contiguous(masks['C2F'].transpose(0, 1))[:C,:F])\n",
    "            S_embedded = self.transformer_decoder(S_embedded,C_embedded,\n",
    "                                                memory_mask = Tensor.contiguous(masks['S2C'].transpose(0, 1))[:S_,:C])\n",
    "            L_embedded = self.transformer_decoder(L_embedded,S_embedded, \n",
    "                                                memory_mask = Tensor.contiguous(self.tmpmask_L2S.transpose(0, 1))[:L,:S_])\n",
    "        \n",
    "        # print('after',S_embedded[0][0])\n",
    "        output = self.MLP(S_embedded)\n",
    "        # print(query_indexs)\n",
    "        # print(output.shape)\n",
    "        # print(output[:,query_indexs].shape)\n",
    "        # print(output[:,query_indexs][0].shape)\n",
    "        \n",
    "        return output[:,query_indexs][0]\n",
    "  \n",
    "\n",
    "# 測試模型\n",
    "num_layers = 1  # TransformerDecoder 的層數\n",
    "embedding_dim = 128  # 嵌入維度\n",
    "hidden_dim = 64  \n",
    "\n",
    "print('input_dims', Train_data.INPUT_DIMS)\n",
    "model = TransformerDecoderModel(Train_data, num_layers, embedding_dim).to(DEVICE)\n",
    "\n",
    "\n",
    "outputs = model(Train_data, mode = 'train', query_indices = [2000,9999], K = 50)\n",
    "# outputs = model(Train_data, mode = 'inferring', query_indices = [10], K = 50)\n",
    "print(\"模型輸出的大小[q,2]:\", outputs.shape)\n",
    "print(outputs)\n",
    "print(outputs.softmax(dim=1))\n",
    "output_labels = torch.argmax(outputs.softmax(dim=1), dim=1)\n",
    "output_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_input torch.cuda.LongTensor torch.Size([3, 1])\n",
      "S_input torch.cuda.FloatTensor torch.Size([39074, 128])\n",
      "C_input torch.cuda.LongTensor torch.Size([469, 1])\n",
      "F_input torch.cuda.LongTensor torch.Size([14, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 9391/39073 [02:31<07:58, 62.05it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 114\u001b[0m\n\u001b[1;32m    111\u001b[0m             f\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m | Loss: \u001b[39m\u001b[39m{\u001b[39;00mepoch_loss\u001b[39m}\u001b[39;00m\u001b[39m | AUC: \u001b[39m\u001b[39m{\u001b[39;00mepoch_AUC\u001b[39m}\u001b[39;00m\u001b[39m| AUC_test: \u001b[39m\u001b[39m{\u001b[39;00mepoch_AUC_test\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m model \u001b[39m=\u001b[39m TransformerDecoderModel(Train_data, num_layers, embedding_dim)\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[0;32m--> 114\u001b[0m train(model, Train_data)\n",
      "Cell \u001b[0;32mIn[15], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, datset)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m trange(\u001b[39mlen\u001b[39m(datset\u001b[39m.\u001b[39mFEATURE_POOL)): \u001b[39m# query through all sample nodes (not infering node)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 27\u001b[0m     outputs \u001b[39m=\u001b[39m model(datset, mode \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, query_indices \u001b[39m=\u001b[39;49m [index], K \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m)\n\u001b[1;32m     28\u001b[0m     \u001b[39m# output shape:[q,2], example: torch.Size( 2, 2]\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[39m# tensor([[-0.6845, -0.6323],\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[39m#          [-0.7770, -0.4703]], device='cuda:0', grad_fn=<IndexBackward0>)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m         \n\u001b[1;32m     32\u001b[0m     \u001b[39m# for trainning, only the query node's output is used\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[39m# caculate loss\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     LABEL_POOL_ \u001b[39m=\u001b[39m LABEL_POOL[[index]] \u001b[39m# shape:[q,2] ,example [[1. 0.], [1. 0.]]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[14], line 146\u001b[0m, in \u001b[0;36mTransformerDecoderModel.forward\u001b[0;34m(self, target_, mode, query_indices, K)\u001b[0m\n\u001b[1;32m    144\u001b[0m PROPAGATE_STEPS \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    145\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(PROPAGATE_STEPS):\n\u001b[0;32m--> 146\u001b[0m     S_embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_decoder(S_embedded,L_embedded, \n\u001b[1;32m    147\u001b[0m                                         memory_mask \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtmpmask_L2S[:S_,:L]) \n\u001b[1;32m    148\u001b[0m     C_embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_decoder(C_embedded,S_embedded,\n\u001b[1;32m    149\u001b[0m                                         memory_mask \u001b[39m=\u001b[39m masks[\u001b[39m'\u001b[39m\u001b[39mS2C\u001b[39m\u001b[39m'\u001b[39m][:C,:S_])\n\u001b[1;32m    150\u001b[0m     F_embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_decoder(F_embedded,C_embedded,\n\u001b[1;32m    151\u001b[0m                                         memory_mask \u001b[39m=\u001b[39m masks[\u001b[39m'\u001b[39m\u001b[39mC2F\u001b[39m\u001b[39m'\u001b[39m][:F,:C])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:369\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    366\u001b[0m output \u001b[39m=\u001b[39m tgt\n\u001b[1;32m    368\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 369\u001b[0m     output \u001b[39m=\u001b[39m mod(output, memory, tgt_mask\u001b[39m=\u001b[39;49mtgt_mask,\n\u001b[1;32m    370\u001b[0m                  memory_mask\u001b[39m=\u001b[39;49mmemory_mask,\n\u001b[1;32m    371\u001b[0m                  tgt_key_padding_mask\u001b[39m=\u001b[39;49mtgt_key_padding_mask,\n\u001b[1;32m    372\u001b[0m                  memory_key_padding_mask\u001b[39m=\u001b[39;49mmemory_key_padding_mask)\n\u001b[1;32m    374\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    375\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(output)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m, in \u001b[0;36mTabHyperformer_Layer.forward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m     13\u001b[0m x \u001b[39m=\u001b[39m tgt\n\u001b[1;32m     14\u001b[0m \u001b[39m# x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mha_block(x, memory, memory_mask))\n\u001b[1;32m     16\u001b[0m \u001b[39m# x =  x + self._mha_block(x, memory, memory_mask, memory_key_padding_mask)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m# x = self.norm3(x + self._ff_block(x))\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "Cell \u001b[0;32mIn[13], line 22\u001b[0m, in \u001b[0;36mTabHyperformer_Layer._mha_block\u001b[0;34m(self, x, mem, attn_mask)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_mha_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor, mem: Tensor,\n\u001b[1;32m     21\u001b[0m                attn_mask: Optional[Tensor],) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 22\u001b[0m     x \u001b[39m=\u001b[39m xops\u001b[39m.\u001b[39;49mmemory_efficient_attention(x, mem, mem, attn_mask)\n\u001b[1;32m     23\u001b[0m     \u001b[39m# return self.dropout2(x)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[39mreturn\u001b[39;00m (x)\n",
      "File \u001b[0;32m~/.conda/envs/xformers/lib/python3.10/site-packages/xformers/ops/fmha/__init__.py:115\u001b[0m, in \u001b[0;36mmemory_efficient_attention\u001b[0;34m(query, key, value, attn_bias, p, scale, op)\u001b[0m\n\u001b[1;32m    107\u001b[0m         grads \u001b[39m=\u001b[39m _memory_efficient_attention_backward(\n\u001b[1;32m    108\u001b[0m             ctx\u001b[39m=\u001b[39mop_ctx, inp\u001b[39m=\u001b[39minp, grad\u001b[39m=\u001b[39mgrad, op\u001b[39m=\u001b[39mctx\u001b[39m.\u001b[39mop_bw\n\u001b[1;32m    109\u001b[0m         )\n\u001b[1;32m    110\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mNone\u001b[39;00m, grads\u001b[39m.\u001b[39mdq, grads\u001b[39m.\u001b[39mdk, grads\u001b[39m.\u001b[39mdv, grads\u001b[39m.\u001b[39mdb) \u001b[39m+\u001b[39m (\u001b[39mNone\u001b[39;00m,) \u001b[39m*\u001b[39m (\n\u001b[1;32m    111\u001b[0m             ctx\u001b[39m.\u001b[39mn_args \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    112\u001b[0m         )\n\u001b[0;32m--> 115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmemory_efficient_attention\u001b[39m(\n\u001b[1;32m    116\u001b[0m     query: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m    117\u001b[0m     key: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m    118\u001b[0m     value: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m    119\u001b[0m     attn_bias: Optional[Union[torch\u001b[39m.\u001b[39mTensor, AttentionBias]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    120\u001b[0m     p: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m,\n\u001b[1;32m    121\u001b[0m     scale: Optional[\u001b[39mfloat\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    122\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m    123\u001b[0m     op: Optional[AttentionOp] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    124\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    125\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Implements the memory-efficient attention mechanism following\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m    `\"Self-Attention Does Not Need O(n^2) Memory\" <http://arxiv.org/abs/2112.05682>`_.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39m    :return: multi-head attention Tensor with shape ``[B, Mq, H, Kv]``\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m     \u001b[39mreturn\u001b[39;00m _memory_efficient_attention(\n\u001b[1;32m    193\u001b[0m         Inputs(\n\u001b[1;32m    194\u001b[0m             query\u001b[39m=\u001b[39mquery, key\u001b[39m=\u001b[39mkey, value\u001b[39m=\u001b[39mvalue, p\u001b[39m=\u001b[39mp, attn_bias\u001b[39m=\u001b[39mattn_bias, scale\u001b[39m=\u001b[39mscale\n\u001b[1;32m    195\u001b[0m         ),\n\u001b[1;32m    196\u001b[0m         op\u001b[39m=\u001b[39mop,\n\u001b[1;32m    197\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "from torch import autograd\n",
    "from torcheval.metrics.aggregation.auc import AUC\n",
    "from torcheval.metrics import BinaryAUROC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "tmp_log = []\n",
    "tmp__log = []\n",
    "def train(model, datset):\n",
    "    LABEL_POOL = datset.LABEL_POOL\n",
    "    TEST_LABEL_POOL = datset.TEST_LABEL_POOL\n",
    "    weight = torch.from_numpy(np.array([0.2, 1])).float().to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss(weight)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    epochs = 200\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # train\n",
    "        model.train()\n",
    "        # logs\n",
    "        loss_log = []\n",
    "        AUC_metric = BinaryAUROC().to(DEVICE)\n",
    "        AUC_metric_test = BinaryAUROC().to(DEVICE)\n",
    "        \n",
    "        iter = 0\n",
    "        for index in trange(len(datset.FEATURE_POOL)): # query through all sample nodes (not infering node)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(datset, mode = 'train', query_indices = [index], K = 10)\n",
    "            # output shape:[q,2], example: torch.Size( 2, 2]\n",
    "            # tensor([[-0.6845, -0.6323],\n",
    "            #          [-0.7770, -0.4703]], device='cuda:0', grad_fn=<IndexBackward0>)\n",
    "                \n",
    "            # for trainning, only the query node's output is used\n",
    "            # caculate loss\n",
    "            LABEL_POOL_ = LABEL_POOL[[index]] # shape:[q,2] ,example [[1. 0.], [1. 0.]]\n",
    "            \n",
    "                        \n",
    "            # print(outputs.squeeze(0),outputs.squeeze(0).shape)\n",
    "            # print(torch.tensor(LABEL_POOL_,device=DEVICE).squeeze(0),torch.tensor(LABEL_POOL_,device=DEVICE).squeeze(0).shape)\n",
    "            # caculate loss\n",
    "            batch_loss = criterion(outputs, torch.tensor(LABEL_POOL_,device=DEVICE))\n",
    "            loss_log.append(batch_loss.item())\n",
    "            # break\n",
    "            # backpropagation\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # TRUE = (torch.argmax(torch.(LABEL_POOL_,device=DEVICE),dim=2))\n",
    "            TRUE = np.argmax(LABEL_POOL_,axis=1)\n",
    "            \n",
    "            outputs = outputs.softmax(dim=1)\n",
    "\n",
    "            pred_prob_of_is_1 = [probs[1] for probs in outputs] \n",
    "            # the probability of the query node is 1 (from model output)\n",
    "            \n",
    "            # tmp_log.append(float(pred_prob_of_is_1))\n",
    "            # tmp__log.append((TRUE))\n",
    "            AUC_metric.update(torch.Tensor(pred_prob_of_is_1),torch.Tensor(TRUE))\n",
    "            torch.cuda.empty_cache()\n",
    "            # break\n",
    "            iter += 1\n",
    "            # if iter >= 100:\n",
    "            #     break\n",
    "        # break\n",
    "        # evaluate\n",
    "        model.eval()\n",
    "        iter = 0\n",
    "        with torch.no_grad():\n",
    "            for index in trange(len(datset.TEST_POOL)):\n",
    "                outputs = model(datset, mode = 'inferring', query_indices = [index], K = None)\n",
    "                LABEL_POOL_ = TEST_LABEL_POOL[[index]]\n",
    "                # batch_loss = criterion(outputs, torch.tensor(LABEL_POOL_,device=DEVICE))\n",
    "\n",
    "                TRUE = np.argmax(LABEL_POOL_,axis=1)\n",
    "                outputs = outputs.softmax(dim=1)\n",
    "                pred_prob_of_is_1 = [probs[1] for probs in outputs] \n",
    "                AUC_metric_test.update(torch.Tensor(pred_prob_of_is_1),torch.Tensor(TRUE))\n",
    "                torch.cuda.empty_cache()\n",
    "                iter += 1\n",
    "                # if iter >= 100:\n",
    "                #     break\n",
    "        \n",
    "        \n",
    "        # print('1 rate pre:',sum(tmp_log)/len(tmp_log),len(tmp_log))\n",
    "        # print('1 rate tru:',float(sum(tmp__log)/len(tmp__log)),len(tmp__log))\n",
    "        # print(tmp__log)\n",
    "        # print(TRUE)\n",
    "        # print(float(AUC_metric.compute()))\n",
    "        # AUC_metric.reset()\n",
    "        # AUC_metric.update(torch.Tensor(tmp_log),torch.Tensor(tmp__log))\n",
    "        # print(float(AUC_metric.compute()))\n",
    "        \n",
    "        \n",
    "\n",
    "        epoch_loss = sum(loss_log) / len(loss_log)\n",
    "        epoch_AUC = float(AUC_metric.compute()) \n",
    "        epoch_AUC_test = float(AUC_metric_test.compute()) \n",
    "\n",
    "        AUC_metric.reset()\n",
    "        AUC_metric_test.reset()\n",
    "        # break\n",
    "        del loss_log, AUC_metric\n",
    "        tmp_log.append(float(epoch_loss))\n",
    "        tmp__log.append(float(epoch_AUC))\n",
    "        \n",
    "        # print(f\"Epoch{epoch+1}/{epochs} | Loss: {epoch_loss} | AUC: {epoch_AUC} |\")\n",
    "        print(f\"Epoch{epoch+1}/{epochs} | Loss: {epoch_loss} | AUC: {epoch_AUC} | AUC_test: {epoch_AUC_test}\")\n",
    "        \n",
    "        \n",
    "        with open('logs/log.txt', 'a') as f:\n",
    "            # f.write(f\"Epoch{epoch+1}/{epochs} | Loss: {epoch_loss} | AUC: {epoch_AUC}| \")\n",
    "            f.write(f\"Epoch{epoch+1}/{epochs} | Loss: {epoch_loss} | AUC: {epoch_AUC}| AUC_test: {epoch_AUC_test}\\n \")\n",
    "\n",
    "model = TransformerDecoderModel(Train_data, num_layers, embedding_dim).to(DEVICE)\n",
    "train(model, Train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(tmp_log)\n",
    "plt.plot(tmp__log)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "print(input.shape, target.shape)\n",
    "print(input)\n",
    "print(target)\n",
    "output = loss(input, target)\n",
    "print(output.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
