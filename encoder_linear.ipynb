{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsou/.conda/envs/GNN/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# baic transformer Encoder model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fun\n",
    "import numpy as np\n",
    "\n",
    "main_df = pd.read_csv('adult.csv')\n",
    "# main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>78</td>\n",
       "      <td>97</td>\n",
       "      <td>164</td>\n",
       "      <td>185</td>\n",
       "      <td>199</td>\n",
       "      <td>209</td>\n",
       "      <td>220</td>\n",
       "      <td>225</td>\n",
       "      <td>229</td>\n",
       "      <td>230</td>\n",
       "      <td>253</td>\n",
       "      <td>341</td>\n",
       "      <td>437</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>78</td>\n",
       "      <td>88</td>\n",
       "      <td>174</td>\n",
       "      <td>187</td>\n",
       "      <td>197</td>\n",
       "      <td>207</td>\n",
       "      <td>217</td>\n",
       "      <td>227</td>\n",
       "      <td>229</td>\n",
       "      <td>230</td>\n",
       "      <td>253</td>\n",
       "      <td>351</td>\n",
       "      <td>437</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>76</td>\n",
       "      <td>104</td>\n",
       "      <td>170</td>\n",
       "      <td>190</td>\n",
       "      <td>197</td>\n",
       "      <td>213</td>\n",
       "      <td>217</td>\n",
       "      <td>227</td>\n",
       "      <td>229</td>\n",
       "      <td>230</td>\n",
       "      <td>253</td>\n",
       "      <td>341</td>\n",
       "      <td>437</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>78</td>\n",
       "      <td>93</td>\n",
       "      <td>178</td>\n",
       "      <td>188</td>\n",
       "      <td>197</td>\n",
       "      <td>209</td>\n",
       "      <td>217</td>\n",
       "      <td>225</td>\n",
       "      <td>229</td>\n",
       "      <td>237</td>\n",
       "      <td>253</td>\n",
       "      <td>341</td>\n",
       "      <td>437</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>89</td>\n",
       "      <td>178</td>\n",
       "      <td>188</td>\n",
       "      <td>199</td>\n",
       "      <td>202</td>\n",
       "      <td>220</td>\n",
       "      <td>227</td>\n",
       "      <td>228</td>\n",
       "      <td>230</td>\n",
       "      <td>253</td>\n",
       "      <td>331</td>\n",
       "      <td>437</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
       "0    8         78      97        164              185             199   \n",
       "1   21         78      88        174              187             197   \n",
       "2   11         76     104        170              190             197   \n",
       "3   27         78      93        178              188             197   \n",
       "4    1         74      89        178              188             199   \n",
       "\n",
       "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
       "0         209           220   225     229           230           253   \n",
       "1         207           217   227     229           230           253   \n",
       "2         213           217   227     229           230           253   \n",
       "3         209           217   225     229           237           253   \n",
       "4         202           220   227     228           230           253   \n",
       "\n",
       "   hours-per-week  native-country  income  \n",
       "0             341             437     440  \n",
       "1             351             437     440  \n",
       "2             341             437     441  \n",
       "3             341             437     441  \n",
       "4             331             437     440  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def POOL_preprocess(df):\n",
    "    '''\n",
    "    input the original dataframe, output the dataframe after preprocessing,\n",
    "    change the numerical columns to categorical columns by qcut and cut\n",
    "    then apply label encoding to all columns\n",
    "    \n",
    "    '''\n",
    "    df = df.copy()\n",
    "    CAT = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\n",
    "    NUM = ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "    # qcut on numerical columns\n",
    "    for column in NUM:\n",
    "        if column in ['educational-num','capital-gain','capital-loss','hours-per-week']:\n",
    "            df[column] = pd.cut(df[column], 100)\n",
    "        else:\n",
    "            df[column] = pd.cut(df[column], 100)\n",
    "    # make income column binary\n",
    "    df['income'] = df['income'].apply(lambda x: 1 if x == '>50K' else 0)\n",
    "\n",
    "    # lable encoding categorical columns\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    lb = LabelEncoder()\n",
    "    df = df.apply(lambda x: lb.fit_transform(x))\n",
    "\n",
    "    # make all catagory in every column unique\n",
    "\n",
    "    # 迴圈處理多個欄位\n",
    "    offset = 0\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].apply(lambda x: x + offset)\n",
    "        offset += df[column].nunique()\n",
    "    \n",
    "    return df\n",
    "tmp = POOL_preprocess(main_df)\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.643585</td>\n",
       "      <td>77.870439</td>\n",
       "      <td>94.497113</td>\n",
       "      <td>173.288420</td>\n",
       "      <td>188.078089</td>\n",
       "      <td>197.618750</td>\n",
       "      <td>208.577700</td>\n",
       "      <td>218.443287</td>\n",
       "      <td>226.668052</td>\n",
       "      <td>228.668482</td>\n",
       "      <td>230.626858</td>\n",
       "      <td>254.102596</td>\n",
       "      <td>341.396728</td>\n",
       "      <td>434.749355</td>\n",
       "      <td>440.239282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.710510</td>\n",
       "      <td>1.464234</td>\n",
       "      <td>7.118204</td>\n",
       "      <td>3.874492</td>\n",
       "      <td>2.570973</td>\n",
       "      <td>1.507703</td>\n",
       "      <td>4.230509</td>\n",
       "      <td>1.602151</td>\n",
       "      <td>0.845986</td>\n",
       "      <td>0.470764</td>\n",
       "      <td>2.670115</td>\n",
       "      <td>5.196314</td>\n",
       "      <td>12.295271</td>\n",
       "      <td>7.775343</td>\n",
       "      <td>0.426649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>437.000000</td>\n",
       "      <td>440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>437.000000</td>\n",
       "      <td>440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>437.000000</td>\n",
       "      <td>440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>397.000000</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>441.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age     workclass        fnlwgt     education  \\\n",
       "count  48842.000000  48842.000000  48842.000000  48842.000000   \n",
       "mean      21.643585     77.870439     94.497113    173.288420   \n",
       "std       13.710510      1.464234      7.118204      3.874492   \n",
       "min        0.000000     74.000000     83.000000    163.000000   \n",
       "25%       11.000000     78.000000     90.000000    172.000000   \n",
       "50%       20.000000     78.000000     94.000000    174.000000   \n",
       "75%       31.000000     78.000000     98.000000    175.000000   \n",
       "max       73.000000     82.000000    162.000000    178.000000   \n",
       "\n",
       "       educational-num  marital-status    occupation  relationship  \\\n",
       "count     48842.000000    48842.000000  48842.000000  48842.000000   \n",
       "mean        188.078089      197.618750    208.577700    218.443287   \n",
       "std           2.570973        1.507703      4.230509      1.602151   \n",
       "min         179.000000      195.000000    202.000000    217.000000   \n",
       "25%         187.000000      197.000000    205.000000    217.000000   \n",
       "50%         188.000000      197.000000    209.000000    218.000000   \n",
       "75%         190.000000      199.000000    212.000000    220.000000   \n",
       "max         194.000000      201.000000    216.000000    222.000000   \n",
       "\n",
       "               race        gender  capital-gain  capital-loss  hours-per-week  \\\n",
       "count  48842.000000  48842.000000  48842.000000  48842.000000    48842.000000   \n",
       "mean     226.668052    228.668482    230.626858    254.102596      341.396728   \n",
       "std        0.845986      0.470764      2.670115      5.196314       12.295271   \n",
       "min      223.000000    228.000000    230.000000    253.000000      302.000000   \n",
       "25%      227.000000    228.000000    230.000000    253.000000      341.000000   \n",
       "50%      227.000000    229.000000    230.000000    253.000000      341.000000   \n",
       "75%      227.000000    229.000000    230.000000    253.000000      346.000000   \n",
       "max      227.000000    229.000000    252.000000    301.000000      397.000000   \n",
       "\n",
       "       native-country        income  \n",
       "count    48842.000000  48842.000000  \n",
       "mean       434.749355    440.239282  \n",
       "std          7.775343      0.426649  \n",
       "min        398.000000    440.000000  \n",
       "25%        437.000000    440.000000  \n",
       "50%        437.000000    440.000000  \n",
       "75%        437.000000    440.000000  \n",
       "max        439.000000    441.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data num: 48842\n",
      "trian data num: 39074\n",
      "test data num: 9768\n"
     ]
    }
   ],
   "source": [
    "train_size = 4*48842//5\n",
    "test_size = 48842//5\n",
    "train_pool = main_df[test_size:]\n",
    "test_pool = main_df[:test_size]\n",
    "print('total data num:' , main_df.shape[0])\n",
    "print('trian data num:' , train_pool.shape[0])\n",
    "print('test data num:' , test_pool.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notations\n",
    "#   node: number of all nodes = L + S + C + F\n",
    "#   L: number of lable nodes\n",
    "#   S: number of sample nodes\n",
    "#   C: number of catagory nodes\n",
    "#   F: number of field(column) nodes\n",
    "#   hidden: number of hidden representation\n",
    "\n",
    "# data size = (node, hidden)\n",
    "# mask size = (node, node - L) without lable nodes\n",
    "#             for each node, real mask = cat[mask,(node,L)] = (node, node)\n",
    "#             cannot see it's label node\n",
    "\n",
    "# use nn.transformerEncoder(data,mask) to get the output\n",
    "# use the above output as input of MLP to predict the lable   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature pool shape: (48842, 14)\n",
      "label pool shape: (48842, 2)\n",
      "L: 2\n",
      "S: 48842\n",
      "P: 310\n",
      "C: 440\n",
      "F: 14\n",
      "total 49608\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439]\n",
      "440\n"
     ]
    }
   ],
   "source": [
    "TARGET_POOL = POOL_preprocess(main_df)\n",
    "LABEL_COLUMN = 'income'\n",
    "# \n",
    "HIDDEN = 64\n",
    "\n",
    "# cut feature and lable\n",
    "FEATURE_POOL = TARGET_POOL.drop(LABEL_COLUMN, axis=1)\n",
    "LABEL_POOL = TARGET_POOL[LABEL_COLUMN]\n",
    "\n",
    "# trasform label into one-hot\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "LABEL_POOL = enc.fit_transform(LABEL_POOL.values.reshape(-1,1)).toarray()\n",
    "\n",
    "print('feature pool shape:', FEATURE_POOL.shape)\n",
    "print('label pool shape:', LABEL_POOL.shape)\n",
    "\n",
    "# L: number of lable nodes\n",
    "L = LABEL_POOL.shape[1]\n",
    "\n",
    "# S: number of sample nodes\n",
    "S = FEATURE_POOL.shape[0]\n",
    "\n",
    "# C: number of catagory nodes\n",
    "C = FEATURE_POOL.apply(lambda x: x.nunique()).sum() # total_unique_labels\n",
    "C_POOL = list(set(FEATURE_POOL.values.flatten()))\n",
    "\n",
    "# F: number of field(column) nodes\n",
    "F = FEATURE_POOL.shape[1]\n",
    "\n",
    "P = 310\n",
    "\n",
    "print('L:', L)\n",
    "print('S:', S)\n",
    "print('P:', P)\n",
    "print('C:', C)\n",
    "print('F:', F)\n",
    "print('total', L+S+P+C+F)\n",
    "print(C_POOL)\n",
    "print(len(C_POOL))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL_POOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49593\n",
      "49607\n",
      "1466140\n",
      "1466140\n"
     ]
    }
   ],
   "source": [
    "# caculate masking\n",
    "\n",
    "edge_x = []\n",
    "edge_y = []\n",
    "\n",
    "# label to sample \n",
    "offset = (L,0) # (x,y)\n",
    "label_ids = TARGET_POOL[LABEL_COLUMN].unique()\n",
    "for i, value_df in enumerate(TARGET_POOL[LABEL_COLUMN]):\n",
    "    for j, value_label in enumerate(label_ids):\n",
    "        if value_label == value_df:\n",
    "            edge_x.append(offset[0] + i)\n",
    "            edge_y.append(offset[1] + j)\n",
    "print(max(edge_x))\n",
    "\n",
    "# sample to catagory\n",
    "offset = (L+S+P,L) # (x,y)\n",
    "tmp_df = TARGET_POOL.drop(LABEL_COLUMN, axis=1)\n",
    "for i, value_df in enumerate(tmp_df.values):\n",
    "    for j, value in enumerate(value_df):\n",
    "        edge_x.append(offset[0] + value)\n",
    "        edge_y.append(offset[1] + i)\n",
    "print(max(edge_x))\n",
    "\n",
    "# catagory to field\n",
    "offset = (L+S+P+C,L+S+P) # (x,y)\n",
    "unique_items = [(TARGET_POOL[column].unique()) for column in (TARGET_POOL.columns)]\n",
    "for i in range(F):\n",
    "    for j in (unique_items[i]):\n",
    "        edge_x.append(offset[0] + i)\n",
    "        edge_y.append(offset[1] + j)\n",
    "print(max(edge_x))\n",
    "\n",
    "# make edges symmetric\n",
    "tmp = edge_x.copy()\n",
    "edge_x += edge_y\n",
    "edge_y += tmp\n",
    "\n",
    "# make value on edge as 1\n",
    "value_on_edge = [1]*len(edge_x)\n",
    "\n",
    "print(len(edge_x))\n",
    "print(len(edge_y))\n",
    "\n",
    "# create mask as sparse tensor\n",
    "indices = torch.tensor([edge_x, edge_y])\n",
    "values = torch.tensor(value_on_edge)\n",
    "size = torch.Size([L+S+P+C+F, L+S+P+C+F])\n",
    "sparse_tensor_mask = torch.sparse_coo_tensor(indices, values, size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_input torch.cuda.FloatTensor torch.Size([2, 2])\n",
      "S_input torch.cuda.LongTensor torch.Size([48842, 14])\n",
      "C_input torch.cuda.LongTensor torch.Size([440, 440])\n",
      "F_input torch.cuda.FloatTensor torch.Size([14, 14])\n",
      "torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# make input tensor\n",
    "# L\n",
    "L_input = torch.eye(L).to('cuda')\n",
    "print('L_input', L_input.type(), L_input.shape)\n",
    "# S\n",
    "S_input = torch.tensor(FEATURE_POOL.values).to('cuda')\n",
    "print('S_input', S_input.type(), S_input.shape)\n",
    "# C random init\n",
    "C_input = torch.tensor(np.diag(C_POOL)).to('cuda')\n",
    "print('C_input', C_input.type(), C_input.shape)\n",
    "# F random init\n",
    "F_input = torch.eye(F).to('cuda')\n",
    "print('F_input', F_input.type(), F_input.shape)\n",
    "print(L_input.type())\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from typing import Optional, Any, Union, Callable\n",
    "from linear_mem_attention_pytorch.fast_attn import Attention\n",
    "\n",
    "class CustomTransformerEncoderLayer(nn.TransformerEncoderLayer):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, activation='relu'):\n",
    "        super().__init__(d_model, nhead, dim_feedforward, dropout, activation)\n",
    "        # remove defined modules\n",
    "        delattr(self, 'self_attn')\n",
    "        \n",
    "        self.self_attn = Attention(dim=d_model, heads = nhead, dim_head = 128, bias=False)\n",
    "    \n",
    "    def _sa_block(self, x: Tensor,\n",
    "                  attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) -> Tensor:\n",
    "        x = x[None, :]\n",
    "        x = self.self_attn(x, x, attn_mask, query_chunk_size=1024, key_chunk_size=1024)\n",
    "        return self.dropout1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dimantions (2, 14, 440, 14)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded shape torch.Size([49298, 128])\n",
      "embedded shape torch.cuda.FloatTensor\n",
      "mask shape torch.Size([49608, 49608])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1) must match the existing size (49608) at non-singleton dimension 0.  Target sizes: [1, 1024, 4, 1024].  Tensor sizes: [49608, 1, 1, 1024]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minput_dimantions\u001b[39m\u001b[39m'\u001b[39m, input_dimantions)\n\u001b[1;32m     53\u001b[0m model \u001b[39m=\u001b[39m TransformerEncoderModel(input_dimantions, num_layers, embedding_dim, hidden_dim)\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m output \u001b[39m=\u001b[39m model(L_input, S_input, C_input, F_input, sparse_tensor_mask\u001b[39m.\u001b[39;49mto(\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     56\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m模型輸出的大小:\u001b[39m\u001b[39m\"\u001b[39m, output\u001b[39m.\u001b[39msize())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[11], line 42\u001b[0m, in \u001b[0;36mTransformerEncoderModel.forward\u001b[0;34m(self, L_input, S_input, C_input, F_input, mask)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39membedded shape\u001b[39m\u001b[39m'\u001b[39m, embedded\u001b[39m.\u001b[39mtype())\n\u001b[1;32m     41\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmask shape\u001b[39m\u001b[39m'\u001b[39m, mask\u001b[39m.\u001b[39mbool()\u001b[39m.\u001b[39mto_dense()\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 42\u001b[0m encoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_encoder(embedded, mask\u001b[39m.\u001b[39;49mbool()\u001b[39m.\u001b[39;49mto_dense())  \u001b[39m# 使用 TransformerEncoder 編碼\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mencoded shape\u001b[39m\u001b[39m'\u001b[39m, encoded\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:280\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    277\u001b[0m         src_key_padding_mask_for_layers \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 280\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask_for_layers)\n\u001b[1;32m    282\u001b[0m \u001b[39mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    283\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mto_padded_tensor(\u001b[39m0.\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:538\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    536\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x))\n\u001b[1;32m    537\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 538\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sa_block(x, src_mask, src_key_padding_mask))\n\u001b[1;32m    539\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[1;32m    541\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "Cell \u001b[0;32mIn[10], line 16\u001b[0m, in \u001b[0;36mCustomTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sa_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor,\n\u001b[1;32m     14\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m     15\u001b[0m     x \u001b[39m=\u001b[39m x[\u001b[39mNone\u001b[39;00m, :]\n\u001b[0;32m---> 16\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(x, x, attn_mask, query_chunk_size\u001b[39m=\u001b[39;49m\u001b[39m1024\u001b[39;49m, key_chunk_size\u001b[39m=\u001b[39;49m\u001b[39m1024\u001b[39;49m)\n\u001b[1;32m     17\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/GNN/lib/python3.10/site-packages/linear_mem_attention_pytorch-0.0.1-py3.10.egg/linear_mem_attention_pytorch/fast_attn.py:34\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, x, context, mask, query_chunk_size, key_chunk_size)\u001b[0m\n\u001b[1;32m     30\u001b[0m kv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_kv(context)\u001b[39m.\u001b[39mchunk(\u001b[39m2\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     32\u001b[0m q, k, v \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m t: rearrange(t, \u001b[39m\"\u001b[39m\u001b[39mb n (h d) -> b n h d\u001b[39m\u001b[39m\"\u001b[39m, h\u001b[39m=\u001b[39mh), (q, \u001b[39m*\u001b[39mkv))\n\u001b[0;32m---> 34\u001b[0m out \u001b[39m=\u001b[39m attention(q, k, v, mask, query_chunk_size, key_chunk_size)\n\u001b[1;32m     36\u001b[0m out \u001b[39m=\u001b[39m rearrange(out, \u001b[39m\"\u001b[39m\u001b[39mb n h d -> b n (h d)\u001b[39m\u001b[39m\"\u001b[39m, h\u001b[39m=\u001b[39mh)\n\u001b[1;32m     37\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_out(out)\n",
      "File \u001b[0;32m~/.conda/envs/GNN/lib/python3.10/site-packages/linear_mem_attention_pytorch-0.0.1-py3.10.egg/linear_mem_attention_pytorch/linear_mem_attn_torch.py:122\u001b[0m, in \u001b[0;36mattention\u001b[0;34m(query, key, value, mask, query_chunk_size, key_chunk_size)\u001b[0m\n\u001b[1;32m    113\u001b[0m     query_chunk \u001b[39m=\u001b[39m dynamic_length_slice(query, chunk_idx, query_chunk_size)\n\u001b[1;32m    115\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    116\u001b[0m         chunk_idx \u001b[39m+\u001b[39m query_chunk_size,\n\u001b[1;32m    117\u001b[0m         query_chunk_attention(\n\u001b[1;32m    118\u001b[0m             query_chunk, key, value, mask, key_chunk_size\u001b[39m=\u001b[39mkey_chunk_size\n\u001b[1;32m    119\u001b[0m         ),\n\u001b[1;32m    120\u001b[0m     )\n\u001b[0;32m--> 122\u001b[0m _, res \u001b[39m=\u001b[39m torch_scan(\n\u001b[1;32m    123\u001b[0m     chunk_scanner, init\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, xs\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, length\u001b[39m=\u001b[39;49mmath\u001b[39m.\u001b[39;49mceil(num_q \u001b[39m/\u001b[39;49m query_chunk_size)\n\u001b[1;32m    124\u001b[0m )\n\u001b[1;32m    125\u001b[0m \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39mreshape(batch, num_q, num_heads, value\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/.conda/envs/GNN/lib/python3.10/site-packages/linear_mem_attention_pytorch-0.0.1-py3.10.egg/linear_mem_attention_pytorch/utils.py:64\u001b[0m, in \u001b[0;36mtorch_scan\u001b[0;34m(f, init, xs, length)\u001b[0m\n\u001b[1;32m     62\u001b[0m ys \u001b[39m=\u001b[39m []\n\u001b[1;32m     63\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m xs:\n\u001b[0;32m---> 64\u001b[0m     carry, y \u001b[39m=\u001b[39m f(carry, x)\n\u001b[1;32m     65\u001b[0m     ys\u001b[39m.\u001b[39mappend(y)\n\u001b[1;32m     66\u001b[0m \u001b[39mreturn\u001b[39;00m carry, torch\u001b[39m.\u001b[39mstack(ys, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/GNN/lib/python3.10/site-packages/linear_mem_attention_pytorch-0.0.1-py3.10.egg/linear_mem_attention_pytorch/linear_mem_attn_torch.py:117\u001b[0m, in \u001b[0;36mattention.<locals>.chunk_scanner\u001b[0;34m(chunk_idx, _)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mchunk_scanner\u001b[39m(chunk_idx: \u001b[39mint\u001b[39m, _):\n\u001b[1;32m    113\u001b[0m     query_chunk \u001b[39m=\u001b[39m dynamic_length_slice(query, chunk_idx, query_chunk_size)\n\u001b[1;32m    115\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    116\u001b[0m         chunk_idx \u001b[39m+\u001b[39m query_chunk_size,\n\u001b[0;32m--> 117\u001b[0m         query_chunk_attention(\n\u001b[1;32m    118\u001b[0m             query_chunk, key, value, mask, key_chunk_size\u001b[39m=\u001b[39;49mkey_chunk_size\n\u001b[1;32m    119\u001b[0m         ),\n\u001b[1;32m    120\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/GNN/lib/python3.10/site-packages/linear_mem_attention_pytorch-0.0.1-py3.10.egg/linear_mem_attention_pytorch/linear_mem_attn_torch.py:83\u001b[0m, in \u001b[0;36mquery_chunk_attention\u001b[0;34m(query, key, value, mask, key_chunk_size)\u001b[0m\n\u001b[1;32m     74\u001b[0m chunk_max \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\n\u001b[1;32m     75\u001b[0m     num_chunks,\n\u001b[1;32m     76\u001b[0m     batch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m     device\u001b[39m=\u001b[39mdevice,\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     82\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_chunks):\n\u001b[0;32m---> 83\u001b[0m     chunk_values[i], chunk_weights[i], chunk_max[i] \u001b[39m=\u001b[39m chunk_scanner(\n\u001b[1;32m     84\u001b[0m         i \u001b[39m*\u001b[39;49m key_chunk_size\n\u001b[1;32m     85\u001b[0m     )\n\u001b[1;32m     87\u001b[0m max_diffs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mexp(chunk_max \u001b[39m-\u001b[39m chunk_max\u001b[39m.\u001b[39mamax(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n\u001b[1;32m     89\u001b[0m all_values \u001b[39m=\u001b[39m (max_diffs\u001b[39m.\u001b[39munsqueeze(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m chunk_values)\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/GNN/lib/python3.10/site-packages/linear_mem_attention_pytorch-0.0.1-py3.10.egg/linear_mem_attention_pytorch/linear_mem_attn_torch.py:52\u001b[0m, in \u001b[0;36mquery_chunk_attention.<locals>.chunk_scanner\u001b[0;34m(chunk_idx)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mif\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     mask_chunk \u001b[39m=\u001b[39m dynamic_length_slice(mask, chunk_idx, key_chunk_size)\n\u001b[0;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m checkpoint\u001b[39m.\u001b[39;49mcheckpoint(\n\u001b[1;32m     53\u001b[0m     summarize_chunk, query, key_chunk, value_chunk, mask_chunk\n\u001b[1;32m     54\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:249\u001b[0m, in \u001b[0;36mcheckpoint\u001b[0;34m(function, use_reentrant, *args, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnexpected keyword arguments: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(arg \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m kwargs))\n\u001b[1;32m    248\u001b[0m \u001b[39mif\u001b[39;00m use_reentrant:\n\u001b[0;32m--> 249\u001b[0m     \u001b[39mreturn\u001b[39;00m CheckpointFunction\u001b[39m.\u001b[39;49mapply(function, preserve, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    250\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     \u001b[39mreturn\u001b[39;00m _checkpoint_without_reentrant(\n\u001b[1;32m    252\u001b[0m         function,\n\u001b[1;32m    253\u001b[0m         preserve,\n\u001b[1;32m    254\u001b[0m         \u001b[39m*\u001b[39margs,\n\u001b[1;32m    255\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    256\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:107\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[0;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[1;32m    104\u001b[0m ctx\u001b[39m.\u001b[39msave_for_backward(\u001b[39m*\u001b[39mtensor_inputs)\n\u001b[1;32m    106\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 107\u001b[0m     outputs \u001b[39m=\u001b[39m run_function(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.conda/envs/GNN/lib/python3.10/site-packages/linear_mem_attention_pytorch-0.0.1-py3.10.egg/linear_mem_attention_pytorch/linear_mem_attn_torch.py:33\u001b[0m, in \u001b[0;36mquery_chunk_attention.<locals>.summarize_chunk\u001b[0;34m(query, key, value, mask)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     max_neg \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mtorch\u001b[39m.\u001b[39mfinfo(attn_weights\u001b[39m.\u001b[39mdtype)\u001b[39m.\u001b[39mmax\n\u001b[0;32m---> 33\u001b[0m     attn_weights\u001b[39m.\u001b[39;49mmasked_fill_(\u001b[39m~\u001b[39;49mmask\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m2\u001b[39;49m), max_neg)\n\u001b[1;32m     35\u001b[0m max_score \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mamax(attn_weights, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m     36\u001b[0m exp_weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mexp(attn_weights \u001b[39m-\u001b[39m max_score)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (49608) at non-singleton dimension 0.  Target sizes: [1, 1024, 4, 1024].  Tensor sizes: [49608, 1, 1, 1024]"
     ]
    }
   ],
   "source": [
    "# baic transformer Encoder model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fun\n",
    "\n",
    "class TransformerEncoderModel(nn.Module):\n",
    "    def __init__(self, nodes_num, num_layers, embedding_dim, hidden_dim):\n",
    "        super(TransformerEncoderModel, self).__init__()\n",
    "\n",
    "        L_dim, S_dim, C_dim, F_dim = nodes_num\n",
    "        \n",
    "        # 目前b卡在embedding的怎麼用\n",
    "        # Catagory_embedding => 數值類Qcut後用linear來做embedding, 類別用nn.Embedding\n",
    "        \n",
    "        # self.Lable_embedding = nn.Embedding(L_dim, embedding_dim)\n",
    "        # self.Sample_embedding = nn.Embedding(S_dim, embedding_dim)\n",
    "        # self.Catagory_embedding = nn.Embedding(C_dim, embedding_dim)\n",
    "        # self.Field_embedding = nn.Embedding(F_dim, emedding_dim)\n",
    "        \n",
    "        self.Lable_embedding = nn.Linear(L_dim, embedding_dim, dtype=torch.float)\n",
    "        self.Sample_embedding = nn.Linear(S_dim, embedding_dim, dtype=torch.float)\n",
    "        self.Catagory_embedding = nn.Linear(C_dim, embedding_dim, dtype=torch.float)\n",
    "        self.Field_embedding = nn.Linear(F_dim, embedding_dim, dtype=torch.float)\n",
    "        \n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            CustomTransformerEncoderLayer(embedding_dim,nhead = 4 ),\n",
    "            num_layers\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, L_input, S_input, C_input, F_input, mask):\n",
    "        L_embedded = self.Lable_embedding(L_input.float())\n",
    "        S_embedded = self.Sample_embedding(S_input.float())\n",
    "        C_embedded = self.Catagory_embedding(C_input.float())\n",
    "        F_embedded = self.Field_embedding(F_input.float())\n",
    "        \n",
    "        # concat all embedded\n",
    "        embedded = torch.cat((L_embedded, S_embedded, C_embedded, F_embedded),0)\n",
    "        print('embedded shape', embedded.shape)\n",
    "        print('embedded shape', embedded.type())\n",
    "        print('mask shape', mask.bool().to_dense().shape)\n",
    "        encoded = self.transformer_encoder(embedded, mask.bool().to_dense())  # 使用 TransformerEncoder 編碼\n",
    "        print('encoded shape', encoded.shape)\n",
    "        # return encoded.permute(1, 0, 2)  # 改變 tensor 的維度順序回來\n",
    "\n",
    "# 測試模型\n",
    "num_layers = 2  # TransformerEncoder 的層數\n",
    "embedding_dim = 128  # 嵌入維度\n",
    "hidden_dim = 64  # TransformerEncoderLayer 的隱藏層維度\n",
    "\n",
    "input_dimantions = (L_input.size(1), S_input.size(1), C_input.size(1), F_input.size(1))\n",
    "print('input_dimantions', input_dimantions)\n",
    "model = TransformerEncoderModel(input_dimantions, num_layers, embedding_dim, hidden_dim).to('cuda')\n",
    "output = model(L_input, S_input, C_input, F_input, sparse_tensor_mask.to('cuda'))\n",
    "\n",
    "print(\"模型輸出的大小:\", output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
